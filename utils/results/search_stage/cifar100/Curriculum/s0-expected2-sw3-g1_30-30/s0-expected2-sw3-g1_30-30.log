12/22 04:22:43AM parser.py:28 [INFO] 
12/22 04:22:43AM parser.py:29 [INFO] Parameters:
12/22 04:22:43AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30/DAG
12/22 04:22:43AM parser.py:31 [INFO] T=10.0
12/22 04:22:43AM parser.py:31 [INFO] ADVANCED=1
12/22 04:22:43AM parser.py:31 [INFO] ALPHA_LR=0.0003
12/22 04:22:43AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/22 04:22:43AM parser.py:31 [INFO] ARCH_CRITERION=expected
12/22 04:22:43AM parser.py:31 [INFO] BATCH_SIZE=64
12/22 04:22:43AM parser.py:31 [INFO] CASCADE=0
12/22 04:22:43AM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/22 04:22:43AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 30]
12/22 04:22:43AM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/22 04:22:43AM parser.py:31 [INFO] DATA_PATH=../data/
12/22 04:22:43AM parser.py:31 [INFO] DATASET=cifar100
12/22 04:22:43AM parser.py:31 [INFO] DEPTH_COEF=0.0
12/22 04:22:43AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/22 04:22:43AM parser.py:31 [INFO] DISCRETE=1
12/22 04:22:43AM parser.py:31 [INFO] EPOCHS=50
12/22 04:22:43AM parser.py:31 [INFO] EVAL_EPOCHS=100
12/22 04:22:43AM parser.py:31 [INFO] EXP_NAME=s0-expected2-sw3-g1_30-30
12/22 04:22:43AM parser.py:31 [INFO] FINAL_L=0.0
12/22 04:22:43AM parser.py:31 [INFO] G=1.0
12/22 04:22:43AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/22 04:22:43AM parser.py:31 [INFO] GPUS=[0]
12/22 04:22:43AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/22 04:22:43AM parser.py:31 [INFO] INIT_CHANNELS=16
12/22 04:22:43AM parser.py:31 [INFO] L=0.0
12/22 04:22:43AM parser.py:31 [INFO] LAYERS=32
12/22 04:22:43AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/22 04:22:43AM parser.py:31 [INFO] NAME=Curriculum
12/22 04:22:43AM parser.py:31 [INFO] NONKD=1
12/22 04:22:43AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30
12/22 04:22:43AM parser.py:31 [INFO] PCDARTS=0
12/22 04:22:43AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30/plots
12/22 04:22:43AM parser.py:31 [INFO] PRINT_FREQ=100
12/22 04:22:43AM parser.py:31 [INFO] RESET=0
12/22 04:22:43AM parser.py:31 [INFO] RESUME_PATH=None
12/22 04:22:43AM parser.py:31 [INFO] SAVE=s0-expected2-sw3-g1_30-30
12/22 04:22:43AM parser.py:31 [INFO] SEED=0
12/22 04:22:43AM parser.py:31 [INFO] SHARE_STAGE=0
12/22 04:22:43AM parser.py:31 [INFO] SLIDE_WINDOW=3
12/22 04:22:43AM parser.py:31 [INFO] SPEC_CELL=1
12/22 04:22:43AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/22 04:22:43AM parser.py:31 [INFO] TEACHER_NAME=none
12/22 04:22:43AM parser.py:31 [INFO] TEACHER_PATH=none
12/22 04:22:43AM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/22 04:22:43AM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
12/22 04:22:43AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/22 04:22:43AM parser.py:31 [INFO] W_LR=0.025
12/22 04:22:43AM parser.py:31 [INFO] W_LR_MIN=0.001
12/22 04:22:43AM parser.py:31 [INFO] W_MOMENTUM=0.9
12/22 04:22:43AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/22 04:22:43AM parser.py:31 [INFO] WORKERS=4
12/22 04:22:43AM parser.py:32 [INFO] 
12/22 04:22:44AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/22 04:23:39AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3344 (4.4863)	Arch Loss 4.2698 (4.4880)	Arch Hard Loss 4.2698 (4.4880)	Arch Beta Loss 6.1913 (6.1938)	Arch depth Loss -0.0040 (-0.0015)	Prec@(1,5) (2.4%, 10.9%)	
12/22 04:24:32AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.0209 (4.3461)	Arch Loss 4.1846 (4.3406)	Arch Hard Loss 4.1846 (4.3406)	Arch Beta Loss 6.1859 (6.1912)	Arch depth Loss -0.0060 (-0.0032)	Prec@(1,5) (3.5%, 15.2%)	
12/22 04:25:25AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9587 (4.2435)	Arch Loss 4.0519 (4.2500)	Arch Hard Loss 4.0519 (4.2500)	Arch Beta Loss 6.1820 (6.1884)	Arch depth Loss -0.0095 (-0.0047)	Prec@(1,5) (4.6%, 18.3%)	
12/22 04:26:13AM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.8669 (4.1796)	Arch Loss 3.8305 (4.1805)	Arch Hard Loss 3.8305 (4.1805)	Arch Beta Loss 6.1758 (6.1860)	Arch depth Loss -0.0087 (-0.0058)	Prec@(1,5) (5.4%, 20.4%)	
12/22 04:26:15AM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  0/159] Final Prec@1 5.4120%
12/22 04:26:23AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9372	Prec@(1,5) (7.5%, 27.7%)
12/22 04:26:31AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9225	Prec@(1,5) (8.1%, 28.3%)
12/22 04:26:39AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9229	Prec@(1,5) (8.1%, 28.2%)
12/22 04:26:46AM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9228	Prec@(1,5) (8.1%, 28.1%)
12/22 04:26:46AM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/159] Final Prec@1 8.0640%
12/22 04:26:46AM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 3), ('skip_connect', 1)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 04:26:47AM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 8.0640%
12/22 04:27:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.025	Loss 3.8585 (3.8893)	Arch Loss 4.1322 (3.8841)	Arch Hard Loss 4.1322 (3.8841)	Arch Beta Loss 6.1683 (6.1721)	Arch depth Loss -0.0079 (-0.0080)	Prec@(1,5) (8.8%, 29.6%)	
12/22 04:28:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.025	Loss 3.6782 (3.8505)	Arch Loss 3.8268 (3.8337)	Arch Hard Loss 3.8268 (3.8337)	Arch Beta Loss 6.1594 (6.1683)	Arch depth Loss -0.0053 (-0.0070)	Prec@(1,5) (9.4%, 31.0%)	
12/22 04:29:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.025	Loss 3.7272 (3.8062)	Arch Loss 3.5344 (3.7964)	Arch Hard Loss 3.5344 (3.7964)	Arch Beta Loss 6.1546 (6.1643)	Arch depth Loss -0.0062 (-0.0070)	Prec@(1,5) (10.2%, 32.4%)	
12/22 04:30:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.025	Loss 3.6855 (3.7657)	Arch Loss 3.7753 (3.7619)	Arch Hard Loss 3.7753 (3.7619)	Arch Beta Loss 6.1494 (6.1615)	Arch depth Loss -0.0046 (-0.0064)	Prec@(1,5) (10.8%, 33.8%)	
12/22 04:30:21午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  1/159] Final Prec@1 10.8520%
12/22 04:30:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.5817	Prec@(1,5) (14.3%, 39.0%)
12/22 04:30:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.5747	Prec@(1,5) (14.5%, 39.0%)
12/22 04:30:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.5804	Prec@(1,5) (14.3%, 39.1%)
12/22 04:30:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.5812	Prec@(1,5) (14.3%, 39.2%)
12/22 04:30:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/159] Final Prec@1 14.2960%
12/22 04:30:53午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
12/22 04:30:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 14.2960%
12/22 04:31:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02499	Loss 3.6353 (3.5638)	Arch Loss 3.5550 (3.5703)	Arch Hard Loss 3.5550 (3.5703)	Arch Beta Loss 6.1408 (6.1451)	Arch depth Loss -0.0065 (-0.0052)	Prec@(1,5) (13.9%, 40.1%)	
12/22 04:32:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02499	Loss 3.4935 (3.5441)	Arch Loss 3.4002 (3.5541)	Arch Hard Loss 3.4002 (3.5541)	Arch Beta Loss 6.1373 (6.1422)	Arch depth Loss -0.0063 (-0.0056)	Prec@(1,5) (14.8%, 40.5%)	
12/22 04:33:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02499	Loss 3.2929 (3.5133)	Arch Loss 3.6146 (3.5254)	Arch Hard Loss 3.6146 (3.5254)	Arch Beta Loss 6.1339 (6.1399)	Arch depth Loss -0.0063 (-0.0058)	Prec@(1,5) (15.2%, 41.2%)	
12/22 04:34:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02499	Loss 3.5192 (3.4930)	Arch Loss 3.2908 (3.4995)	Arch Hard Loss 3.2908 (3.4995)	Arch Beta Loss 6.1235 (6.1369)	Arch depth Loss -0.0070 (-0.0061)	Prec@(1,5) (15.7%, 41.8%)	
12/22 04:34:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  2/159] Final Prec@1 15.6760%
12/22 04:34:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.4426	Prec@(1,5) (16.5%, 43.4%)
12/22 04:34:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.4632	Prec@(1,5) (16.0%, 42.7%)
12/22 04:34:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.4560	Prec@(1,5) (16.2%, 43.1%)
12/22 04:34:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.4562	Prec@(1,5) (16.2%, 43.1%)
12/22 04:34:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/159] Final Prec@1 16.2240%
12/22 04:34:58午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 1), ('skip_connect', 3)], [('max_pool_3x3', 4), ('skip_connect', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
12/22 04:34:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 16.2240%
12/22 04:35:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02498	Loss 3.5035 (3.3502)	Arch Loss 3.4229 (3.3502)	Arch Hard Loss 3.4229 (3.3502)	Arch Beta Loss 6.1134 (6.1169)	Arch depth Loss -0.0044 (-0.0050)	Prec@(1,5) (18.3%, 46.4%)	
12/22 04:36:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02498	Loss 3.1996 (3.3149)	Arch Loss 3.6360 (3.3325)	Arch Hard Loss 3.6360 (3.3325)	Arch Beta Loss 6.1065 (6.1140)	Arch depth Loss -0.0045 (-0.0045)	Prec@(1,5) (18.8%, 47.1%)	
12/22 04:37:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02498	Loss 2.9987 (3.2792)	Arch Loss 3.3645 (3.3030)	Arch Hard Loss 3.3645 (3.3030)	Arch Beta Loss 6.0952 (6.1094)	Arch depth Loss -0.0086 (-0.0050)	Prec@(1,5) (19.3%, 48.1%)	
12/22 04:38:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02498	Loss 3.1137 (3.2549)	Arch Loss 3.1531 (3.2788)	Arch Hard Loss 3.1531 (3.2788)	Arch Beta Loss 6.0850 (6.1049)	Arch depth Loss -0.0072 (-0.0056)	Prec@(1,5) (19.9%, 48.7%)	
12/22 04:38:29午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  3/159] Final Prec@1 19.8840%
12/22 04:38:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.1510	Prec@(1,5) (21.9%, 50.9%)
12/22 04:38:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.1506	Prec@(1,5) (21.9%, 50.8%)
12/22 04:38:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.1598	Prec@(1,5) (21.7%, 50.7%)
12/22 04:39:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.1658	Prec@(1,5) (21.7%, 50.7%)
12/22 04:39:00午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/159] Final Prec@1 21.6560%
12/22 04:39:00午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
12/22 04:39:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 21.6560%
12/22 04:39:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02496	Loss 2.9803 (3.0895)	Arch Loss 3.0267 (3.1749)	Arch Hard Loss 3.0267 (3.1749)	Arch Beta Loss 6.0788 (6.0816)	Arch depth Loss -0.0074 (-0.0073)	Prec@(1,5) (23.2%, 52.8%)	
12/22 04:40:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02496	Loss 3.1713 (3.0731)	Arch Loss 3.1913 (3.1403)	Arch Hard Loss 3.1913 (3.1403)	Arch Beta Loss 6.0654 (6.0774)	Arch depth Loss -0.0112 (-0.0087)	Prec@(1,5) (23.5%, 53.3%)	
12/22 04:41:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02496	Loss 2.6771 (3.0595)	Arch Loss 3.0622 (3.1186)	Arch Hard Loss 3.0622 (3.1186)	Arch Beta Loss 6.0552 (6.0712)	Arch depth Loss -0.0108 (-0.0092)	Prec@(1,5) (23.5%, 53.7%)	
12/22 04:42:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02496	Loss 2.9021 (3.0513)	Arch Loss 2.8077 (3.0941)	Arch Hard Loss 2.8077 (3.0941)	Arch Beta Loss 6.0450 (6.0664)	Arch depth Loss -0.0127 (-0.0097)	Prec@(1,5) (23.6%, 53.8%)	
12/22 04:42:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  4/159] Final Prec@1 23.6280%
12/22 04:42:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.0459	Prec@(1,5) (23.6%, 54.9%)
12/22 04:42:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.0030	Prec@(1,5) (24.3%, 55.8%)
12/22 04:42:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0009	Prec@(1,5) (24.5%, 56.0%)
12/22 04:43:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 2.9966	Prec@(1,5) (24.8%, 56.2%)
12/22 04:43:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/159] Final Prec@1 24.8080%
12/22 04:43:06午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
12/22 04:43:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 24.8080%
12/22 04:44:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02494	Loss 3.1988 (2.8995)	Arch Loss 3.0006 (2.9714)	Arch Hard Loss 3.0006 (2.9714)	Arch Beta Loss 6.0329 (6.0404)	Arch depth Loss -0.0127 (-0.0123)	Prec@(1,5) (25.9%, 57.8%)	
12/22 04:44:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02494	Loss 3.2088 (2.8852)	Arch Loss 3.2077 (2.9758)	Arch Hard Loss 3.2077 (2.9758)	Arch Beta Loss 6.0199 (6.0336)	Arch depth Loss -0.0166 (-0.0140)	Prec@(1,5) (26.7%, 57.9%)	
12/22 04:45:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02494	Loss 2.8697 (2.8874)	Arch Loss 2.6699 (2.9560)	Arch Hard Loss 2.6699 (2.9560)	Arch Beta Loss 6.0122 (6.0280)	Arch depth Loss -0.0168 (-0.0151)	Prec@(1,5) (26.6%, 57.6%)	
12/22 04:46:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02494	Loss 2.6361 (2.8793)	Arch Loss 2.8170 (2.9357)	Arch Hard Loss 2.8170 (2.9357)	Arch Beta Loss 6.0058 (6.0235)	Arch depth Loss -0.0142 (-0.0152)	Prec@(1,5) (26.8%, 58.1%)	
12/22 04:46:42午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  5/159] Final Prec@1 26.7480%
12/22 04:46:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8729	Prec@(1,5) (27.2%, 59.3%)
12/22 04:46:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8905	Prec@(1,5) (26.9%, 59.1%)
12/22 04:47:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8980	Prec@(1,5) (26.6%, 58.7%)
12/22 04:47:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8916	Prec@(1,5) (26.7%, 58.8%)
12/22 04:47:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/159] Final Prec@1 26.7240%
12/22 04:47:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
12/22 04:47:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 26.7240%
12/22 04:48:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02492	Loss 2.9609 (2.7232)	Arch Loss 3.1007 (2.8378)	Arch Hard Loss 3.1007 (2.8378)	Arch Beta Loss 5.9925 (5.9990)	Arch depth Loss -0.0172 (-0.0155)	Prec@(1,5) (29.4%, 61.8%)	
12/22 04:49:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02492	Loss 2.8668 (2.7402)	Arch Loss 2.7790 (2.8213)	Arch Hard Loss 2.7790 (2.8213)	Arch Beta Loss 5.9802 (5.9929)	Arch depth Loss -0.0189 (-0.0167)	Prec@(1,5) (28.9%, 61.5%)	
12/22 04:49:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02492	Loss 2.9559 (2.7381)	Arch Loss 2.5255 (2.8020)	Arch Hard Loss 2.5255 (2.8020)	Arch Beta Loss 5.9746 (5.9878)	Arch depth Loss -0.0162 (-0.0169)	Prec@(1,5) (29.0%, 61.6%)	
12/22 04:50:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02492	Loss 2.7612 (2.7322)	Arch Loss 2.8827 (2.8025)	Arch Hard Loss 2.8827 (2.8025)	Arch Beta Loss 5.9691 (5.9845)	Arch depth Loss -0.0157 (-0.0167)	Prec@(1,5) (29.2%, 61.7%)	
12/22 04:50:49午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  6/159] Final Prec@1 29.2080%
12/22 04:50:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7783	Prec@(1,5) (29.1%, 61.4%)
12/22 04:51:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7607	Prec@(1,5) (29.6%, 62.0%)
12/22 04:51:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7724	Prec@(1,5) (29.1%, 61.7%)
12/22 04:51:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7763	Prec@(1,5) (29.1%, 61.6%)
12/22 04:51:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/159] Final Prec@1 29.0880%
12/22 04:51:20午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG3_concat=[10, 11])
12/22 04:51:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 29.0880%
12/22 04:52:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02489	Loss 2.8328 (2.6115)	Arch Loss 2.7596 (2.7372)	Arch Hard Loss 2.7596 (2.7372)	Arch Beta Loss 5.9578 (5.9641)	Arch depth Loss -0.0163 (-0.0160)	Prec@(1,5) (31.6%, 64.6%)	
12/22 04:53:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02489	Loss 2.5620 (2.6099)	Arch Loss 2.8017 (2.7276)	Arch Hard Loss 2.8017 (2.7276)	Arch Beta Loss 5.9444 (5.9576)	Arch depth Loss -0.0197 (-0.0172)	Prec@(1,5) (31.8%, 64.7%)	
12/22 04:54:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02489	Loss 2.8226 (2.5970)	Arch Loss 3.3511 (2.7185)	Arch Hard Loss 3.3511 (2.7185)	Arch Beta Loss 5.9378 (5.9525)	Arch depth Loss -0.0212 (-0.0182)	Prec@(1,5) (32.5%, 65.3%)	
12/22 04:54:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02489	Loss 2.6571 (2.5914)	Arch Loss 2.6009 (2.6997)	Arch Hard Loss 2.6009 (2.6997)	Arch Beta Loss 5.9319 (5.9484)	Arch depth Loss -0.0206 (-0.0188)	Prec@(1,5) (32.5%, 65.3%)	
12/22 04:54:53午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  7/159] Final Prec@1 32.5000%
12/22 04:55:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6545	Prec@(1,5) (31.9%, 64.0%)
12/22 04:55:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6451	Prec@(1,5) (32.1%, 64.1%)
12/22 04:55:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6495	Prec@(1,5) (32.0%, 64.2%)
12/22 04:55:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6542	Prec@(1,5) (31.7%, 64.0%)
12/22 04:55:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/159] Final Prec@1 31.7320%
12/22 04:55:25午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
12/22 04:55:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 31.7320%
12/22 04:56:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02485	Loss 2.3722 (2.4693)	Arch Loss 3.0751 (2.6339)	Arch Hard Loss 3.0751 (2.6339)	Arch Beta Loss 5.9175 (5.9241)	Arch depth Loss -0.0221 (-0.0215)	Prec@(1,5) (34.5%, 68.0%)	
12/22 04:57:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02485	Loss 2.0540 (2.4754)	Arch Loss 2.7847 (2.6396)	Arch Hard Loss 2.7847 (2.6396)	Arch Beta Loss 5.9060 (5.9181)	Arch depth Loss -0.0265 (-0.0229)	Prec@(1,5) (34.8%, 67.8%)	
12/22 04:58:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02485	Loss 2.5557 (2.4784)	Arch Loss 2.5918 (2.6350)	Arch Hard Loss 2.5918 (2.6350)	Arch Beta Loss 5.8977 (5.9126)	Arch depth Loss -0.0296 (-0.0246)	Prec@(1,5) (34.9%, 67.8%)	
12/22 04:58:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02485	Loss 2.2586 (2.4755)	Arch Loss 2.7995 (2.6171)	Arch Hard Loss 2.7995 (2.6171)	Arch Beta Loss 5.8913 (5.9084)	Arch depth Loss -0.0303 (-0.0258)	Prec@(1,5) (34.9%, 67.9%)	
12/22 04:58:57午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  8/159] Final Prec@1 34.9600%
12/22 04:59:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.5565	Prec@(1,5) (33.6%, 66.2%)
12/22 04:59:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.5724	Prec@(1,5) (33.4%, 65.8%)
12/22 04:59:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.5888	Prec@(1,5) (33.3%, 65.3%)
12/22 04:59:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5878	Prec@(1,5) (33.2%, 65.5%)
12/22 04:59:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/159] Final Prec@1 33.2000%
12/22 04:59:28午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 04:59:28午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 33.2000%
12/22 05:00:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02481	Loss 2.4773 (2.3754)	Arch Loss 2.7548 (2.5553)	Arch Hard Loss 2.7548 (2.5553)	Arch Beta Loss 5.8838 (5.8875)	Arch depth Loss -0.0308 (-0.0309)	Prec@(1,5) (37.2%, 70.0%)	
12/22 05:01:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02481	Loss 2.3372 (2.3754)	Arch Loss 2.7492 (2.5310)	Arch Hard Loss 2.7492 (2.5310)	Arch Beta Loss 5.8799 (5.8842)	Arch depth Loss -0.0317 (-0.0312)	Prec@(1,5) (37.1%, 69.9%)	
12/22 05:02:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02481	Loss 2.2905 (2.3708)	Arch Loss 2.1385 (2.5287)	Arch Hard Loss 2.1385 (2.5287)	Arch Beta Loss 5.8702 (5.8816)	Arch depth Loss -0.0319 (-0.0314)	Prec@(1,5) (37.3%, 70.0%)	
12/22 05:03:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02481	Loss 2.1349 (2.3700)	Arch Loss 2.5150 (2.5177)	Arch Hard Loss 2.5150 (2.5177)	Arch Beta Loss 5.8648 (5.8783)	Arch depth Loss -0.0308 (-0.0314)	Prec@(1,5) (37.2%, 70.1%)	
12/22 05:03:01午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  9/159] Final Prec@1 37.2360%
12/22 05:03:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4952	Prec@(1,5) (35.0%, 68.2%)
12/22 05:03:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4815	Prec@(1,5) (35.3%, 68.3%)
12/22 05:03:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4926	Prec@(1,5) (35.1%, 68.2%)
12/22 05:03:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4895	Prec@(1,5) (35.1%, 68.0%)
12/22 05:03:32午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/159] Final Prec@1 35.0920%
12/22 05:03:32午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:03:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 35.0920%
12/22 05:04:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02477	Loss 2.5193 (2.2511)	Arch Loss 2.6247 (2.5011)	Arch Hard Loss 2.6247 (2.5011)	Arch Beta Loss 5.8574 (5.8594)	Arch depth Loss -0.0314 (-0.0317)	Prec@(1,5) (39.4%, 72.7%)	
12/22 05:05:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02477	Loss 2.5026 (2.2759)	Arch Loss 2.2629 (2.4716)	Arch Hard Loss 2.2629 (2.4716)	Arch Beta Loss 5.8502 (5.8574)	Arch depth Loss -0.0323 (-0.0316)	Prec@(1,5) (39.1%, 72.2%)	
12/22 05:06:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02477	Loss 2.2833 (2.2817)	Arch Loss 2.2402 (2.4632)	Arch Hard Loss 2.2402 (2.4632)	Arch Beta Loss 5.8431 (5.8540)	Arch depth Loss -0.0329 (-0.0320)	Prec@(1,5) (38.9%, 72.0%)	
12/22 05:07:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02477	Loss 2.4694 (2.2748)	Arch Loss 2.2404 (2.4496)	Arch Hard Loss 2.2404 (2.4496)	Arch Beta Loss 5.8365 (5.8504)	Arch depth Loss -0.0329 (-0.0323)	Prec@(1,5) (39.2%, 72.2%)	
12/22 05:07:03午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 10/159] Final Prec@1 39.1880%
12/22 05:07:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.4085	Prec@(1,5) (36.8%, 69.2%)
12/22 05:07:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3802	Prec@(1,5) (37.0%, 70.0%)
12/22 05:07:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3950	Prec@(1,5) (37.3%, 69.7%)
12/22 05:07:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3883	Prec@(1,5) (37.3%, 69.9%)
12/22 05:07:35午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/159] Final Prec@1 37.3360%
12/22 05:07:35午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:07:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 37.3360%
12/22 05:08:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02472	Loss 2.0133 (2.1838)	Arch Loss 2.7925 (2.4018)	Arch Hard Loss 2.7925 (2.4018)	Arch Beta Loss 5.8353 (5.8359)	Arch depth Loss -0.0327 (-0.0330)	Prec@(1,5) (41.6%, 74.2%)	
12/22 05:09:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02472	Loss 2.5216 (2.1774)	Arch Loss 2.5478 (2.3879)	Arch Hard Loss 2.5478 (2.3879)	Arch Beta Loss 5.8286 (5.8342)	Arch depth Loss -0.0343 (-0.0331)	Prec@(1,5) (41.1%, 74.1%)	
12/22 05:10:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02472	Loss 2.2322 (2.1775)	Arch Loss 2.2222 (2.3740)	Arch Hard Loss 2.2222 (2.3740)	Arch Beta Loss 5.8241 (5.8314)	Arch depth Loss -0.0353 (-0.0336)	Prec@(1,5) (41.6%, 74.1%)	
12/22 05:11:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02472	Loss 2.1141 (2.1837)	Arch Loss 2.3149 (2.3719)	Arch Hard Loss 2.3149 (2.3719)	Arch Beta Loss 5.8195 (5.8291)	Arch depth Loss -0.0349 (-0.0340)	Prec@(1,5) (41.4%, 74.1%)	
12/22 05:11:09午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 11/159] Final Prec@1 41.3720%
12/22 05:11:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.3135	Prec@(1,5) (39.0%, 71.2%)
12/22 05:11:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.2963	Prec@(1,5) (39.3%, 71.6%)
12/22 05:11:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.2857	Prec@(1,5) (39.4%, 71.8%)
12/22 05:11:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.2882	Prec@(1,5) (39.6%, 71.9%)
12/22 05:11:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/159] Final Prec@1 39.5440%
12/22 05:11:40午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:11:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.5440%
12/22 05:12:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02467	Loss 2.0514 (2.0660)	Arch Loss 2.1960 (2.3476)	Arch Hard Loss 2.1960 (2.3476)	Arch Beta Loss 5.8197 (5.8201)	Arch depth Loss -0.0338 (-0.0347)	Prec@(1,5) (43.6%, 76.1%)	
12/22 05:13:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02467	Loss 2.1808 (2.0940)	Arch Loss 2.1190 (2.3474)	Arch Hard Loss 2.1190 (2.3474)	Arch Beta Loss 5.8119 (5.8182)	Arch depth Loss -0.0319 (-0.0341)	Prec@(1,5) (43.1%, 75.9%)	
12/22 05:14:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02467	Loss 2.1009 (2.1061)	Arch Loss 2.5211 (2.3316)	Arch Hard Loss 2.5211 (2.3316)	Arch Beta Loss 5.8012 (5.8146)	Arch depth Loss -0.0317 (-0.0335)	Prec@(1,5) (42.7%, 75.6%)	
12/22 05:15:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02467	Loss 1.8578 (2.1055)	Arch Loss 2.2380 (2.3132)	Arch Hard Loss 2.2380 (2.3132)	Arch Beta Loss 5.7952 (5.8108)	Arch depth Loss -0.0329 (-0.0332)	Prec@(1,5) (42.9%, 75.6%)	
12/22 05:15:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 12/159] Final Prec@1 42.8720%
12/22 05:15:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.2851	Prec@(1,5) (40.5%, 71.9%)
12/22 05:15:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.2840	Prec@(1,5) (39.9%, 72.2%)
12/22 05:15:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.2733	Prec@(1,5) (40.1%, 72.4%)
12/22 05:15:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.2841	Prec@(1,5) (39.8%, 72.2%)
12/22 05:15:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/159] Final Prec@1 39.7960%
12/22 05:15:43午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:15:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 39.7960%
12/22 05:16:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02461	Loss 1.9744 (1.9817)	Arch Loss 2.4165 (2.2578)	Arch Hard Loss 2.4165 (2.2578)	Arch Beta Loss 5.7889 (5.7917)	Arch depth Loss -0.0327 (-0.0329)	Prec@(1,5) (45.0%, 78.5%)	
12/22 05:17:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02461	Loss 1.8992 (2.0374)	Arch Loss 2.1427 (2.2568)	Arch Hard Loss 2.1427 (2.2568)	Arch Beta Loss 5.7793 (5.7870)	Arch depth Loss -0.0349 (-0.0335)	Prec@(1,5) (43.8%, 77.4%)	
12/22 05:18:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02461	Loss 2.0784 (2.0307)	Arch Loss 2.0473 (2.2587)	Arch Hard Loss 2.0473 (2.2587)	Arch Beta Loss 5.7740 (5.7836)	Arch depth Loss -0.0320 (-0.0333)	Prec@(1,5) (44.2%, 77.4%)	
12/22 05:19:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02461	Loss 1.8806 (2.0301)	Arch Loss 1.8136 (2.2557)	Arch Hard Loss 1.8136 (2.2557)	Arch Beta Loss 5.7691 (5.7809)	Arch depth Loss -0.0333 (-0.0331)	Prec@(1,5) (44.4%, 77.3%)	
12/22 05:19:15午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 13/159] Final Prec@1 44.3720%
12/22 05:19:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.2038	Prec@(1,5) (42.3%, 73.5%)
12/22 05:19:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.2348	Prec@(1,5) (41.2%, 72.8%)
12/22 05:19:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.2119	Prec@(1,5) (41.8%, 73.5%)
12/22 05:19:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.2091	Prec@(1,5) (41.9%, 73.6%)
12/22 05:19:47午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/159] Final Prec@1 41.8480%
12/22 05:19:47午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 8), ('max_pool_3x3', 6)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:19:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.8480%
12/22 05:20:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02455	Loss 1.9785 (1.9268)	Arch Loss 2.2086 (2.2620)	Arch Hard Loss 2.2086 (2.2620)	Arch Beta Loss 5.7624 (5.7658)	Arch depth Loss -0.0345 (-0.0339)	Prec@(1,5) (47.4%, 79.1%)	
12/22 05:21:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02455	Loss 1.9994 (1.9464)	Arch Loss 2.2293 (2.2467)	Arch Hard Loss 2.2293 (2.2467)	Arch Beta Loss 5.7555 (5.7627)	Arch depth Loss -0.0328 (-0.0338)	Prec@(1,5) (47.1%, 78.7%)	
12/22 05:22:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02455	Loss 2.2511 (1.9500)	Arch Loss 2.2401 (2.2387)	Arch Hard Loss 2.2401 (2.2387)	Arch Beta Loss 5.7484 (5.7588)	Arch depth Loss -0.0312 (-0.0329)	Prec@(1,5) (46.9%, 78.7%)	
12/22 05:23:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02455	Loss 1.9002 (1.9587)	Arch Loss 2.2853 (2.2238)	Arch Hard Loss 2.2853 (2.2238)	Arch Beta Loss 5.7472 (5.7562)	Arch depth Loss -0.0296 (-0.0323)	Prec@(1,5) (46.5%, 78.6%)	
12/22 05:23:20午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 14/159] Final Prec@1 46.5240%
12/22 05:23:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.2272	Prec@(1,5) (41.7%, 73.2%)
12/22 05:23:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.2491	Prec@(1,5) (41.0%, 73.1%)
12/22 05:23:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.2497	Prec@(1,5) (40.7%, 73.0%)
12/22 05:23:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.2500	Prec@(1,5) (40.7%, 73.1%)
12/22 05:23:51午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/159] Final Prec@1 40.7160%
12/22 05:23:51午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:23:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 41.8480%
12/22 05:24:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02448	Loss 2.0897 (1.8577)	Arch Loss 2.1498 (2.1959)	Arch Hard Loss 2.1498 (2.1959)	Arch Beta Loss 5.7405 (5.7440)	Arch depth Loss -0.0281 (-0.0295)	Prec@(1,5) (48.7%, 80.1%)	
12/22 05:25:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02448	Loss 1.7346 (1.8666)	Arch Loss 2.2043 (2.1913)	Arch Hard Loss 2.2043 (2.1913)	Arch Beta Loss 5.7325 (5.7397)	Arch depth Loss -0.0259 (-0.0284)	Prec@(1,5) (48.5%, 80.0%)	
12/22 05:26:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02448	Loss 2.0628 (1.8731)	Arch Loss 2.0972 (2.1882)	Arch Hard Loss 2.0972 (2.1882)	Arch Beta Loss 5.7275 (5.7366)	Arch depth Loss -0.0240 (-0.0272)	Prec@(1,5) (48.4%, 80.1%)	
12/22 05:27:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02448	Loss 1.7884 (1.8852)	Arch Loss 1.8106 (2.1803)	Arch Hard Loss 1.8106 (2.1803)	Arch Beta Loss 5.7215 (5.7338)	Arch depth Loss -0.0244 (-0.0266)	Prec@(1,5) (48.1%, 79.9%)	
12/22 05:27:23午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 15/159] Final Prec@1 48.1120%
12/22 05:27:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1585	Prec@(1,5) (42.4%, 75.4%)
12/22 05:27:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.1387	Prec@(1,5) (42.7%, 75.5%)
12/22 05:27:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1536	Prec@(1,5) (42.3%, 75.2%)
12/22 05:27:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.1513	Prec@(1,5) (42.3%, 75.4%)
12/22 05:27:54午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/159] Final Prec@1 42.2720%
12/22 05:27:54午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:27:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.2720%
12/22 05:28:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.02441	Loss 1.5700 (1.7847)	Arch Loss 1.7623 (2.1319)	Arch Hard Loss 1.7623 (2.1319)	Arch Beta Loss 5.7146 (5.7170)	Arch depth Loss -0.0219 (-0.0219)	Prec@(1,5) (50.4%, 81.8%)	
12/22 05:29:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.02441	Loss 1.9177 (1.8080)	Arch Loss 2.0766 (2.1390)	Arch Hard Loss 2.0766 (2.1390)	Arch Beta Loss 5.7072 (5.7139)	Arch depth Loss -0.0186 (-0.0211)	Prec@(1,5) (49.7%, 81.5%)	
12/22 05:30:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.02441	Loss 1.8917 (1.8243)	Arch Loss 2.2091 (2.1576)	Arch Hard Loss 2.2091 (2.1576)	Arch Beta Loss 5.7026 (5.7106)	Arch depth Loss -0.0172 (-0.0203)	Prec@(1,5) (49.5%, 81.3%)	
12/22 05:31:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.02441	Loss 2.0520 (1.8288)	Arch Loss 1.9297 (2.1416)	Arch Hard Loss 1.9297 (2.1416)	Arch Beta Loss 5.6970 (5.7080)	Arch depth Loss -0.0141 (-0.0192)	Prec@(1,5) (49.3%, 81.1%)	
12/22 05:31:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 16/159] Final Prec@1 49.3480%
12/22 05:31:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1308	Prec@(1,5) (43.5%, 74.3%)
12/22 05:31:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.1079	Prec@(1,5) (43.7%, 75.3%)
12/22 05:31:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.1162	Prec@(1,5) (43.5%, 75.4%)
12/22 05:31:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.1063	Prec@(1,5) (43.8%, 75.7%)
12/22 05:31:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/159] Final Prec@1 43.7800%
12/22 05:31:56午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:31:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.7800%
12/22 05:32:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.02434	Loss 1.6074 (1.7209)	Arch Loss 1.9900 (2.0996)	Arch Hard Loss 1.9900 (2.0996)	Arch Beta Loss 5.6902 (5.6933)	Arch depth Loss -0.0124 (-0.0135)	Prec@(1,5) (51.7%, 82.9%)	
12/22 05:33:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.02434	Loss 1.8541 (1.7559)	Arch Loss 1.9810 (2.1073)	Arch Hard Loss 1.9810 (2.1073)	Arch Beta Loss 5.6862 (5.6909)	Arch depth Loss -0.0062 (-0.0114)	Prec@(1,5) (51.1%, 82.3%)	
12/22 05:34:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.02434	Loss 1.9143 (1.7757)	Arch Loss 1.7048 (2.1259)	Arch Hard Loss 1.7048 (2.1259)	Arch Beta Loss 5.6789 (5.6880)	Arch depth Loss -0.0057 (-0.0095)	Prec@(1,5) (50.5%, 81.9%)	
12/22 05:35:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.02434	Loss 1.5836 (1.7836)	Arch Loss 2.0365 (2.1197)	Arch Hard Loss 2.0365 (2.1197)	Arch Beta Loss 5.6745 (5.6853)	Arch depth Loss -0.0041 (-0.0086)	Prec@(1,5) (50.1%, 81.9%)	
12/22 05:35:28午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 17/159] Final Prec@1 50.1000%
12/22 05:35:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0418	Prec@(1,5) (45.4%, 77.1%)
12/22 05:35:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0359	Prec@(1,5) (45.5%, 77.0%)
12/22 05:35:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0400	Prec@(1,5) (45.4%, 76.8%)
12/22 05:35:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0437	Prec@(1,5) (45.1%, 76.7%)
12/22 05:35:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/159] Final Prec@1 45.0760%
12/22 05:35:59午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:35:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.0760%
12/22 05:36:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.02426	Loss 1.5375 (1.6765)	Arch Loss 2.1097 (2.0566)	Arch Hard Loss 2.1097 (2.0566)	Arch Beta Loss 5.6697 (5.6718)	Arch depth Loss -0.0001 (-0.0014)	Prec@(1,5) (52.8%, 83.6%)	
12/22 05:37:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.02426	Loss 1.4809 (1.7182)	Arch Loss 1.8950 (2.0785)	Arch Hard Loss 1.8950 (2.0785)	Arch Beta Loss 5.6613 (5.6683)	Arch depth Loss 0.0024 (-0.0001)	Prec@(1,5) (51.6%, 82.9%)	
12/22 05:38:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.02426	Loss 1.5960 (1.7226)	Arch Loss 2.2006 (2.0828)	Arch Hard Loss 2.2006 (2.0828)	Arch Beta Loss 5.6595 (5.6660)	Arch depth Loss 0.0053 (0.0014)	Prec@(1,5) (51.6%, 82.7%)	
12/22 05:39:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.02426	Loss 1.8715 (1.7314)	Arch Loss 1.5484 (2.0711)	Arch Hard Loss 1.5484 (2.0711)	Arch Beta Loss 5.6564 (5.6640)	Arch depth Loss 0.0079 (0.0027)	Prec@(1,5) (51.6%, 82.6%)	
12/22 05:39:32午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 18/159] Final Prec@1 51.6200%
12/22 05:39:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.1159	Prec@(1,5) (43.9%, 75.7%)
12/22 05:39:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.1057	Prec@(1,5) (44.5%, 75.9%)
12/22 05:39:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.1036	Prec@(1,5) (44.8%, 75.8%)
12/22 05:40:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.1151	Prec@(1,5) (44.3%, 75.8%)
12/22 05:40:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/159] Final Prec@1 44.3200%
12/22 05:40:06午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 05:40:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.0760%
12/22 05:41:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.02417	Loss 1.2901 (1.6109)	Arch Loss 2.3225 (2.0567)	Arch Hard Loss 2.3225 (2.0567)	Arch Beta Loss 5.6463 (5.6512)	Arch depth Loss 0.0145 (0.0107)	Prec@(1,5) (54.2%, 84.7%)	
12/22 05:41:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.02417	Loss 1.8517 (1.6497)	Arch Loss 2.2308 (2.0656)	Arch Hard Loss 2.2308 (2.0656)	Arch Beta Loss 5.6432 (5.6480)	Arch depth Loss 0.0181 (0.0133)	Prec@(1,5) (53.4%, 84.3%)	
12/22 05:42:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.02417	Loss 2.0880 (1.6745)	Arch Loss 1.7822 (2.0468)	Arch Hard Loss 1.7822 (2.0468)	Arch Beta Loss 5.6380 (5.6456)	Arch depth Loss 0.0207 (0.0153)	Prec@(1,5) (53.0%, 83.7%)	
12/22 05:43:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.02417	Loss 1.8452 (1.6850)	Arch Loss 2.0527 (2.0393)	Arch Hard Loss 2.0527 (2.0393)	Arch Beta Loss 5.6327 (5.6432)	Arch depth Loss 0.0245 (0.0169)	Prec@(1,5) (52.7%, 83.5%)	
12/22 05:43:39午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 19/159] Final Prec@1 52.6880%
12/22 05:43:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0934	Prec@(1,5) (44.9%, 76.1%)
12/22 05:43:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.1005	Prec@(1,5) (44.9%, 75.9%)
12/22 05:44:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0826	Prec@(1,5) (45.2%, 76.0%)
12/22 05:44:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0785	Prec@(1,5) (45.2%, 76.2%)
12/22 05:44:11午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/159] Final Prec@1 45.1720%
12/22 05:44:11午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:44:11午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1720%
12/22 05:45:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.02409	Loss 1.8636 (1.5987)	Arch Loss 1.9098 (2.0091)	Arch Hard Loss 1.9098 (2.0091)	Arch Beta Loss 5.6277 (5.6303)	Arch depth Loss 0.0261 (0.0252)	Prec@(1,5) (54.9%, 84.8%)	
12/22 05:46:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.02409	Loss 1.5330 (1.6115)	Arch Loss 2.5226 (2.0262)	Arch Hard Loss 2.5226 (2.0262)	Arch Beta Loss 5.6222 (5.6273)	Arch depth Loss 0.0294 (0.0265)	Prec@(1,5) (54.4%, 84.7%)	
12/22 05:47:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.02409	Loss 1.2727 (1.6230)	Arch Loss 1.7383 (2.0190)	Arch Hard Loss 1.7383 (2.0190)	Arch Beta Loss 5.6161 (5.6245)	Arch depth Loss 0.0290 (0.0275)	Prec@(1,5) (54.1%, 84.5%)	
12/22 05:47:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.02409	Loss 1.8263 (1.6442)	Arch Loss 1.8690 (2.0125)	Arch Hard Loss 1.8690 (2.0125)	Arch Beta Loss 5.6148 (5.6223)	Arch depth Loss 0.0323 (0.0282)	Prec@(1,5) (53.8%, 84.1%)	
12/22 05:47:52午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 20/159] Final Prec@1 53.8400%
12/22 05:48:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9473	Prec@(1,5) (48.6%, 78.9%)
12/22 05:48:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9500	Prec@(1,5) (47.9%, 78.8%)
12/22 05:48:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9542	Prec@(1,5) (47.6%, 78.7%)
12/22 05:48:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9636	Prec@(1,5) (47.4%, 78.5%)
12/22 05:48:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/159] Final Prec@1 47.3760%
12/22 05:48:24午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:48:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.3760%
12/22 05:49:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.02399	Loss 1.5082 (1.5320)	Arch Loss 2.3521 (2.0108)	Arch Hard Loss 2.3521 (2.0108)	Arch Beta Loss 5.6069 (5.6112)	Arch depth Loss 0.0373 (0.0357)	Prec@(1,5) (56.5%, 86.5%)	
12/22 05:50:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.02399	Loss 1.7410 (1.5681)	Arch Loss 2.2987 (2.0218)	Arch Hard Loss 2.2987 (2.0218)	Arch Beta Loss 5.6014 (5.6082)	Arch depth Loss 0.0455 (0.0390)	Prec@(1,5) (55.3%, 85.5%)	
12/22 05:51:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.02399	Loss 1.6710 (1.5885)	Arch Loss 1.7421 (2.0041)	Arch Hard Loss 1.7421 (2.0041)	Arch Beta Loss 5.5971 (5.6054)	Arch depth Loss 0.0461 (0.0411)	Prec@(1,5) (54.9%, 85.1%)	
12/22 05:52:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.02399	Loss 1.7384 (1.5993)	Arch Loss 1.8541 (2.0024)	Arch Hard Loss 1.8541 (2.0024)	Arch Beta Loss 5.5939 (5.6030)	Arch depth Loss 0.0497 (0.0427)	Prec@(1,5) (54.9%, 84.9%)	
12/22 05:52:04午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 21/159] Final Prec@1 54.8840%
12/22 05:52:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 1.9631	Prec@(1,5) (47.8%, 77.6%)
12/22 05:52:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 1.9694	Prec@(1,5) (47.5%, 78.1%)
12/22 05:52:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 1.9828	Prec@(1,5) (47.0%, 77.9%)
12/22 05:52:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 1.9805	Prec@(1,5) (47.1%, 78.0%)
12/22 05:52:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/159] Final Prec@1 47.0880%
12/22 05:52:36午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:52:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.3760%
12/22 05:53:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.0239	Loss 1.6203 (1.4860)	Arch Loss 2.4970 (2.0210)	Arch Hard Loss 2.4970 (2.0210)	Arch Beta Loss 5.5894 (5.5919)	Arch depth Loss 0.0579 (0.0539)	Prec@(1,5) (57.8%, 87.0%)	
12/22 05:54:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.0239	Loss 1.6090 (1.5318)	Arch Loss 1.7899 (1.9925)	Arch Hard Loss 1.7899 (1.9925)	Arch Beta Loss 5.5867 (5.5903)	Arch depth Loss 0.0573 (0.0555)	Prec@(1,5) (56.5%, 86.1%)	
12/22 05:55:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.0239	Loss 1.2496 (1.5485)	Arch Loss 2.2531 (1.9884)	Arch Hard Loss 2.2531 (1.9884)	Arch Beta Loss 5.5801 (5.5878)	Arch depth Loss 0.0614 (0.0567)	Prec@(1,5) (56.0%, 85.8%)	
12/22 05:56:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.0239	Loss 1.7332 (1.5623)	Arch Loss 1.8531 (1.9792)	Arch Hard Loss 1.8531 (1.9792)	Arch Beta Loss 5.5811 (5.5862)	Arch depth Loss 0.0630 (0.0581)	Prec@(1,5) (55.5%, 85.6%)	
12/22 05:56:09午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 22/159] Final Prec@1 55.5080%
12/22 05:56:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9468	Prec@(1,5) (47.4%, 79.0%)
12/22 05:56:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 1.9542	Prec@(1,5) (47.0%, 79.0%)
12/22 05:56:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9485	Prec@(1,5) (47.4%, 79.1%)
12/22 05:56:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 1.9529	Prec@(1,5) (47.3%, 79.0%)
12/22 05:56:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/159] Final Prec@1 47.3400%
12/22 05:56:40午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:56:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 47.3760%
12/22 05:57:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0238	Loss 1.5477 (1.4410)	Arch Loss 1.7505 (1.9610)	Arch Hard Loss 1.7505 (1.9610)	Arch Beta Loss 5.5795 (5.5793)	Arch depth Loss 0.0674 (0.0649)	Prec@(1,5) (58.3%, 87.9%)	
12/22 05:58:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0238	Loss 1.4403 (1.4887)	Arch Loss 2.2172 (1.9606)	Arch Hard Loss 2.2172 (1.9606)	Arch Beta Loss 5.5715 (5.5777)	Arch depth Loss 0.0718 (0.0672)	Prec@(1,5) (57.9%, 86.6%)	
12/22 05:59:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0238	Loss 1.6478 (1.5112)	Arch Loss 1.7394 (1.9720)	Arch Hard Loss 1.7394 (1.9720)	Arch Beta Loss 5.5744 (5.5762)	Arch depth Loss 0.0739 (0.0693)	Prec@(1,5) (57.0%, 86.4%)	
12/22 06:00:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0238	Loss 1.5455 (1.5195)	Arch Loss 1.9897 (1.9667)	Arch Hard Loss 1.9897 (1.9667)	Arch Beta Loss 5.5714 (5.5756)	Arch depth Loss 0.0757 (0.0705)	Prec@(1,5) (56.7%, 86.2%)	
12/22 06:00:11午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 23/159] Final Prec@1 56.7160%
12/22 06:00:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9418	Prec@(1,5) (48.1%, 78.5%)
12/22 06:00:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9340	Prec@(1,5) (48.2%, 79.0%)
12/22 06:00:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9421	Prec@(1,5) (48.2%, 78.9%)
12/22 06:00:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9460	Prec@(1,5) (48.1%, 79.0%)
12/22 06:00:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/159] Final Prec@1 48.1080%
12/22 06:00:43午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:00:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.1080%
12/22 06:01:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.02369	Loss 1.2204 (1.4252)	Arch Loss 2.2703 (1.9128)	Arch Hard Loss 2.2703 (1.9128)	Arch Beta Loss 5.5703 (5.5711)	Arch depth Loss 0.0773 (0.0783)	Prec@(1,5) (59.4%, 87.7%)	
12/22 06:02:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.02369	Loss 1.4867 (1.4562)	Arch Loss 2.2137 (1.9403)	Arch Hard Loss 2.2137 (1.9403)	Arch Beta Loss 5.5682 (5.5703)	Arch depth Loss 0.0808 (0.0784)	Prec@(1,5) (58.8%, 87.2%)	
12/22 06:03:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.02369	Loss 1.8185 (1.4720)	Arch Loss 1.7114 (1.9399)	Arch Hard Loss 1.7114 (1.9399)	Arch Beta Loss 5.5635 (5.5690)	Arch depth Loss 0.0845 (0.0800)	Prec@(1,5) (58.1%, 86.8%)	
12/22 06:04:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.02369	Loss 1.3871 (1.4867)	Arch Loss 1.8019 (1.9482)	Arch Hard Loss 1.8019 (1.9482)	Arch Beta Loss 5.5594 (5.5670)	Arch depth Loss 0.0923 (0.0820)	Prec@(1,5) (57.7%, 86.7%)	
12/22 06:04:21午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 24/159] Final Prec@1 57.7240%
12/22 06:04:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.0108	Prec@(1,5) (46.3%, 78.9%)
12/22 06:04:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 1.9952	Prec@(1,5) (47.2%, 78.9%)
12/22 06:04:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.0029	Prec@(1,5) (46.9%, 78.4%)
12/22 06:04:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 1.9956	Prec@(1,5) (47.0%, 78.3%)
12/22 06:04:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/159] Final Prec@1 47.0000%
12/22 06:04:53午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('avg_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:04:53午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.1080%
12/22 06:05:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.02358	Loss 1.6046 (1.4091)	Arch Loss 1.9959 (1.9060)	Arch Hard Loss 1.9959 (1.9060)	Arch Beta Loss 5.5559 (5.5571)	Arch depth Loss 0.0947 (0.0927)	Prec@(1,5) (60.1%, 88.2%)	
12/22 06:06:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.02358	Loss 1.6508 (1.4324)	Arch Loss 2.3720 (1.9127)	Arch Hard Loss 2.3720 (1.9127)	Arch Beta Loss 5.5545 (5.5566)	Arch depth Loss 0.0974 (0.0943)	Prec@(1,5) (59.0%, 87.7%)	
12/22 06:07:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.02358	Loss 1.2719 (1.4458)	Arch Loss 1.4222 (1.9173)	Arch Hard Loss 1.4222 (1.9173)	Arch Beta Loss 5.5519 (5.5552)	Arch depth Loss 0.1005 (0.0961)	Prec@(1,5) (58.6%, 87.4%)	
12/22 06:08:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.02358	Loss 1.1583 (1.4550)	Arch Loss 1.6349 (1.9189)	Arch Hard Loss 1.6349 (1.9189)	Arch Beta Loss 5.5491 (5.5539)	Arch depth Loss 0.1030 (0.0975)	Prec@(1,5) (58.4%, 87.4%)	
12/22 06:08:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 25/159] Final Prec@1 58.3840%
12/22 06:08:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9099	Prec@(1,5) (48.4%, 79.7%)
12/22 06:08:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9087	Prec@(1,5) (49.0%, 79.5%)
12/22 06:08:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8906	Prec@(1,5) (49.1%, 79.7%)
12/22 06:08:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8925	Prec@(1,5) (48.9%, 79.7%)
12/22 06:08:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/159] Final Prec@1 48.8640%
12/22 06:08:58午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:08:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 48.8640%
12/22 06:09:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.02347	Loss 1.8616 (1.3664)	Arch Loss 1.6721 (1.8430)	Arch Hard Loss 1.6721 (1.8430)	Arch Beta Loss 5.5455 (5.5470)	Arch depth Loss 0.1037 (0.1029)	Prec@(1,5) (60.3%, 88.7%)	
12/22 06:10:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.02347	Loss 1.1694 (1.3900)	Arch Loss 2.3204 (1.8827)	Arch Hard Loss 2.3204 (1.8827)	Arch Beta Loss 5.5427 (5.5459)	Arch depth Loss 0.1106 (0.1051)	Prec@(1,5) (59.6%, 88.5%)	
12/22 06:11:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.02347	Loss 1.2777 (1.3987)	Arch Loss 1.6972 (1.8913)	Arch Hard Loss 1.6972 (1.8913)	Arch Beta Loss 5.5426 (5.5446)	Arch depth Loss 0.1151 (0.1076)	Prec@(1,5) (59.2%, 88.3%)	
12/22 06:12:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.02347	Loss 1.2591 (1.4209)	Arch Loss 2.0224 (1.8971)	Arch Hard Loss 2.0224 (1.8971)	Arch Beta Loss 5.5410 (5.5439)	Arch depth Loss 0.1175 (0.1099)	Prec@(1,5) (58.7%, 87.9%)	
12/22 06:12:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 26/159] Final Prec@1 58.7400%
12/22 06:12:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.8644	Prec@(1,5) (49.6%, 80.2%)
12/22 06:12:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.8653	Prec@(1,5) (49.5%, 80.1%)
12/22 06:12:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.8722	Prec@(1,5) (49.3%, 80.1%)
12/22 06:13:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.8804	Prec@(1,5) (49.2%, 79.9%)
12/22 06:13:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/159] Final Prec@1 49.2440%
12/22 06:13:02午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:13:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.2440%
12/22 06:14:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.02335	Loss 1.0856 (1.3194)	Arch Loss 2.2072 (1.9144)	Arch Hard Loss 2.2072 (1.9144)	Arch Beta Loss 5.5361 (5.5387)	Arch depth Loss 0.1201 (0.1182)	Prec@(1,5) (61.4%, 89.4%)	
12/22 06:14:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.02335	Loss 1.6201 (1.3656)	Arch Loss 1.5557 (1.9009)	Arch Hard Loss 1.5557 (1.9009)	Arch Beta Loss 5.5274 (5.5348)	Arch depth Loss 0.1221 (0.1200)	Prec@(1,5) (60.4%, 88.7%)	
12/22 06:15:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.02335	Loss 1.2815 (1.3778)	Arch Loss 2.0820 (1.8989)	Arch Hard Loss 2.0820 (1.8989)	Arch Beta Loss 5.5251 (5.5322)	Arch depth Loss 0.1284 (0.1215)	Prec@(1,5) (59.9%, 88.5%)	
12/22 06:16:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.02335	Loss 1.2688 (1.3949)	Arch Loss 1.6583 (1.8954)	Arch Hard Loss 1.6583 (1.8954)	Arch Beta Loss 5.5211 (5.5301)	Arch depth Loss 0.1321 (0.1233)	Prec@(1,5) (59.6%, 88.3%)	
12/22 06:16:41午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 27/159] Final Prec@1 59.5600%
12/22 06:16:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8916	Prec@(1,5) (49.5%, 79.6%)
12/22 06:16:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8752	Prec@(1,5) (49.9%, 79.9%)
12/22 06:17:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8737	Prec@(1,5) (49.9%, 80.1%)
12/22 06:17:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8696	Prec@(1,5) (50.0%, 80.1%)
12/22 06:17:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/159] Final Prec@1 50.0200%
12/22 06:17:13午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:17:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.0200%
12/22 06:18:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.02323	Loss 1.3607 (1.3039)	Arch Loss 1.7063 (1.8433)	Arch Hard Loss 1.7063 (1.8433)	Arch Beta Loss 5.5177 (5.5192)	Arch depth Loss 0.1336 (0.1329)	Prec@(1,5) (61.7%, 89.9%)	
12/22 06:19:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.02323	Loss 1.2125 (1.3400)	Arch Loss 1.5957 (1.8622)	Arch Hard Loss 1.5957 (1.8622)	Arch Beta Loss 5.5138 (5.5173)	Arch depth Loss 0.1387 (0.1344)	Prec@(1,5) (61.0%, 89.3%)	
12/22 06:19:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.02323	Loss 1.4473 (1.3445)	Arch Loss 2.0329 (1.8680)	Arch Hard Loss 2.0329 (1.8680)	Arch Beta Loss 5.5101 (5.5158)	Arch depth Loss 0.1410 (0.1360)	Prec@(1,5) (61.0%, 89.2%)	
12/22 06:20:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.02323	Loss 1.2299 (1.3703)	Arch Loss 1.5844 (1.8764)	Arch Hard Loss 1.5844 (1.8764)	Arch Beta Loss 5.5060 (5.5137)	Arch depth Loss 0.1457 (0.1379)	Prec@(1,5) (60.3%, 88.7%)	
12/22 06:20:49午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 28/159] Final Prec@1 60.3200%
12/22 06:20:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.8691	Prec@(1,5) (49.5%, 80.6%)
12/22 06:21:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.8904	Prec@(1,5) (49.4%, 80.1%)
12/22 06:21:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.8793	Prec@(1,5) (49.7%, 80.3%)
12/22 06:21:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8730	Prec@(1,5) (49.7%, 80.3%)
12/22 06:21:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/159] Final Prec@1 49.7400%
12/22 06:21:21午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 10), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:21:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.0200%
12/22 06:22:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.02311	Loss 1.2688 (1.2681)	Arch Loss 1.6904 (1.8711)	Arch Hard Loss 1.6904 (1.8711)	Arch Beta Loss 5.5057 (5.5053)	Arch depth Loss 0.1456 (0.1461)	Prec@(1,5) (63.5%, 90.4%)	
12/22 06:23:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.02311	Loss 1.1599 (1.2939)	Arch Loss 1.5980 (1.8862)	Arch Hard Loss 1.5980 (1.8862)	Arch Beta Loss 5.5061 (5.5061)	Arch depth Loss 0.1531 (0.1483)	Prec@(1,5) (62.6%, 89.9%)	
12/22 06:24:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.02311	Loss 1.3489 (1.3197)	Arch Loss 2.0180 (1.8735)	Arch Hard Loss 2.0180 (1.8735)	Arch Beta Loss 5.5021 (5.5054)	Arch depth Loss 0.1548 (0.1504)	Prec@(1,5) (61.8%, 89.5%)	
12/22 06:24:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.02311	Loss 1.2458 (1.3341)	Arch Loss 1.9546 (1.8678)	Arch Hard Loss 1.9546 (1.8678)	Arch Beta Loss 5.4992 (5.5043)	Arch depth Loss 0.1565 (0.1517)	Prec@(1,5) (61.3%, 89.3%)	
12/22 06:24:56午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 29/159] Final Prec@1 61.3480%
12/22 06:25:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8489	Prec@(1,5) (50.6%, 80.4%)
12/22 06:25:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8414	Prec@(1,5) (50.9%, 80.9%)
12/22 06:25:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8522	Prec@(1,5) (50.7%, 80.7%)
12/22 06:25:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8442	Prec@(1,5) (50.6%, 80.9%)
12/22 06:25:27午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/159] Final Prec@1 50.6080%
12/22 06:25:27午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:25:28午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.6080%
12/22 06:25:28午前 searchEvalStage_curriculum_trainer.py:151 [INFO] --> Curriculum part A finished. Part B begins!
12/22 06:26:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.02298	Loss 1.3576 (1.2551)	Arch Loss 6.7584 (7.1221)	Arch Hard Loss 1.5693 (1.8092)	Arch Beta Loss 5.1891 (5.3130)	Arch depth Loss 0.1100 (0.1333)	Prec@(1,5) (63.3%, 90.6%)	
12/22 06:27:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.02298	Loss 1.4634 (1.2482)	Arch Loss 7.1811 (7.0451)	Arch Hard Loss 2.1568 (1.8380)	Arch Beta Loss 5.0243 (5.2071)	Arch depth Loss 0.0685 (0.1110)	Prec@(1,5) (63.7%, 90.4%)	
12/22 06:28:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.02298	Loss 1.3986 (1.2763)	Arch Loss 6.5567 (6.9595)	Arch Hard Loss 1.6570 (1.8349)	Arch Beta Loss 4.8997 (5.1245)	Arch depth Loss 0.0278 (0.0898)	Prec@(1,5) (62.8%, 89.8%)	
12/22 06:29:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.02298	Loss 1.5128 (1.3053)	Arch Loss 7.0335 (6.9025)	Arch Hard Loss 2.2287 (1.8412)	Arch Beta Loss 4.8048 (5.0613)	Arch depth Loss -0.0061 (0.0716)	Prec@(1,5) (62.0%, 89.6%)	
12/22 06:29:03午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 30/159] Final Prec@1 61.9560%
12/22 06:29:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8720	Prec@(1,5) (50.6%, 80.2%)
12/22 06:29:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8809	Prec@(1,5) (50.2%, 80.0%)
12/22 06:29:27午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8877	Prec@(1,5) (50.0%, 79.9%)
12/22 06:29:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8839	Prec@(1,5) (49.9%, 80.0%)
12/22 06:29:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/159] Final Prec@1 49.9520%
12/22 06:29:34午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 5])
12/22 06:29:35午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.6080%
12/22 06:30:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.02284	Loss 1.2299 (1.2419)	Arch Loss 6.4490 (6.5758)	Arch Hard Loss 1.7379 (1.8197)	Arch Beta Loss 4.7112 (4.7562)	Arch depth Loss -0.0419 (-0.0251)	Prec@(1,5) (64.4%, 90.0%)	
12/22 06:31:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.02284	Loss 1.0641 (1.2487)	Arch Loss 6.3603 (6.5543)	Arch Hard Loss 1.7320 (1.8420)	Arch Beta Loss 4.6282 (4.7123)	Arch depth Loss -0.0749 (-0.0419)	Prec@(1,5) (63.6%, 90.4%)	
12/22 06:32:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.02284	Loss 1.4676 (1.2739)	Arch Loss 6.6029 (6.5141)	Arch Hard Loss 2.0500 (1.8427)	Arch Beta Loss 4.5528 (4.6714)	Arch depth Loss -0.1012 (-0.0574)	Prec@(1,5) (63.0%, 90.0%)	
12/22 06:33:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.02284	Loss 1.6069 (1.2926)	Arch Loss 6.2464 (6.4731)	Arch Hard Loss 1.7559 (1.8363)	Arch Beta Loss 4.4905 (4.6368)	Arch depth Loss -0.1257 (-0.0704)	Prec@(1,5) (62.6%, 89.7%)	
12/22 06:33:06午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 31/159] Final Prec@1 62.6440%
12/22 06:33:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8214	Prec@(1,5) (51.6%, 80.6%)
12/22 06:33:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8317	Prec@(1,5) (51.3%, 80.5%)
12/22 06:33:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8416	Prec@(1,5) (50.9%, 80.3%)
12/22 06:33:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8467	Prec@(1,5) (50.6%, 80.3%)
12/22 06:33:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/159] Final Prec@1 50.5880%
12/22 06:33:38午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 06:33:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.6080%
12/22 06:34:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.02271	Loss 1.6718 (1.2298)	Arch Loss 5.8638 (6.2637)	Arch Hard Loss 1.4399 (1.8075)	Arch Beta Loss 4.4238 (4.4561)	Arch depth Loss -0.1505 (-0.1384)	Prec@(1,5) (64.2%, 90.7%)	
12/22 06:35:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.02271	Loss 1.1682 (1.2523)	Arch Loss 6.3328 (6.2403)	Arch Hard Loss 1.9703 (1.8159)	Arch Beta Loss 4.3626 (4.4244)	Arch depth Loss -0.1731 (-0.1504)	Prec@(1,5) (63.7%, 90.4%)	
12/22 06:36:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.02271	Loss 1.1631 (1.2610)	Arch Loss 6.1131 (6.2164)	Arch Hard Loss 1.8078 (1.8222)	Arch Beta Loss 4.3053 (4.3942)	Arch depth Loss -0.1965 (-0.1620)	Prec@(1,5) (63.4%, 90.3%)	
12/22 06:37:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.02271	Loss 1.4159 (1.2702)	Arch Loss 6.1442 (6.1841)	Arch Hard Loss 1.8889 (1.8163)	Arch Beta Loss 4.2554 (4.3678)	Arch depth Loss -0.2136 (-0.1720)	Prec@(1,5) (63.0%, 90.3%)	
12/22 06:37:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 32/159] Final Prec@1 62.9640%
12/22 06:37:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8354	Prec@(1,5) (51.2%, 81.6%)
12/22 06:37:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8258	Prec@(1,5) (51.5%, 81.5%)
12/22 06:37:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8219	Prec@(1,5) (51.4%, 81.5%)
12/22 06:37:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8192	Prec@(1,5) (51.4%, 81.5%)
12/22 06:37:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/159] Final Prec@1 51.4320%
12/22 06:37:43午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 06:37:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
12/22 06:38:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.02257	Loss 1.3533 (1.1792)	Arch Loss 6.0143 (6.0425)	Arch Hard Loss 1.8115 (1.8140)	Arch Beta Loss 4.2028 (4.2284)	Arch depth Loss -0.2307 (-0.2221)	Prec@(1,5) (65.1%, 91.6%)	
12/22 06:39:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.02257	Loss 1.1300 (1.2208)	Arch Loss 5.5683 (6.0049)	Arch Hard Loss 1.4151 (1.8019)	Arch Beta Loss 4.1532 (4.2030)	Arch depth Loss -0.2464 (-0.2306)	Prec@(1,5) (64.1%, 91.1%)	
12/22 06:40:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.02257	Loss 1.3500 (1.2443)	Arch Loss 6.2329 (5.9963)	Arch Hard Loss 2.1274 (1.8179)	Arch Beta Loss 4.1054 (4.1783)	Arch depth Loss -0.2599 (-0.2381)	Prec@(1,5) (63.6%, 90.7%)	
12/22 06:41:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.02257	Loss 1.3874 (1.2577)	Arch Loss 5.8699 (5.9683)	Arch Hard Loss 1.8055 (1.8116)	Arch Beta Loss 4.0644 (4.1567)	Arch depth Loss -0.2715 (-0.2444)	Prec@(1,5) (63.3%, 90.5%)	
12/22 06:41:18午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 33/159] Final Prec@1 63.2560%
12/22 06:41:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8425	Prec@(1,5) (51.2%, 80.7%)
12/22 06:41:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8251	Prec@(1,5) (51.7%, 80.8%)
12/22 06:41:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8265	Prec@(1,5) (51.3%, 80.7%)
12/22 06:41:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8298	Prec@(1,5) (51.1%, 80.8%)
12/22 06:41:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/159] Final Prec@1 51.1080%
12/22 06:41:49午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 06:41:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
12/22 06:42:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.02242	Loss 1.0194 (1.1621)	Arch Loss 5.8525 (5.8004)	Arch Hard Loss 1.8330 (1.7591)	Arch Beta Loss 4.0195 (4.0414)	Arch depth Loss -0.2798 (-0.2755)	Prec@(1,5) (66.6%, 91.4%)	
12/22 06:43:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.02242	Loss 1.1773 (1.1943)	Arch Loss 5.9903 (5.8125)	Arch Hard Loss 2.0135 (1.7930)	Arch Beta Loss 3.9768 (4.0195)	Arch depth Loss -0.2892 (-0.2799)	Prec@(1,5) (65.6%, 91.2%)	
12/22 06:44:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.02242	Loss 1.3728 (1.2119)	Arch Loss 6.0629 (5.8016)	Arch Hard Loss 2.1261 (1.8032)	Arch Beta Loss 3.9368 (3.9985)	Arch depth Loss -0.2967 (-0.2843)	Prec@(1,5) (65.0%, 90.9%)	
12/22 06:45:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.02242	Loss 1.1852 (1.2373)	Arch Loss 5.6370 (5.7895)	Arch Hard Loss 1.7354 (1.8094)	Arch Beta Loss 3.9016 (3.9801)	Arch depth Loss -0.3025 (-0.2878)	Prec@(1,5) (64.2%, 90.5%)	
12/22 06:45:23午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 34/159] Final Prec@1 64.1760%
12/22 06:45:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8224	Prec@(1,5) (51.2%, 81.2%)
12/22 06:45:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.8265	Prec@(1,5) (51.0%, 81.3%)
12/22 06:45:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.8120	Prec@(1,5) (51.3%, 81.5%)
12/22 06:45:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.8149	Prec@(1,5) (51.3%, 81.4%)
12/22 06:45:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/159] Final Prec@1 51.2840%
12/22 06:45:55午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 06:45:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.4320%
12/22 06:46:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.02228	Loss 1.2895 (1.1529)	Arch Loss 5.4884 (5.6982)	Arch Hard Loss 1.6249 (1.8160)	Arch Beta Loss 3.8635 (3.8822)	Arch depth Loss -0.3071 (-0.3052)	Prec@(1,5) (66.4%, 91.7%)	
12/22 06:47:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.02228	Loss 1.4510 (1.1913)	Arch Loss 5.3554 (5.6871)	Arch Hard Loss 1.5287 (1.8235)	Arch Beta Loss 3.8267 (3.8636)	Arch depth Loss -0.3100 (-0.3065)	Prec@(1,5) (65.3%, 91.2%)	
12/22 06:48:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.02228	Loss 1.4926 (1.2134)	Arch Loss 5.5130 (5.6479)	Arch Hard Loss 1.7207 (1.8025)	Arch Beta Loss 3.7922 (3.8455)	Arch depth Loss -0.3127 (-0.3082)	Prec@(1,5) (64.4%, 90.9%)	
12/22 06:49:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.02228	Loss 1.3980 (1.2261)	Arch Loss 5.3447 (5.6305)	Arch Hard Loss 1.5835 (1.8010)	Arch Beta Loss 3.7612 (3.8295)	Arch depth Loss -0.3156 (-0.3097)	Prec@(1,5) (64.2%, 90.6%)	
12/22 06:49:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 35/159] Final Prec@1 64.1520%
12/22 06:49:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7720	Prec@(1,5) (52.5%, 82.1%)
12/22 06:49:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7938	Prec@(1,5) (52.0%, 81.7%)
12/22 06:49:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7951	Prec@(1,5) (52.3%, 81.6%)
12/22 06:49:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.8026	Prec@(1,5) (52.1%, 81.5%)
12/22 06:49:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/159] Final Prec@1 52.1280%
12/22 06:49:57午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 06:49:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.1280%
12/22 06:50:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.02212	Loss 1.1320 (1.1390)	Arch Loss 5.8503 (5.5603)	Arch Hard Loss 2.1225 (1.8159)	Arch Beta Loss 3.7279 (3.7443)	Arch depth Loss -0.3159 (-0.3166)	Prec@(1,5) (66.7%, 92.6%)	
12/22 06:51:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.02212	Loss 1.0745 (1.1812)	Arch Loss 5.1072 (5.5171)	Arch Hard Loss 1.4105 (1.7890)	Arch Beta Loss 3.6967 (3.7281)	Arch depth Loss -0.3156 (-0.3163)	Prec@(1,5) (65.2%, 91.7%)	
12/22 06:52:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.02212	Loss 1.0539 (1.1954)	Arch Loss 5.4957 (5.5029)	Arch Hard Loss 1.8293 (1.7904)	Arch Beta Loss 3.6664 (3.7125)	Arch depth Loss -0.3155 (-0.3160)	Prec@(1,5) (64.8%, 91.3%)	
12/22 06:53:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.02212	Loss 1.2456 (1.2018)	Arch Loss 5.4566 (5.4901)	Arch Hard Loss 1.8176 (1.7914)	Arch Beta Loss 3.6390 (3.6987)	Arch depth Loss -0.3176 (-0.3162)	Prec@(1,5) (64.7%, 91.2%)	
12/22 06:53:30午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 36/159] Final Prec@1 64.7160%
12/22 06:53:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.8607	Prec@(1,5) (50.9%, 80.7%)
12/22 06:53:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.8328	Prec@(1,5) (51.1%, 81.2%)
12/22 06:53:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.8481	Prec@(1,5) (50.6%, 80.9%)
12/22 06:54:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.8529	Prec@(1,5) (50.4%, 80.9%)
12/22 06:54:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/159] Final Prec@1 50.4560%
12/22 06:54:02午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 06:54:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.1280%
12/22 06:54:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.02197	Loss 1.0546 (1.1296)	Arch Loss 5.3929 (5.4100)	Arch Hard Loss 1.7830 (1.7858)	Arch Beta Loss 3.6099 (3.6242)	Arch depth Loss -0.3171 (-0.3176)	Prec@(1,5) (66.2%, 92.1%)	
12/22 06:55:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.02197	Loss 1.4657 (1.1555)	Arch Loss 5.7480 (5.3885)	Arch Hard Loss 2.1661 (1.7785)	Arch Beta Loss 3.5819 (3.6100)	Arch depth Loss -0.3157 (-0.3169)	Prec@(1,5) (65.8%, 91.8%)	
12/22 06:56:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.02197	Loss 1.1958 (1.1789)	Arch Loss 5.3645 (5.3808)	Arch Hard Loss 1.8105 (1.7848)	Arch Beta Loss 3.5540 (3.5959)	Arch depth Loss -0.3115 (-0.3158)	Prec@(1,5) (65.3%, 91.5%)	
12/22 06:57:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.02197	Loss 0.9420 (1.1895)	Arch Loss 5.3189 (5.3673)	Arch Hard Loss 1.7882 (1.7838)	Arch Beta Loss 3.5306 (3.5835)	Arch depth Loss -0.3080 (-0.3145)	Prec@(1,5) (65.0%, 91.4%)	
12/22 06:57:33午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 37/159] Final Prec@1 65.0360%
12/22 06:57:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.7879	Prec@(1,5) (52.0%, 81.6%)
12/22 06:57:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.7801	Prec@(1,5) (52.3%, 82.0%)
12/22 06:57:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.7656	Prec@(1,5) (52.6%, 82.2%)
12/22 06:58:04午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.7703	Prec@(1,5) (52.6%, 82.1%)
12/22 06:58:04午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/159] Final Prec@1 52.6160%
12/22 06:58:04午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 6], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 06:58:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6160%
12/22 06:58:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.02181	Loss 0.9610 (1.1127)	Arch Loss 5.1376 (5.2804)	Arch Hard Loss 1.6320 (1.7627)	Arch Beta Loss 3.5055 (3.5177)	Arch depth Loss -0.3051 (-0.3066)	Prec@(1,5) (67.7%, 92.1%)	
12/22 06:59:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.02181	Loss 1.1085 (1.1456)	Arch Loss 5.2486 (5.2578)	Arch Hard Loss 1.7676 (1.7524)	Arch Beta Loss 3.4810 (3.5054)	Arch depth Loss -0.2984 (-0.3042)	Prec@(1,5) (66.6%, 91.7%)	
12/22 07:00:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.02181	Loss 1.2358 (1.1593)	Arch Loss 5.4122 (5.2551)	Arch Hard Loss 1.9552 (1.7620)	Arch Beta Loss 3.4570 (3.4931)	Arch depth Loss -0.2934 (-0.3011)	Prec@(1,5) (66.1%, 91.6%)	
12/22 07:01:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.02181	Loss 0.9168 (1.1723)	Arch Loss 5.5353 (5.2613)	Arch Hard Loss 2.0997 (1.7790)	Arch Beta Loss 3.4356 (3.4823)	Arch depth Loss -0.2855 (-0.2984)	Prec@(1,5) (65.8%, 91.4%)	
12/22 07:01:37午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 38/159] Final Prec@1 65.7720%
12/22 07:01:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7765	Prec@(1,5) (53.9%, 81.7%)
12/22 07:01:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7566	Prec@(1,5) (53.3%, 82.3%)
12/22 07:02:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7535	Prec@(1,5) (53.3%, 82.4%)
12/22 07:02:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7520	Prec@(1,5) (53.3%, 82.4%)
12/22 07:02:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/159] Final Prec@1 53.3280%
12/22 07:02:08午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:02:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.3280%
12/22 07:03:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.02165	Loss 1.0722 (1.0825)	Arch Loss 5.0440 (5.2067)	Arch Hard Loss 1.6325 (1.7832)	Arch Beta Loss 3.4116 (3.4235)	Arch depth Loss -0.2817 (-0.2833)	Prec@(1,5) (68.5%, 92.7%)	
12/22 07:03:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.02165	Loss 0.7814 (1.1097)	Arch Loss 5.1156 (5.1835)	Arch Hard Loss 1.7265 (1.7719)	Arch Beta Loss 3.3891 (3.4116)	Arch depth Loss -0.2770 (-0.2816)	Prec@(1,5) (67.9%, 92.3%)	
12/22 07:04:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.02165	Loss 0.9849 (1.1399)	Arch Loss 5.3117 (5.1717)	Arch Hard Loss 1.9438 (1.7712)	Arch Beta Loss 3.3679 (3.4005)	Arch depth Loss -0.2704 (-0.2788)	Prec@(1,5) (66.7%, 91.9%)	
12/22 07:05:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.02165	Loss 1.2127 (1.1544)	Arch Loss 5.2941 (5.1603)	Arch Hard Loss 1.9449 (1.7695)	Arch Beta Loss 3.3492 (3.3908)	Arch depth Loss -0.2640 (-0.2761)	Prec@(1,5) (66.1%, 91.8%)	
12/22 07:05:38午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 39/159] Final Prec@1 66.1080%
12/22 07:05:46午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.8267	Prec@(1,5) (51.0%, 81.3%)
12/22 07:05:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.8138	Prec@(1,5) (51.7%, 81.6%)
12/22 07:06:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.8171	Prec@(1,5) (51.9%, 81.5%)
12/22 07:06:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.8227	Prec@(1,5) (51.6%, 81.4%)
12/22 07:06:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/159] Final Prec@1 51.6600%
12/22 07:06:09午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:06:10午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.3280%
12/22 07:07:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.02149	Loss 1.1278 (1.0983)	Arch Loss 5.2471 (5.1493)	Arch Hard Loss 1.9186 (1.8109)	Arch Beta Loss 3.3286 (3.3384)	Arch depth Loss -0.2590 (-0.2618)	Prec@(1,5) (68.5%, 92.0%)	
12/22 07:07:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.02149	Loss 1.1377 (1.1182)	Arch Loss 5.1958 (5.1221)	Arch Hard Loss 1.8871 (1.7935)	Arch Beta Loss 3.3087 (3.3286)	Arch depth Loss -0.2515 (-0.2583)	Prec@(1,5) (67.7%, 92.1%)	
12/22 07:08:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.02149	Loss 0.9950 (1.1462)	Arch Loss 5.1637 (5.1153)	Arch Hard Loss 1.8746 (1.7967)	Arch Beta Loss 3.2891 (3.3186)	Arch depth Loss -0.2445 (-0.2549)	Prec@(1,5) (66.9%, 91.8%)	
12/22 07:09:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.02149	Loss 1.4559 (1.1514)	Arch Loss 4.8781 (5.0912)	Arch Hard Loss 1.6057 (1.7813)	Arch Beta Loss 3.2724 (3.3098)	Arch depth Loss -0.2394 (-0.2522)	Prec@(1,5) (66.6%, 91.8%)	
12/22 07:09:39午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 40/159] Final Prec@1 66.5720%
12/22 07:09:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7731	Prec@(1,5) (52.2%, 81.9%)
12/22 07:09:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7786	Prec@(1,5) (52.2%, 81.7%)
12/22 07:10:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7857	Prec@(1,5) (52.2%, 81.8%)
12/22 07:10:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7884	Prec@(1,5) (52.2%, 81.8%)
12/22 07:10:10午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/159] Final Prec@1 52.2000%
12/22 07:10:10午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:10:11午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.3280%
12/22 07:11:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.02132	Loss 0.9912 (1.0728)	Arch Loss 4.8166 (5.0303)	Arch Hard Loss 1.5632 (1.7676)	Arch Beta Loss 3.2534 (3.2627)	Arch depth Loss -0.2324 (-0.2354)	Prec@(1,5) (68.3%, 92.8%)	
12/22 07:12:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.02132	Loss 0.9717 (1.0967)	Arch Loss 5.1665 (5.0313)	Arch Hard Loss 1.9316 (1.7779)	Arch Beta Loss 3.2349 (3.2534)	Arch depth Loss -0.2219 (-0.2316)	Prec@(1,5) (67.8%, 92.5%)	
12/22 07:12:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.02132	Loss 1.0867 (1.1134)	Arch Loss 4.6283 (5.0168)	Arch Hard Loss 1.4111 (1.7726)	Arch Beta Loss 3.2172 (3.2442)	Arch depth Loss -0.2163 (-0.2274)	Prec@(1,5) (67.2%, 92.3%)	
12/22 07:13:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.02132	Loss 1.4310 (1.1326)	Arch Loss 4.8088 (5.0058)	Arch Hard Loss 1.6077 (1.7698)	Arch Beta Loss 3.2011 (3.2361)	Arch depth Loss -0.2109 (-0.2243)	Prec@(1,5) (66.8%, 92.0%)	
12/22 07:13:45午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 41/159] Final Prec@1 66.7600%
12/22 07:13:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.8214	Prec@(1,5) (51.2%, 81.4%)
12/22 07:14:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.8283	Prec@(1,5) (51.2%, 81.5%)
12/22 07:14:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.8262	Prec@(1,5) (51.3%, 81.6%)
12/22 07:14:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.8297	Prec@(1,5) (51.2%, 81.5%)
12/22 07:14:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/159] Final Prec@1 51.1920%
12/22 07:14:16午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:14:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.3280%
12/22 07:15:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.02115	Loss 1.2140 (1.0755)	Arch Loss 4.7643 (4.9748)	Arch Hard Loss 1.5804 (1.7826)	Arch Beta Loss 3.1840 (3.1922)	Arch depth Loss -0.1987 (-0.2049)	Prec@(1,5) (68.1%, 93.3%)	
12/22 07:16:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.02115	Loss 1.2533 (1.0969)	Arch Loss 4.7458 (4.9318)	Arch Hard Loss 1.5787 (1.7481)	Arch Beta Loss 3.1672 (3.1838)	Arch depth Loss -0.1926 (-0.2002)	Prec@(1,5) (67.6%, 92.7%)	
12/22 07:16:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.02115	Loss 1.0735 (1.1162)	Arch Loss 5.0711 (4.9348)	Arch Hard Loss 1.9217 (1.7595)	Arch Beta Loss 3.1495 (3.1753)	Arch depth Loss -0.1838 (-0.1960)	Prec@(1,5) (67.1%, 92.4%)	
12/22 07:17:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.02115	Loss 1.0839 (1.1263)	Arch Loss 4.9811 (4.9337)	Arch Hard Loss 1.8478 (1.7664)	Arch Beta Loss 3.1333 (3.1674)	Arch depth Loss -0.1763 (-0.1924)	Prec@(1,5) (66.8%, 92.2%)	
12/22 07:17:47午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 42/159] Final Prec@1 66.8520%
12/22 07:17:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.7364	Prec@(1,5) (52.9%, 82.6%)
12/22 07:18:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7549	Prec@(1,5) (52.6%, 82.6%)
12/22 07:18:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7526	Prec@(1,5) (52.7%, 82.7%)
12/22 07:18:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7561	Prec@(1,5) (52.7%, 82.6%)
12/22 07:18:19午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/159] Final Prec@1 52.7080%
12/22 07:18:19午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[4, 5], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:18:19午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.3280%
12/22 07:19:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.02097	Loss 1.1592 (1.0505)	Arch Loss 5.0740 (4.8656)	Arch Hard Loss 1.9568 (1.7404)	Arch Beta Loss 3.1172 (3.1252)	Arch depth Loss -0.1704 (-0.1735)	Prec@(1,5) (69.1%, 93.2%)	
12/22 07:20:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.02097	Loss 1.0511 (1.0855)	Arch Loss 4.6193 (4.8707)	Arch Hard Loss 1.5184 (1.7536)	Arch Beta Loss 3.1008 (3.1171)	Arch depth Loss -0.1626 (-0.1695)	Prec@(1,5) (67.9%, 92.7%)	
12/22 07:21:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.02097	Loss 1.3031 (1.1097)	Arch Loss 4.8640 (4.8602)	Arch Hard Loss 1.7794 (1.7512)	Arch Beta Loss 3.0846 (3.1089)	Arch depth Loss -0.1477 (-0.1646)	Prec@(1,5) (67.2%, 92.4%)	
12/22 07:21:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.02097	Loss 1.0386 (1.1207)	Arch Loss 4.5245 (4.8587)	Arch Hard Loss 1.4550 (1.7572)	Arch Beta Loss 3.0695 (3.1015)	Arch depth Loss -0.1385 (-0.1596)	Prec@(1,5) (67.0%, 92.2%)	
12/22 07:21:53午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 43/159] Final Prec@1 67.0280%
12/22 07:22:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7312	Prec@(1,5) (53.7%, 82.3%)
12/22 07:22:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7514	Prec@(1,5) (53.2%, 82.3%)
12/22 07:22:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7615	Prec@(1,5) (53.0%, 82.3%)
12/22 07:22:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7758	Prec@(1,5) (52.7%, 82.2%)
12/22 07:22:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/159] Final Prec@1 52.6960%
12/22 07:22:25午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:22:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.3280%
12/22 07:23:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.02079	Loss 1.1730 (1.0636)	Arch Loss 4.9354 (4.8086)	Arch Hard Loss 1.8823 (1.7474)	Arch Beta Loss 3.0530 (3.0612)	Arch depth Loss -0.1299 (-0.1346)	Prec@(1,5) (68.3%, 93.2%)	
12/22 07:24:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.02079	Loss 1.2034 (1.0840)	Arch Loss 5.3604 (4.8100)	Arch Hard Loss 2.3236 (1.7571)	Arch Beta Loss 3.0368 (3.0529)	Arch depth Loss -0.1217 (-0.1299)	Prec@(1,5) (68.0%, 92.7%)	
12/22 07:25:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.02079	Loss 1.2205 (1.1106)	Arch Loss 4.7562 (4.8116)	Arch Hard Loss 1.7358 (1.7669)	Arch Beta Loss 3.0204 (3.0447)	Arch depth Loss -0.1130 (-0.1256)	Prec@(1,5) (67.2%, 92.4%)	
12/22 07:26:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.02079	Loss 0.8452 (1.1124)	Arch Loss 5.2155 (4.7952)	Arch Hard Loss 2.2085 (1.7576)	Arch Beta Loss 3.0070 (3.0376)	Arch depth Loss -0.1054 (-0.1219)	Prec@(1,5) (67.1%, 92.4%)	
12/22 07:26:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 44/159] Final Prec@1 67.0960%
12/22 07:26:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.7570	Prec@(1,5) (52.9%, 82.6%)
12/22 07:26:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.7616	Prec@(1,5) (52.9%, 82.8%)
12/22 07:26:37午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7656	Prec@(1,5) (52.8%, 82.8%)
12/22 07:26:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7711	Prec@(1,5) (52.5%, 82.6%)
12/22 07:26:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/159] Final Prec@1 52.5200%
12/22 07:26:44午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:26:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.3280%
12/22 07:27:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.02061	Loss 0.9070 (1.0644)	Arch Loss 4.5550 (4.7166)	Arch Hard Loss 1.5632 (1.7173)	Arch Beta Loss 2.9918 (2.9993)	Arch depth Loss -0.0947 (-0.0997)	Prec@(1,5) (68.5%, 93.1%)	
12/22 07:28:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.02061	Loss 1.2908 (1.0799)	Arch Loss 5.0083 (4.7216)	Arch Hard Loss 2.0326 (1.7301)	Arch Beta Loss 2.9757 (2.9914)	Arch depth Loss -0.0852 (-0.0948)	Prec@(1,5) (68.1%, 92.9%)	
12/22 07:29:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.02061	Loss 1.0518 (1.0836)	Arch Loss 4.9722 (4.7181)	Arch Hard Loss 2.0118 (1.7345)	Arch Beta Loss 2.9605 (2.9836)	Arch depth Loss -0.0780 (-0.0903)	Prec@(1,5) (67.8%, 92.7%)	
12/22 07:30:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.02061	Loss 0.9299 (1.0918)	Arch Loss 4.7018 (4.7123)	Arch Hard Loss 1.7564 (1.7358)	Arch Beta Loss 2.9453 (2.9765)	Arch depth Loss -0.0712 (-0.0869)	Prec@(1,5) (67.8%, 92.6%)	
12/22 07:30:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 45/159] Final Prec@1 67.7720%
12/22 07:30:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.6976	Prec@(1,5) (54.5%, 83.6%)
12/22 07:30:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7291	Prec@(1,5) (53.8%, 83.0%)
12/22 07:30:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7328	Prec@(1,5) (53.6%, 83.0%)
12/22 07:30:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7318	Prec@(1,5) (53.8%, 83.0%)
12/22 07:30:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/159] Final Prec@1 53.7360%
12/22 07:30:56午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:30:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7360%
12/22 07:31:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.02043	Loss 1.2138 (0.9904)	Arch Loss 4.6817 (4.6663)	Arch Hard Loss 1.7527 (1.7295)	Arch Beta Loss 2.9290 (2.9368)	Arch depth Loss -0.0616 (-0.0655)	Prec@(1,5) (71.2%, 93.6%)	
12/22 07:32:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.02043	Loss 0.9197 (1.0265)	Arch Loss 4.6961 (4.6655)	Arch Hard Loss 1.7837 (1.7368)	Arch Beta Loss 2.9124 (2.9287)	Arch depth Loss -0.0543 (-0.0620)	Prec@(1,5) (69.7%, 93.4%)	
12/22 07:33:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.02043	Loss 0.9409 (1.0577)	Arch Loss 4.5597 (4.6563)	Arch Hard Loss 1.6640 (1.7359)	Arch Beta Loss 2.8956 (2.9203)	Arch depth Loss -0.0485 (-0.0584)	Prec@(1,5) (68.7%, 93.1%)	
12/22 07:34:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.02043	Loss 0.7084 (1.0736)	Arch Loss 4.8860 (4.6513)	Arch Hard Loss 2.0046 (1.7383)	Arch Beta Loss 2.8814 (2.9130)	Arch depth Loss -0.0392 (-0.0550)	Prec@(1,5) (68.3%, 93.0%)	
12/22 07:34:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 46/159] Final Prec@1 68.2520%
12/22 07:34:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.8414	Prec@(1,5) (52.0%, 81.2%)
12/22 07:34:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.8537	Prec@(1,5) (52.2%, 81.0%)
12/22 07:34:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.8522	Prec@(1,5) (52.1%, 81.1%)
12/22 07:35:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.8501	Prec@(1,5) (52.2%, 80.9%)
12/22 07:35:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/159] Final Prec@1 52.2080%
12/22 07:35:03午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:35:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7360%
12/22 07:35:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.02024	Loss 0.7930 (1.0357)	Arch Loss 4.3035 (4.5912)	Arch Hard Loss 1.4388 (1.7185)	Arch Beta Loss 2.8646 (2.8727)	Arch depth Loss -0.0315 (-0.0355)	Prec@(1,5) (69.7%, 93.4%)	
12/22 07:36:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.02024	Loss 0.9216 (1.0364)	Arch Loss 4.6788 (4.6114)	Arch Hard Loss 1.8302 (1.7467)	Arch Beta Loss 2.8487 (2.8647)	Arch depth Loss -0.0238 (-0.0313)	Prec@(1,5) (69.5%, 93.4%)	
12/22 07:37:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.02024	Loss 0.8707 (1.0562)	Arch Loss 4.3116 (4.5985)	Arch Hard Loss 1.4790 (1.7418)	Arch Beta Loss 2.8326 (2.8566)	Arch depth Loss -0.0178 (-0.0276)	Prec@(1,5) (68.8%, 93.1%)	
12/22 07:38:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.02024	Loss 1.2688 (1.0695)	Arch Loss 4.6557 (4.5947)	Arch Hard Loss 1.8372 (1.7452)	Arch Beta Loss 2.8185 (2.8495)	Arch depth Loss -0.0128 (-0.0247)	Prec@(1,5) (68.4%, 92.9%)	
12/22 07:38:36午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 47/159] Final Prec@1 68.4040%
12/22 07:38:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7164	Prec@(1,5) (53.8%, 83.1%)
12/22 07:38:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.7109	Prec@(1,5) (54.1%, 83.0%)
12/22 07:39:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.7118	Prec@(1,5) (54.1%, 82.9%)
12/22 07:39:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7152	Prec@(1,5) (54.0%, 82.8%)
12/22 07:39:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/159] Final Prec@1 54.0160%
12/22 07:39:07午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:39:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 07:40:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.02005	Loss 1.0801 (1.0134)	Arch Loss 4.4347 (4.5212)	Arch Hard Loss 1.6328 (1.7113)	Arch Beta Loss 2.8019 (2.8099)	Arch depth Loss -0.0065 (-0.0093)	Prec@(1,5) (69.9%, 93.7%)	
12/22 07:40:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.02005	Loss 1.0445 (1.0294)	Arch Loss 4.6079 (4.5355)	Arch Hard Loss 1.8221 (1.7337)	Arch Beta Loss 2.7859 (2.8019)	Arch depth Loss 0.0005 (-0.0060)	Prec@(1,5) (69.5%, 93.5%)	
12/22 07:41:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.02005	Loss 1.1140 (1.0510)	Arch Loss 4.2229 (4.5296)	Arch Hard Loss 1.4520 (1.7357)	Arch Beta Loss 2.7709 (2.7940)	Arch depth Loss 0.0107 (-0.0021)	Prec@(1,5) (69.0%, 93.1%)	
12/22 07:42:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.02005	Loss 1.1701 (1.0666)	Arch Loss 4.3704 (4.5286)	Arch Hard Loss 1.6126 (1.7415)	Arch Beta Loss 2.7578 (2.7871)	Arch depth Loss 0.0174 (0.0017)	Prec@(1,5) (68.4%, 93.0%)	
12/22 07:42:42午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 48/159] Final Prec@1 68.4160%
12/22 07:42:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7425	Prec@(1,5) (53.8%, 82.8%)
12/22 07:42:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.7243	Prec@(1,5) (53.9%, 83.1%)
12/22 07:43:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.7205	Prec@(1,5) (54.0%, 83.2%)
12/22 07:43:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7253	Prec@(1,5) (54.0%, 83.1%)
12/22 07:43:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/159] Final Prec@1 53.9400%
12/22 07:43:14午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:43:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 07:44:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.01986	Loss 0.8096 (0.9884)	Arch Loss 4.4208 (4.4857)	Arch Hard Loss 1.6783 (1.7356)	Arch Beta Loss 2.7424 (2.7500)	Arch depth Loss 0.0288 (0.0242)	Prec@(1,5) (71.3%, 94.1%)	
12/22 07:45:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.01986	Loss 1.1025 (1.0072)	Arch Loss 4.4846 (4.4840)	Arch Hard Loss 1.7571 (1.7417)	Arch Beta Loss 2.7275 (2.7423)	Arch depth Loss 0.0316 (0.0272)	Prec@(1,5) (70.4%, 93.8%)	
12/22 07:46:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.01986	Loss 0.9500 (1.0254)	Arch Loss 4.5585 (4.4795)	Arch Hard Loss 1.8452 (1.7444)	Arch Beta Loss 2.7133 (2.7350)	Arch depth Loss 0.0413 (0.0302)	Prec@(1,5) (69.6%, 93.6%)	
12/22 07:46:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.01986	Loss 1.2432 (1.0481)	Arch Loss 4.2043 (4.4799)	Arch Hard Loss 1.5029 (1.7513)	Arch Beta Loss 2.7014 (2.7286)	Arch depth Loss 0.0490 (0.0337)	Prec@(1,5) (68.9%, 93.3%)	
12/22 07:46:54午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 49/159] Final Prec@1 68.9120%
12/22 07:47:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.7419	Prec@(1,5) (53.4%, 83.4%)
12/22 07:47:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.7675	Prec@(1,5) (52.6%, 82.9%)
12/22 07:47:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7822	Prec@(1,5) (52.2%, 82.5%)
12/22 07:47:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.7768	Prec@(1,5) (52.4%, 82.6%)
12/22 07:47:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/159] Final Prec@1 52.4120%
12/22 07:47:26午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:47:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 07:48:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][100/390]	Step 19650	lr 0.01967	Loss 0.8438 (0.9753)	Arch Loss 4.5162 (4.4504)	Arch Hard Loss 1.8284 (1.7561)	Arch Beta Loss 2.6878 (2.6943)	Arch depth Loss 0.0591 (0.0541)	Prec@(1,5) (71.4%, 94.7%)	
12/22 07:49:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][200/390]	Step 19750	lr 0.01967	Loss 1.1359 (1.0136)	Arch Loss 4.4729 (4.4275)	Arch Hard Loss 1.7995 (1.7401)	Arch Beta Loss 2.6734 (2.6874)	Arch depth Loss 0.0652 (0.0575)	Prec@(1,5) (70.0%, 93.9%)	
12/22 07:50:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][300/390]	Step 19850	lr 0.01967	Loss 1.1252 (1.0319)	Arch Loss 4.5608 (4.4184)	Arch Hard Loss 1.9004 (1.7378)	Arch Beta Loss 2.6603 (2.6806)	Arch depth Loss 0.0694 (0.0607)	Prec@(1,5) (69.5%, 93.5%)	
12/22 07:51:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][390/390]	Step 19940	lr 0.01967	Loss 1.2282 (1.0478)	Arch Loss 3.9363 (4.4112)	Arch Hard Loss 1.2889 (1.7369)	Arch Beta Loss 2.6475 (2.6744)	Arch depth Loss 0.0717 (0.0633)	Prec@(1,5) (68.9%, 93.3%)	
12/22 07:51:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 50/159] Final Prec@1 68.9040%
12/22 07:51:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][100/391]	Step 19941	Loss 1.8059	Prec@(1,5) (52.6%, 82.3%)
12/22 07:51:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][200/391]	Step 19941	Loss 1.7897	Prec@(1,5) (52.9%, 82.4%)
12/22 07:51:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][300/391]	Step 19941	Loss 1.7994	Prec@(1,5) (52.7%, 82.3%)
12/22 07:51:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][390/391]	Step 19941	Loss 1.8015	Prec@(1,5) (52.6%, 82.3%)
12/22 07:51:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/159] Final Prec@1 52.5920%
12/22 07:51:44午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:51:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 07:52:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][100/390]	Step 20041	lr 0.01947	Loss 1.1459 (0.9606)	Arch Loss 4.2280 (4.3630)	Arch Hard Loss 1.5930 (1.7217)	Arch Beta Loss 2.6351 (2.6414)	Arch depth Loss 0.0759 (0.0738)	Prec@(1,5) (71.7%, 94.6%)	
12/22 07:53:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][200/390]	Step 20141	lr 0.01947	Loss 0.8615 (1.0021)	Arch Loss 4.7851 (4.3797)	Arch Hard Loss 2.1633 (1.7448)	Arch Beta Loss 2.6218 (2.6349)	Arch depth Loss 0.0830 (0.0766)	Prec@(1,5) (70.1%, 93.7%)	
12/22 07:54:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][300/390]	Step 20241	lr 0.01947	Loss 0.9639 (1.0166)	Arch Loss 4.3047 (4.3604)	Arch Hard Loss 1.6964 (1.7321)	Arch Beta Loss 2.6083 (2.6283)	Arch depth Loss 0.0881 (0.0793)	Prec@(1,5) (69.7%, 93.6%)	
12/22 07:55:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][390/390]	Step 20331	lr 0.01947	Loss 1.1157 (1.0339)	Arch Loss 3.7655 (4.3549)	Arch Hard Loss 1.1676 (1.7325)	Arch Beta Loss 2.5979 (2.6224)	Arch depth Loss 0.0921 (0.0817)	Prec@(1,5) (69.3%, 93.3%)	
12/22 07:55:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 51/159] Final Prec@1 69.3320%
12/22 07:55:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][100/391]	Step 20332	Loss 1.8156	Prec@(1,5) (51.7%, 82.5%)
12/22 07:55:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][200/391]	Step 20332	Loss 1.8147	Prec@(1,5) (52.0%, 82.4%)
12/22 07:55:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][300/391]	Step 20332	Loss 1.8170	Prec@(1,5) (52.2%, 82.0%)
12/22 07:56:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][390/391]	Step 20332	Loss 1.8270	Prec@(1,5) (52.2%, 81.9%)
12/22 07:56:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/159] Final Prec@1 52.1800%
12/22 07:56:03午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:56:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 07:57:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][100/390]	Step 20432	lr 0.01927	Loss 0.9502 (0.9685)	Arch Loss 4.0335 (4.2974)	Arch Hard Loss 1.4470 (1.7054)	Arch Beta Loss 2.5865 (2.5920)	Arch depth Loss 0.0949 (0.0929)	Prec@(1,5) (71.3%, 94.3%)	
12/22 07:57:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][200/390]	Step 20532	lr 0.01927	Loss 1.2635 (0.9924)	Arch Loss 4.4944 (4.2880)	Arch Hard Loss 1.9189 (1.7016)	Arch Beta Loss 2.5755 (2.5864)	Arch depth Loss 0.0996 (0.0951)	Prec@(1,5) (70.4%, 94.0%)	
12/22 07:58:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][300/390]	Step 20632	lr 0.01927	Loss 1.0654 (1.0161)	Arch Loss 4.3102 (4.2950)	Arch Hard Loss 1.7463 (1.7142)	Arch Beta Loss 2.5639 (2.5808)	Arch depth Loss 0.1041 (0.0975)	Prec@(1,5) (69.8%, 93.6%)	
12/22 07:59:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][390/390]	Step 20722	lr 0.01927	Loss 1.2584 (1.0296)	Arch Loss 3.9542 (4.2995)	Arch Hard Loss 1.4001 (1.7237)	Arch Beta Loss 2.5542 (2.5758)	Arch depth Loss 0.1091 (0.0998)	Prec@(1,5) (69.4%, 93.4%)	
12/22 07:59:45午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 52/159] Final Prec@1 69.3840%
12/22 07:59:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][100/391]	Step 20723	Loss 1.7496	Prec@(1,5) (53.9%, 82.9%)
12/22 08:00:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][200/391]	Step 20723	Loss 1.7565	Prec@(1,5) (53.5%, 82.9%)
12/22 08:00:10午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][300/391]	Step 20723	Loss 1.7640	Prec@(1,5) (53.3%, 82.8%)
12/22 08:00:17午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][390/391]	Step 20723	Loss 1.7767	Prec@(1,5) (53.0%, 82.5%)
12/22 08:00:17午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/159] Final Prec@1 53.0280%
12/22 08:00:17午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:00:17午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 08:01:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][100/390]	Step 20823	lr 0.01907	Loss 0.9859 (1.0116)	Arch Loss 3.9174 (4.2702)	Arch Hard Loss 1.3741 (1.7215)	Arch Beta Loss 2.5433 (2.5488)	Arch depth Loss 0.1196 (0.1147)	Prec@(1,5) (70.2%, 93.7%)	
12/22 08:02:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][200/390]	Step 20923	lr 0.01907	Loss 0.8656 (1.0037)	Arch Loss 4.4633 (4.2754)	Arch Hard Loss 1.9305 (1.7319)	Arch Beta Loss 2.5328 (2.5435)	Arch depth Loss 0.1260 (0.1190)	Prec@(1,5) (70.3%, 93.7%)	
12/22 08:03:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][300/390]	Step 21023	lr 0.01907	Loss 0.9617 (1.0204)	Arch Loss 4.2439 (4.2778)	Arch Hard Loss 1.7200 (1.7394)	Arch Beta Loss 2.5239 (2.5384)	Arch depth Loss 0.1263 (0.1220)	Prec@(1,5) (69.7%, 93.5%)	
12/22 08:03:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][390/390]	Step 21113	lr 0.01907	Loss 1.2110 (1.0312)	Arch Loss 4.4020 (4.2727)	Arch Hard Loss 1.8861 (1.7387)	Arch Beta Loss 2.5159 (2.5340)	Arch depth Loss 0.1317 (0.1236)	Prec@(1,5) (69.3%, 93.4%)	
12/22 08:03:57午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 53/159] Final Prec@1 69.2480%
12/22 08:04:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][100/391]	Step 21114	Loss 1.7527	Prec@(1,5) (53.7%, 82.7%)
12/22 08:04:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][200/391]	Step 21114	Loss 1.7295	Prec@(1,5) (53.9%, 83.1%)
12/22 08:04:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][300/391]	Step 21114	Loss 1.7398	Prec@(1,5) (53.7%, 82.9%)
12/22 08:04:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][390/391]	Step 21114	Loss 1.7314	Prec@(1,5) (53.8%, 83.0%)
12/22 08:04:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/159] Final Prec@1 53.8160%
12/22 08:04:29午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:04:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 08:05:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][100/390]	Step 21214	lr 0.01886	Loss 0.6380 (0.9753)	Arch Loss 4.3653 (4.2237)	Arch Hard Loss 1.8589 (1.7127)	Arch Beta Loss 2.5065 (2.5110)	Arch depth Loss 0.1349 (0.1339)	Prec@(1,5) (71.0%, 94.0%)	
12/22 08:06:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][200/390]	Step 21314	lr 0.01886	Loss 0.9825 (1.0054)	Arch Loss 4.5168 (4.2159)	Arch Hard Loss 2.0197 (1.7097)	Arch Beta Loss 2.4970 (2.5062)	Arch depth Loss 0.1391 (0.1356)	Prec@(1,5) (70.5%, 93.5%)	
12/22 08:07:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][300/390]	Step 21414	lr 0.01886	Loss 1.0634 (1.0150)	Arch Loss 4.3118 (4.2248)	Arch Hard Loss 1.8233 (1.7230)	Arch Beta Loss 2.4886 (2.5018)	Arch depth Loss 0.1419 (0.1373)	Prec@(1,5) (70.2%, 93.4%)	
12/22 08:08:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][390/390]	Step 21504	lr 0.01886	Loss 0.9655 (1.0188)	Arch Loss 3.9075 (4.2283)	Arch Hard Loss 1.4263 (1.7304)	Arch Beta Loss 2.4812 (2.4979)	Arch depth Loss 0.1421 (0.1384)	Prec@(1,5) (70.1%, 93.2%)	
12/22 08:08:28午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 54/159] Final Prec@1 70.0840%
12/22 08:08:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][100/391]	Step 21505	Loss 1.7506	Prec@(1,5) (53.6%, 83.2%)
12/22 08:08:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][200/391]	Step 21505	Loss 1.7563	Prec@(1,5) (53.1%, 82.9%)
12/22 08:08:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][300/391]	Step 21505	Loss 1.7429	Prec@(1,5) (53.5%, 82.9%)
12/22 08:09:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][390/391]	Step 21505	Loss 1.7382	Prec@(1,5) (53.6%, 83.1%)
12/22 08:09:00午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/159] Final Prec@1 53.6560%
12/22 08:09:00午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:09:00午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0160%
12/22 08:10:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][100/390]	Step 21605	lr 0.01866	Loss 0.7559 (0.9270)	Arch Loss 4.3491 (4.1981)	Arch Hard Loss 1.8770 (1.7213)	Arch Beta Loss 2.4721 (2.4768)	Arch depth Loss 0.1486 (0.1466)	Prec@(1,5) (72.5%, 94.6%)	
12/22 08:11:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][200/390]	Step 21705	lr 0.01866	Loss 0.9194 (0.9595)	Arch Loss 4.4383 (4.1750)	Arch Hard Loss 1.9742 (1.7027)	Arch Beta Loss 2.4641 (2.4724)	Arch depth Loss 0.1507 (0.1480)	Prec@(1,5) (71.6%, 94.2%)	
12/22 08:12:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][300/390]	Step 21805	lr 0.01866	Loss 1.1718 (0.9886)	Arch Loss 3.8621 (4.1981)	Arch Hard Loss 1.4054 (1.7299)	Arch Beta Loss 2.4566 (2.4683)	Arch depth Loss 0.1511 (0.1488)	Prec@(1,5) (70.6%, 93.9%)	
12/22 08:12:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][390/390]	Step 21895	lr 0.01866	Loss 1.1498 (1.0068)	Arch Loss 3.9384 (4.1882)	Arch Hard Loss 1.4883 (1.7234)	Arch Beta Loss 2.4501 (2.4648)	Arch depth Loss 0.1556 (0.1500)	Prec@(1,5) (70.0%, 93.6%)	
12/22 08:12:54午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 55/159] Final Prec@1 70.0360%
12/22 08:13:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][100/391]	Step 21896	Loss 1.6713	Prec@(1,5) (55.2%, 83.3%)
12/22 08:13:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][200/391]	Step 21896	Loss 1.7101	Prec@(1,5) (54.6%, 83.0%)
12/22 08:13:19午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][300/391]	Step 21896	Loss 1.7142	Prec@(1,5) (54.5%, 83.2%)
12/22 08:13:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][390/391]	Step 21896	Loss 1.7223	Prec@(1,5) (54.2%, 83.0%)
12/22 08:13:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/159] Final Prec@1 54.2280%
12/22 08:13:26午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:13:27午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.2280%
12/22 08:14:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][100/390]	Step 21996	lr 0.01845	Loss 0.9349 (0.9480)	Arch Loss 3.9639 (4.1785)	Arch Hard Loss 1.5218 (1.7323)	Arch Beta Loss 2.4421 (2.4462)	Arch depth Loss 0.1591 (0.1588)	Prec@(1,5) (72.3%, 94.5%)	
12/22 08:15:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][200/390]	Step 22096	lr 0.01845	Loss 1.0038 (0.9663)	Arch Loss 4.7081 (4.1765)	Arch Hard Loss 2.2731 (1.7340)	Arch Beta Loss 2.4351 (2.4425)	Arch depth Loss 0.1604 (0.1589)	Prec@(1,5) (71.5%, 94.1%)	
12/22 08:16:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][300/390]	Step 22196	lr 0.01845	Loss 1.2436 (0.9923)	Arch Loss 4.0491 (4.1789)	Arch Hard Loss 1.6207 (1.7400)	Arch Beta Loss 2.4284 (2.4388)	Arch depth Loss 0.1599 (0.1591)	Prec@(1,5) (70.5%, 93.9%)	
12/22 08:17:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][390/390]	Step 22286	lr 0.01845	Loss 1.0763 (0.9999)	Arch Loss 3.9099 (4.1657)	Arch Hard Loss 1.4865 (1.7299)	Arch Beta Loss 2.4234 (2.4358)	Arch depth Loss 0.1598 (0.1593)	Prec@(1,5) (70.3%, 93.8%)	
12/22 08:17:19午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 56/159] Final Prec@1 70.2720%
12/22 08:17:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][100/391]	Step 22287	Loss 1.8057	Prec@(1,5) (53.4%, 82.1%)
12/22 08:17:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][200/391]	Step 22287	Loss 1.7706	Prec@(1,5) (54.0%, 82.7%)
12/22 08:17:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][300/391]	Step 22287	Loss 1.7619	Prec@(1,5) (54.1%, 82.7%)
12/22 08:17:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][390/391]	Step 22287	Loss 1.7592	Prec@(1,5) (54.0%, 82.9%)
12/22 08:17:51午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/159] Final Prec@1 54.0480%
12/22 08:17:51午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:17:52午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.2280%
12/22 08:18:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][100/390]	Step 22387	lr 0.01824	Loss 0.8647 (0.9420)	Arch Loss 4.0571 (4.1494)	Arch Hard Loss 1.6403 (1.7294)	Arch Beta Loss 2.4168 (2.4200)	Arch depth Loss 0.1615 (0.1610)	Prec@(1,5) (72.0%, 94.0%)	
12/22 08:19:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][200/390]	Step 22487	lr 0.01824	Loss 0.9522 (0.9514)	Arch Loss 4.2536 (4.1379)	Arch Hard Loss 1.8428 (1.7211)	Arch Beta Loss 2.4107 (2.4168)	Arch depth Loss 0.1657 (0.1626)	Prec@(1,5) (71.7%, 94.1%)	
12/22 08:20:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][300/390]	Step 22587	lr 0.01824	Loss 1.2387 (0.9660)	Arch Loss 4.3804 (4.1406)	Arch Hard Loss 1.9752 (1.7267)	Arch Beta Loss 2.4052 (2.4138)	Arch depth Loss 0.1674 (0.1639)	Prec@(1,5) (71.1%, 93.9%)	
12/22 08:21:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][390/390]	Step 22677	lr 0.01824	Loss 1.0335 (0.9832)	Arch Loss 4.2409 (4.1330)	Arch Hard Loss 1.8419 (1.7219)	Arch Beta Loss 2.3990 (2.4111)	Arch depth Loss 0.1662 (0.1645)	Prec@(1,5) (70.6%, 93.8%)	
12/22 08:21:31午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 57/159] Final Prec@1 70.5720%
12/22 08:21:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][100/391]	Step 22678	Loss 1.7860	Prec@(1,5) (53.0%, 82.3%)
12/22 08:21:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][200/391]	Step 22678	Loss 1.7820	Prec@(1,5) (52.8%, 82.3%)
12/22 08:21:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][300/391]	Step 22678	Loss 1.7793	Prec@(1,5) (52.7%, 82.7%)
12/22 08:22:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][390/391]	Step 22678	Loss 1.7648	Prec@(1,5) (53.0%, 83.0%)
12/22 08:22:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/159] Final Prec@1 53.0120%
12/22 08:22:02午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:22:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.2280%
12/22 08:22:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][100/390]	Step 22778	lr 0.01802	Loss 1.2666 (0.9608)	Arch Loss 3.8699 (4.1373)	Arch Hard Loss 1.4772 (1.7415)	Arch Beta Loss 2.3926 (2.3959)	Arch depth Loss 0.1693 (0.1680)	Prec@(1,5) (71.0%, 94.4%)	
12/22 08:23:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][200/390]	Step 22878	lr 0.01802	Loss 0.6528 (0.9640)	Arch Loss 3.9095 (4.1550)	Arch Hard Loss 1.5222 (1.7620)	Arch Beta Loss 2.3873 (2.3930)	Arch depth Loss 0.1720 (0.1691)	Prec@(1,5) (71.1%, 94.3%)	
12/22 08:24:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][300/390]	Step 22978	lr 0.01802	Loss 1.3755 (0.9780)	Arch Loss 4.2247 (4.1363)	Arch Hard Loss 1.8428 (1.7462)	Arch Beta Loss 2.3819 (2.3902)	Arch depth Loss 0.1703 (0.1700)	Prec@(1,5) (70.7%, 94.0%)	
12/22 08:25:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][390/390]	Step 23068	lr 0.01802	Loss 0.8210 (0.9854)	Arch Loss 4.4815 (4.1226)	Arch Hard Loss 2.1044 (1.7349)	Arch Beta Loss 2.3771 (2.3877)	Arch depth Loss 0.1727 (0.1705)	Prec@(1,5) (70.4%, 93.9%)	
12/22 08:25:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 58/159] Final Prec@1 70.4480%
12/22 08:25:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][100/391]	Step 23069	Loss 1.7198	Prec@(1,5) (54.8%, 83.4%)
12/22 08:25:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][200/391]	Step 23069	Loss 1.7124	Prec@(1,5) (54.5%, 83.7%)
12/22 08:25:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][300/391]	Step 23069	Loss 1.7254	Prec@(1,5) (54.3%, 83.4%)
12/22 08:26:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][390/391]	Step 23069	Loss 1.7262	Prec@(1,5) (54.3%, 83.5%)
12/22 08:26:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/159] Final Prec@1 54.2680%
12/22 08:26:06午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:26:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.2680%
12/22 08:27:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][100/390]	Step 23169	lr 0.01781	Loss 1.1424 (0.9074)	Arch Loss 4.1404 (4.1003)	Arch Hard Loss 1.7685 (1.7256)	Arch Beta Loss 2.3719 (2.3746)	Arch depth Loss 0.1716 (0.1722)	Prec@(1,5) (72.5%, 95.0%)	
12/22 08:27:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][200/390]	Step 23269	lr 0.01781	Loss 1.0825 (0.9239)	Arch Loss 3.7687 (4.1147)	Arch Hard Loss 1.4019 (1.7428)	Arch Beta Loss 2.3668 (2.3719)	Arch depth Loss 0.1731 (0.1723)	Prec@(1,5) (72.0%, 94.8%)	
12/22 08:28:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][300/390]	Step 23369	lr 0.01781	Loss 1.1320 (0.9565)	Arch Loss 3.7965 (4.0962)	Arch Hard Loss 1.4344 (1.7268)	Arch Beta Loss 2.3621 (2.3694)	Arch depth Loss 0.1741 (0.1729)	Prec@(1,5) (71.1%, 94.4%)	
12/22 08:29:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][390/390]	Step 23459	lr 0.01781	Loss 1.2259 (0.9705)	Arch Loss 4.2381 (4.0963)	Arch Hard Loss 1.8799 (1.7291)	Arch Beta Loss 2.3582 (2.3672)	Arch depth Loss 0.1770 (0.1736)	Prec@(1,5) (70.7%, 94.2%)	
12/22 08:29:36午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 59/159] Final Prec@1 70.7400%
12/22 08:29:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][100/391]	Step 23460	Loss 1.7358	Prec@(1,5) (54.2%, 83.1%)
12/22 08:29:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][200/391]	Step 23460	Loss 1.7251	Prec@(1,5) (54.6%, 83.2%)
12/22 08:30:00午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][300/391]	Step 23460	Loss 1.7232	Prec@(1,5) (54.6%, 83.2%)
12/22 08:30:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][390/391]	Step 23460	Loss 1.7206	Prec@(1,5) (54.6%, 83.2%)
12/22 08:30:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/159] Final Prec@1 54.6120%
12/22 08:30:08午前 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 08:30:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:30:09午前 searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
12/22 08:30:09午前 searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 1., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 1., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 1., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 1., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 1., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 1., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [1., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
#####################
12/22 08:30:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][100/703]	Step 23560	lr 0.025	Loss 2.4322 (2.4457)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (36.1%, 68.8%)	
12/22 08:30:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][200/703]	Step 23660	lr 0.025	Loss 2.1888 (2.2984)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (39.1%, 72.0%)	
12/22 08:31:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][300/703]	Step 23760	lr 0.025	Loss 1.9735 (2.2066)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (41.1%, 73.9%)	
12/22 08:31:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][400/703]	Step 23860	lr 0.025	Loss 1.8515 (2.1497)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.4%, 75.0%)	
12/22 08:31:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][500/703]	Step 23960	lr 0.025	Loss 1.8797 (2.1156)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.2%, 75.7%)	
12/22 08:32:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][600/703]	Step 24060	lr 0.025	Loss 1.8063 (2.0886)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.9%, 76.3%)	
12/22 08:32:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][700/703]	Step 24160	lr 0.025	Loss 2.1172 (2.0572)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.6%, 76.8%)	
12/22 08:32:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][703/703]	Step 24163	lr 0.025	Loss 1.9876 (2.0565)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.7%, 76.8%)	
12/22 08:32:37午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 60/159] Final Prec@1 44.6533%
12/22 08:32:44午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][78/79]	Step 24164	Loss 2.1853	Prec@(1,5) (42.7%, 75.6%)
12/22 08:32:44午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/159] Final Prec@1 42.7400%
12/22 08:32:44午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:33:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][100/703]	Step 24264	lr 0.02499	Loss 1.9548 (1.7895)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.9%, 81.7%)	
12/22 08:33:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][200/703]	Step 24364	lr 0.02499	Loss 1.6199 (1.7935)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 81.4%)	
12/22 08:33:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][300/703]	Step 24464	lr 0.02499	Loss 1.9100 (1.7973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.8%, 81.3%)	
12/22 08:34:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][400/703]	Step 24564	lr 0.02499	Loss 2.1089 (1.7964)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 81.4%)	
12/22 08:34:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][500/703]	Step 24664	lr 0.02499	Loss 1.6299 (1.7957)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 81.3%)	
12/22 08:34:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][600/703]	Step 24764	lr 0.02499	Loss 1.5340 (1.7885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (51.0%, 81.5%)	
12/22 08:35:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][700/703]	Step 24864	lr 0.02499	Loss 1.9776 (1.7899)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 81.4%)	
12/22 08:35:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][703/703]	Step 24867	lr 0.02499	Loss 1.5206 (1.7900)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.9%, 81.4%)	
12/22 08:35:10午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 61/159] Final Prec@1 50.8867%
12/22 08:35:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][78/79]	Step 24868	Loss 2.1279	Prec@(1,5) (44.0%, 75.5%)
12/22 08:35:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/159] Final Prec@1 43.9800%
12/22 08:35:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:35:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][100/703]	Step 24968	lr 0.02498	Loss 1.5390 (1.6927)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.1%)	
12/22 08:35:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][200/703]	Step 25068	lr 0.02498	Loss 1.7447 (1.6865)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.4%)	
12/22 08:36:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][300/703]	Step 25168	lr 0.02498	Loss 1.8456 (1.6983)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.5%, 83.2%)	
12/22 08:36:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][400/703]	Step 25268	lr 0.02498	Loss 2.4560 (1.6940)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.2%)	
12/22 08:37:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][500/703]	Step 25368	lr 0.02498	Loss 1.9644 (1.7004)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.1%)	
12/22 08:37:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][600/703]	Step 25468	lr 0.02498	Loss 1.6843 (1.6982)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.1%)	
12/22 08:37:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][700/703]	Step 25568	lr 0.02498	Loss 1.7483 (1.6976)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.1%)	
12/22 08:37:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][703/703]	Step 25571	lr 0.02498	Loss 1.4549 (1.6977)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.6%, 83.2%)	
12/22 08:37:43午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 62/159] Final Prec@1 52.6400%
12/22 08:37:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][78/79]	Step 25572	Loss 1.9109	Prec@(1,5) (48.4%, 79.7%)
12/22 08:37:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/159] Final Prec@1 48.3600%
12/22 08:37:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:38:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][100/703]	Step 25672	lr 0.02495	Loss 1.6563 (1.6089)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.7%, 84.0%)	
12/22 08:38:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][200/703]	Step 25772	lr 0.02495	Loss 1.5710 (1.6068)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.1%, 84.3%)	
12/22 08:38:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][300/703]	Step 25872	lr 0.02495	Loss 1.4714 (1.6035)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.2%, 84.5%)	
12/22 08:39:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][400/703]	Step 25972	lr 0.02495	Loss 1.6478 (1.6061)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.1%, 84.5%)	
12/22 08:39:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][500/703]	Step 26072	lr 0.02495	Loss 1.4299 (1.6120)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.0%, 84.5%)	
12/22 08:39:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][600/703]	Step 26172	lr 0.02495	Loss 1.8825 (1.6196)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.4%)	
12/22 08:40:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][700/703]	Step 26272	lr 0.02495	Loss 1.7364 (1.6236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.4%)	
12/22 08:40:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][703/703]	Step 26275	lr 0.02495	Loss 1.4791 (1.6236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (54.8%, 84.4%)	
12/22 08:40:16午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 63/159] Final Prec@1 54.8067%
12/22 08:40:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][78/79]	Step 26276	Loss 2.0863	Prec@(1,5) (46.0%, 76.9%)
12/22 08:40:23午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/159] Final Prec@1 46.0000%
12/22 08:40:23午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:40:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][100/703]	Step 26376	lr 0.02491	Loss 1.3951 (1.5358)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.6%, 86.0%)	
12/22 08:41:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][200/703]	Step 26476	lr 0.02491	Loss 1.5301 (1.5468)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.8%)	
12/22 08:41:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][300/703]	Step 26576	lr 0.02491	Loss 1.9062 (1.5530)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.5%)	
12/22 08:41:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][400/703]	Step 26676	lr 0.02491	Loss 1.6351 (1.5608)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.5%)	
12/22 08:42:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][500/703]	Step 26776	lr 0.02491	Loss 1.6564 (1.5661)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.4%)	
12/22 08:42:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][600/703]	Step 26876	lr 0.02491	Loss 1.5704 (1.5732)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.1%, 85.3%)	
12/22 08:42:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][700/703]	Step 26976	lr 0.02491	Loss 1.4866 (1.5731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.2%)	
12/22 08:42:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][703/703]	Step 26979	lr 0.02491	Loss 1.6834 (1.5732)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.0%, 85.2%)	
12/22 08:42:49午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 64/159] Final Prec@1 56.0244%
12/22 08:42:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][78/79]	Step 26980	Loss 2.0295	Prec@(1,5) (45.6%, 78.1%)
12/22 08:42:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/159] Final Prec@1 45.6000%
12/22 08:42:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:43:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][100/703]	Step 27080	lr 0.02485	Loss 1.4687 (1.5074)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.3%)	
12/22 08:43:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][200/703]	Step 27180	lr 0.02485	Loss 1.3599 (1.5172)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.0%)	
12/22 08:43:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][300/703]	Step 27280	lr 0.02485	Loss 1.9140 (1.5143)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.1%)	
12/22 08:44:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][400/703]	Step 27380	lr 0.02485	Loss 1.4692 (1.5199)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.0%)	
12/22 08:44:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][500/703]	Step 27480	lr 0.02485	Loss 1.4664 (1.5288)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.1%, 85.9%)	
12/22 08:45:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][600/703]	Step 27580	lr 0.02485	Loss 1.3922 (1.5300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.1%, 85.8%)	
12/22 08:45:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][700/703]	Step 27680	lr 0.02485	Loss 1.5500 (1.5341)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 85.7%)	
12/22 08:45:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][703/703]	Step 27683	lr 0.02485	Loss 1.4439 (1.5342)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 85.7%)	
12/22 08:45:22午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 65/159] Final Prec@1 56.9578%
12/22 08:45:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][78/79]	Step 27684	Loss 1.8358	Prec@(1,5) (50.0%, 81.0%)
12/22 08:45:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/159] Final Prec@1 50.0600%
12/22 08:45:28午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:45:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][100/703]	Step 27784	lr 0.02479	Loss 1.5354 (1.5078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.0%, 86.5%)	
12/22 08:46:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][200/703]	Step 27884	lr 0.02479	Loss 1.1847 (1.4954)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.6%)	
12/22 08:46:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][300/703]	Step 27984	lr 0.02479	Loss 1.4183 (1.4999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.6%, 86.6%)	
12/22 08:46:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][400/703]	Step 28084	lr 0.02479	Loss 1.7168 (1.5014)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 86.6%)	
12/22 08:47:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][500/703]	Step 28184	lr 0.02479	Loss 1.5315 (1.5078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.2%, 86.4%)	
12/22 08:47:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][600/703]	Step 28284	lr 0.02479	Loss 1.7400 (1.5108)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 86.3%)	
12/22 08:47:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][700/703]	Step 28384	lr 0.02479	Loss 1.4289 (1.5066)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.4%)	
12/22 08:47:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][703/703]	Step 28387	lr 0.02479	Loss 1.3616 (1.5068)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 86.4%)	
12/22 08:47:54午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 66/159] Final Prec@1 57.3889%
12/22 08:48:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][78/79]	Step 28388	Loss 1.7736	Prec@(1,5) (51.7%, 82.0%)
12/22 08:48:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/159] Final Prec@1 51.7400%
12/22 08:48:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:48:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][100/703]	Step 28488	lr 0.02471	Loss 1.5109 (1.4189)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 88.0%)	
12/22 08:48:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][200/703]	Step 28588	lr 0.02471	Loss 1.3504 (1.4406)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.8%)	
12/22 08:49:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][300/703]	Step 28688	lr 0.02471	Loss 1.7358 (1.4511)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.6%, 87.5%)	
12/22 08:49:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][400/703]	Step 28788	lr 0.02471	Loss 1.3859 (1.4645)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 87.3%)	
12/22 08:49:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][500/703]	Step 28888	lr 0.02471	Loss 1.6210 (1.4713)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.0%, 87.1%)	
12/22 08:50:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][600/703]	Step 28988	lr 0.02471	Loss 1.3241 (1.4773)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.9%, 86.9%)	
12/22 08:50:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][700/703]	Step 29088	lr 0.02471	Loss 1.1145 (1.4681)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.0%)	
12/22 08:50:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][703/703]	Step 29091	lr 0.02471	Loss 1.8402 (1.4685)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 87.0%)	
12/22 08:50:27午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 67/159] Final Prec@1 58.1311%
12/22 08:50:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][78/79]	Step 29092	Loss 1.8237	Prec@(1,5) (51.9%, 81.1%)
12/22 08:50:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/159] Final Prec@1 51.9400%
12/22 08:50:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:50:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][100/703]	Step 29192	lr 0.02462	Loss 1.2555 (1.4312)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.7%)	
12/22 08:51:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][200/703]	Step 29292	lr 0.02462	Loss 1.5349 (1.4236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.4%)	
12/22 08:51:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][300/703]	Step 29392	lr 0.02462	Loss 1.4179 (1.4325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.2%, 87.2%)	
12/22 08:51:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][400/703]	Step 29492	lr 0.02462	Loss 1.4375 (1.4383)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 87.1%)	
12/22 08:52:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][500/703]	Step 29592	lr 0.02462	Loss 1.4852 (1.4463)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.1%)	
12/22 08:52:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][600/703]	Step 29692	lr 0.02462	Loss 1.3464 (1.4517)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.0%)	
12/22 08:52:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][700/703]	Step 29792	lr 0.02462	Loss 1.3235 (1.4527)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.8%, 87.0%)	
12/22 08:52:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][703/703]	Step 29795	lr 0.02462	Loss 1.9989 (1.4539)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.8%, 86.9%)	
12/22 08:53:00午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 68/159] Final Prec@1 58.7933%
12/22 08:53:06午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][78/79]	Step 29796	Loss 1.7534	Prec@(1,5) (52.2%, 82.7%)
12/22 08:53:06午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/159] Final Prec@1 52.2000%
12/22 08:53:06午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:53:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][100/703]	Step 29896	lr 0.02452	Loss 1.4436 (1.3581)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.4%)	
12/22 08:53:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][200/703]	Step 29996	lr 0.02452	Loss 1.4179 (1.3649)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.4%)	
12/22 08:54:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][300/703]	Step 30096	lr 0.02452	Loss 1.3750 (1.3911)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 87.9%)	
12/22 08:54:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][400/703]	Step 30196	lr 0.02452	Loss 1.2814 (1.4015)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.4%, 87.7%)	
12/22 08:54:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][500/703]	Step 30296	lr 0.02452	Loss 1.3377 (1.4035)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 87.8%)	
12/22 08:55:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][600/703]	Step 30396	lr 0.02452	Loss 1.4977 (1.4078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 87.7%)	
12/22 08:55:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][700/703]	Step 30496	lr 0.02452	Loss 1.8512 (1.4158)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.5%)	
12/22 08:55:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][703/703]	Step 30499	lr 0.02452	Loss 1.2679 (1.4155)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.5%)	
12/22 08:55:32午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 69/159] Final Prec@1 59.9778%
12/22 08:55:39午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][78/79]	Step 30500	Loss 1.8369	Prec@(1,5) (51.0%, 81.4%)
12/22 08:55:39午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/159] Final Prec@1 50.9000%
12/22 08:55:39午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:56:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][100/703]	Step 30600	lr 0.02441	Loss 1.5299 (1.3904)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.3%, 88.3%)	
12/22 08:56:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][200/703]	Step 30700	lr 0.02441	Loss 1.3828 (1.3905)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.2%)	
12/22 08:56:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][300/703]	Step 30800	lr 0.02441	Loss 1.4793 (1.3868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.2%)	
12/22 08:57:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][400/703]	Step 30900	lr 0.02441	Loss 1.6673 (1.3972)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 88.0%)	
12/22 08:57:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][500/703]	Step 31000	lr 0.02441	Loss 1.3790 (1.3978)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.9%)	
12/22 08:57:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][600/703]	Step 31100	lr 0.02441	Loss 1.0512 (1.3971)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.9%)	
12/22 08:58:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][700/703]	Step 31200	lr 0.02441	Loss 1.5589 (1.4047)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 87.8%)	
12/22 08:58:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][703/703]	Step 31203	lr 0.02441	Loss 1.2333 (1.4041)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.9%, 87.8%)	
12/22 08:58:05午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 70/159] Final Prec@1 59.8711%
12/22 08:58:12午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][78/79]	Step 31204	Loss 1.7794	Prec@(1,5) (51.5%, 81.9%)
12/22 08:58:12午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/159] Final Prec@1 51.4600%
12/22 08:58:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 08:58:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][100/703]	Step 31304	lr 0.02429	Loss 1.0935 (1.3280)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.2%)	
12/22 08:58:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][200/703]	Step 31404	lr 0.02429	Loss 1.0177 (1.3438)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 88.9%)	
12/22 08:59:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][300/703]	Step 31504	lr 0.02429	Loss 1.2526 (1.3515)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.8%)	
12/22 08:59:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][400/703]	Step 31604	lr 0.02429	Loss 1.4445 (1.3564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.7%)	
12/22 08:59:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][500/703]	Step 31704	lr 0.02429	Loss 1.1871 (1.3610)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.6%)	
12/22 09:00:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][600/703]	Step 31804	lr 0.02429	Loss 1.5896 (1.3673)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.0%, 88.4%)	
12/22 09:00:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][700/703]	Step 31904	lr 0.02429	Loss 1.0948 (1.3758)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.3%)	
12/22 09:00:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][703/703]	Step 31907	lr 0.02429	Loss 1.3232 (1.3763)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.2%)	
12/22 09:00:38午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 71/159] Final Prec@1 60.7600%
12/22 09:00:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][78/79]	Step 31908	Loss 1.7247	Prec@(1,5) (53.3%, 82.4%)
12/22 09:00:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/159] Final Prec@1 53.2800%
12/22 09:00:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:01:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][100/703]	Step 32008	lr 0.02416	Loss 1.5917 (1.3214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.1%)	
12/22 09:01:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][200/703]	Step 32108	lr 0.02416	Loss 1.2694 (1.3406)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.6%)	
12/22 09:01:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][300/703]	Step 32208	lr 0.02416	Loss 1.5143 (1.3433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.6%, 88.6%)	
12/22 09:02:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][400/703]	Step 32308	lr 0.02416	Loss 1.3359 (1.3423)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.8%)	
12/22 09:02:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][500/703]	Step 32408	lr 0.02416	Loss 1.6337 (1.3500)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.3%, 88.6%)	
12/22 09:02:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][600/703]	Step 32508	lr 0.02416	Loss 1.5062 (1.3532)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.5%)	
12/22 09:03:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][700/703]	Step 32608	lr 0.02416	Loss 1.3290 (1.3604)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.5%)	
12/22 09:03:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][703/703]	Step 32611	lr 0.02416	Loss 1.4079 (1.3618)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.2%, 88.5%)	
12/22 09:03:11午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 72/159] Final Prec@1 61.1600%
12/22 09:03:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][78/79]	Step 32612	Loss 1.7796	Prec@(1,5) (52.3%, 81.9%)
12/22 09:03:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/159] Final Prec@1 52.3600%
12/22 09:03:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:03:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][100/703]	Step 32712	lr 0.02401	Loss 1.2195 (1.3239)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.9%)	
12/22 09:04:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][200/703]	Step 32812	lr 0.02401	Loss 1.4512 (1.3127)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.3%)	
12/22 09:04:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][300/703]	Step 32912	lr 0.02401	Loss 1.0665 (1.3196)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.1%)	
12/22 09:04:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][400/703]	Step 33012	lr 0.02401	Loss 1.1857 (1.3258)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.1%)	
12/22 09:05:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][500/703]	Step 33112	lr 0.02401	Loss 0.9487 (1.3307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 89.0%)	
12/22 09:05:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][600/703]	Step 33212	lr 0.02401	Loss 1.4181 (1.3384)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.9%)	
12/22 09:05:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][700/703]	Step 33312	lr 0.02401	Loss 1.2551 (1.3424)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.8%)	
12/22 09:05:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][703/703]	Step 33315	lr 0.02401	Loss 1.2342 (1.3427)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.8%)	
12/22 09:05:44午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 73/159] Final Prec@1 61.4822%
12/22 09:05:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][78/79]	Step 33316	Loss 1.7716	Prec@(1,5) (52.5%, 82.3%)
12/22 09:05:50午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/159] Final Prec@1 52.5200%
12/22 09:05:50午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:06:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][100/703]	Step 33416	lr 0.02386	Loss 1.1225 (1.2839)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.1%)	
12/22 09:06:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][200/703]	Step 33516	lr 0.02386	Loss 1.3006 (1.3039)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.3%)	
12/22 09:06:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][300/703]	Step 33616	lr 0.02386	Loss 1.0571 (1.3230)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 89.0%)	
12/22 09:07:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][400/703]	Step 33716	lr 0.02386	Loss 1.5571 (1.3294)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 88.9%)	
12/22 09:07:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][500/703]	Step 33816	lr 0.02386	Loss 1.4616 (1.3312)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 88.8%)	
12/22 09:07:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][600/703]	Step 33916	lr 0.02386	Loss 1.3958 (1.3314)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.8%)	
12/22 09:08:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][700/703]	Step 34016	lr 0.02386	Loss 1.2998 (1.3308)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.8%)	
12/22 09:08:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][703/703]	Step 34019	lr 0.02386	Loss 1.2263 (1.3312)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.8%)	
12/22 09:08:17午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 74/159] Final Prec@1 61.8489%
12/22 09:08:23午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][78/79]	Step 34020	Loss 1.8061	Prec@(1,5) (51.2%, 82.0%)
12/22 09:08:23午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/159] Final Prec@1 51.2400%
12/22 09:08:23午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:08:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][100/703]	Step 34120	lr 0.02369	Loss 1.0276 (1.2322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.4%)	
12/22 09:09:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][200/703]	Step 34220	lr 0.02369	Loss 1.0842 (1.2561)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.8%)	
12/22 09:09:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][300/703]	Step 34320	lr 0.02369	Loss 1.6661 (1.2686)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.6%, 89.7%)	
12/22 09:09:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][400/703]	Step 34420	lr 0.02369	Loss 1.3508 (1.2796)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.7%)	
12/22 09:10:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][500/703]	Step 34520	lr 0.02369	Loss 1.1679 (1.2907)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.5%)	
12/22 09:10:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][600/703]	Step 34620	lr 0.02369	Loss 1.7294 (1.3023)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.4%)	
12/22 09:10:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][700/703]	Step 34720	lr 0.02369	Loss 1.6635 (1.3101)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.4%, 89.3%)	
12/22 09:10:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][703/703]	Step 34723	lr 0.02369	Loss 1.4079 (1.3103)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.3%)	
12/22 09:10:50午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 75/159] Final Prec@1 62.4511%
12/22 09:10:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][78/79]	Step 34724	Loss 1.7653	Prec@(1,5) (53.0%, 82.2%)
12/22 09:10:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/159] Final Prec@1 52.9400%
12/22 09:10:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:11:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][100/703]	Step 34824	lr 0.02352	Loss 1.0960 (1.2238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 89.9%)	
12/22 09:11:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][200/703]	Step 34924	lr 0.02352	Loss 1.1262 (1.2361)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.0%)	
12/22 09:11:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][300/703]	Step 35024	lr 0.02352	Loss 1.2757 (1.2472)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 89.9%)	
12/22 09:12:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][400/703]	Step 35124	lr 0.02352	Loss 1.1033 (1.2616)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.5%, 89.8%)	
12/22 09:12:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][500/703]	Step 35224	lr 0.02352	Loss 1.3864 (1.2719)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.7%)	
12/22 09:13:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][600/703]	Step 35324	lr 0.02352	Loss 1.0914 (1.2827)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.6%)	
12/22 09:13:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][700/703]	Step 35424	lr 0.02352	Loss 1.6043 (1.2916)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.5%)	
12/22 09:13:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][703/703]	Step 35427	lr 0.02352	Loss 1.4013 (1.2914)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.5%)	
12/22 09:13:23午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 76/159] Final Prec@1 62.6711%
12/22 09:13:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][78/79]	Step 35428	Loss 1.6701	Prec@(1,5) (54.5%, 84.9%)
12/22 09:13:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/159] Final Prec@1 54.5000%
12/22 09:13:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:13:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][100/703]	Step 35528	lr 0.02333	Loss 1.3091 (1.2262)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 90.8%)	
12/22 09:14:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][200/703]	Step 35628	lr 0.02333	Loss 1.0958 (1.2628)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 90.0%)	
12/22 09:14:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][300/703]	Step 35728	lr 0.02333	Loss 1.2363 (1.2729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.9%)	
12/22 09:14:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][400/703]	Step 35828	lr 0.02333	Loss 1.4964 (1.2796)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.7%)	
12/22 09:15:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][500/703]	Step 35928	lr 0.02333	Loss 1.3686 (1.2823)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.7%)	
12/22 09:15:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][600/703]	Step 36028	lr 0.02333	Loss 1.2005 (1.2869)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.7%)	
12/22 09:15:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][700/703]	Step 36128	lr 0.02333	Loss 0.9136 (1.2855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.7%)	
12/22 09:15:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][703/703]	Step 36131	lr 0.02333	Loss 1.4936 (1.2856)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.7%)	
12/22 09:15:55午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 77/159] Final Prec@1 62.7733%
12/22 09:16:02午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][78/79]	Step 36132	Loss 1.7878	Prec@(1,5) (52.5%, 82.1%)
12/22 09:16:02午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/159] Final Prec@1 52.5400%
12/22 09:16:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:16:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][100/703]	Step 36232	lr 0.02313	Loss 1.4314 (1.2098)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 89.8%)	
12/22 09:16:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][200/703]	Step 36332	lr 0.02313	Loss 1.4281 (1.2258)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 89.8%)	
12/22 09:17:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][300/703]	Step 36432	lr 0.02313	Loss 0.9526 (1.2474)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 89.7%)	
12/22 09:17:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][400/703]	Step 36532	lr 0.02313	Loss 1.2420 (1.2497)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 89.8%)	
12/22 09:17:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][500/703]	Step 36632	lr 0.02313	Loss 1.1579 (1.2567)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 89.7%)	
12/22 09:18:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][600/703]	Step 36732	lr 0.02313	Loss 1.2057 (1.2604)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.7%)	
12/22 09:18:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][700/703]	Step 36832	lr 0.02313	Loss 1.5305 (1.2675)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.6%)	
12/22 09:18:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][703/703]	Step 36835	lr 0.02313	Loss 1.0997 (1.2673)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.6%)	
12/22 09:18:28午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 78/159] Final Prec@1 63.7289%
12/22 09:18:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][78/79]	Step 36836	Loss 1.7799	Prec@(1,5) (53.0%, 82.6%)
12/22 09:18:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/159] Final Prec@1 52.9800%
12/22 09:18:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:18:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][100/703]	Step 36936	lr 0.02292	Loss 1.2028 (1.1973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.8%)	
12/22 09:19:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][200/703]	Step 37036	lr 0.02292	Loss 1.2622 (1.1977)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 90.7%)	
12/22 09:19:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][300/703]	Step 37136	lr 0.02292	Loss 0.8298 (1.2156)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.5%)	
12/22 09:19:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][400/703]	Step 37236	lr 0.02292	Loss 1.1549 (1.2292)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.3%)	
12/22 09:20:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][500/703]	Step 37336	lr 0.02292	Loss 1.1042 (1.2394)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.1%)	
12/22 09:20:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][600/703]	Step 37436	lr 0.02292	Loss 1.3851 (1.2466)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 90.1%)	
12/22 09:21:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][700/703]	Step 37536	lr 0.02292	Loss 1.3955 (1.2493)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 89.9%)	
12/22 09:21:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][703/703]	Step 37539	lr 0.02292	Loss 1.1685 (1.2497)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.1%, 89.9%)	
12/22 09:21:01午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 79/159] Final Prec@1 64.0800%
12/22 09:21:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][78/79]	Step 37540	Loss 1.6759	Prec@(1,5) (54.5%, 83.7%)
12/22 09:21:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/159] Final Prec@1 54.5200%
12/22 09:21:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.6120%
12/22 09:21:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][100/703]	Step 37640	lr 0.02271	Loss 1.2731 (1.1730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.4%)	
12/22 09:21:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][200/703]	Step 37740	lr 0.02271	Loss 1.3209 (1.1835)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.3%)	
12/22 09:22:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][300/703]	Step 37840	lr 0.02271	Loss 1.1125 (1.2066)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.8%)	
12/22 09:22:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][400/703]	Step 37940	lr 0.02271	Loss 1.1303 (1.2221)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.5%)	
12/22 09:22:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][500/703]	Step 38040	lr 0.02271	Loss 1.2507 (1.2325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.4%)	
12/22 09:23:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][600/703]	Step 38140	lr 0.02271	Loss 1.1200 (1.2401)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.2%)	
12/22 09:23:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][700/703]	Step 38240	lr 0.02271	Loss 1.4848 (1.2371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.2%)	
12/22 09:23:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][703/703]	Step 38243	lr 0.02271	Loss 1.3359 (1.2375)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.2%)	
12/22 09:23:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 80/159] Final Prec@1 64.3022%
12/22 09:23:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][78/79]	Step 38244	Loss 1.6950	Prec@(1,5) (54.8%, 83.9%)
12/22 09:23:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/159] Final Prec@1 54.8600%
12/22 09:23:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.8600%
12/22 09:24:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][100/703]	Step 38344	lr 0.02248	Loss 1.5200 (1.2045)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.8%)	
12/22 09:24:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][200/703]	Step 38444	lr 0.02248	Loss 1.3154 (1.2076)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.8%)	
12/22 09:24:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][300/703]	Step 38544	lr 0.02248	Loss 1.3380 (1.2149)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.5%)	
12/22 09:25:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][400/703]	Step 38644	lr 0.02248	Loss 0.8504 (1.2224)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.4%)	
12/22 09:25:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][500/703]	Step 38744	lr 0.02248	Loss 1.0658 (1.2268)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
12/22 09:25:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][600/703]	Step 38844	lr 0.02248	Loss 1.0504 (1.2262)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.7%, 90.4%)	
12/22 09:26:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][700/703]	Step 38944	lr 0.02248	Loss 1.3767 (1.2303)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.3%)	
12/22 09:26:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][703/703]	Step 38947	lr 0.02248	Loss 1.3034 (1.2309)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.3%)	
12/22 09:26:07午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 81/159] Final Prec@1 64.4689%
12/22 09:26:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][78/79]	Step 38948	Loss 1.6657	Prec@(1,5) (55.0%, 83.9%)
12/22 09:26:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/159] Final Prec@1 55.0200%
12/22 09:26:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.0200%
12/22 09:26:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][100/703]	Step 39048	lr 0.02225	Loss 1.0647 (1.1595)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.4%)	
12/22 09:26:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][200/703]	Step 39148	lr 0.02225	Loss 1.2064 (1.1672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.2%)	
12/22 09:27:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][300/703]	Step 39248	lr 0.02225	Loss 0.9856 (1.1665)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.2%)	
12/22 09:27:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][400/703]	Step 39348	lr 0.02225	Loss 1.3666 (1.1750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.0%)	
12/22 09:27:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][500/703]	Step 39448	lr 0.02225	Loss 1.3626 (1.1904)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.9%)	
12/22 09:28:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][600/703]	Step 39548	lr 0.02225	Loss 1.2694 (1.2019)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.7%)	
12/22 09:28:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][700/703]	Step 39648	lr 0.02225	Loss 1.4845 (1.2077)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.6%)	
12/22 09:28:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][703/703]	Step 39651	lr 0.02225	Loss 1.2110 (1.2072)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.0%, 90.6%)	
12/22 09:28:41午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 82/159] Final Prec@1 65.0089%
12/22 09:28:47午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][78/79]	Step 39652	Loss 1.6347	Prec@(1,5) (55.3%, 84.7%)
12/22 09:28:47午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/159] Final Prec@1 55.2800%
12/22 09:28:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 55.2800%
12/22 09:29:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][100/703]	Step 39752	lr 0.022	Loss 0.9273 (1.1408)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.4%)	
12/22 09:29:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][200/703]	Step 39852	lr 0.022	Loss 0.9644 (1.1765)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.0%)	
12/22 09:29:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][300/703]	Step 39952	lr 0.022	Loss 1.0937 (1.1751)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 91.1%)	
12/22 09:30:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][400/703]	Step 40052	lr 0.022	Loss 1.3323 (1.1785)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.0%)	
12/22 09:30:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][500/703]	Step 40152	lr 0.022	Loss 1.1046 (1.1903)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.8%)	
12/22 09:30:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][600/703]	Step 40252	lr 0.022	Loss 1.2334 (1.1976)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.8%)	
12/22 09:31:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][700/703]	Step 40352	lr 0.022	Loss 1.3645 (1.2053)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.6%)	
12/22 09:31:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][703/703]	Step 40355	lr 0.022	Loss 1.3498 (1.2066)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.6%)	
12/22 09:31:14午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 83/159] Final Prec@1 64.8067%
12/22 09:31:20午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][78/79]	Step 40356	Loss 1.6131	Prec@(1,5) (56.7%, 84.6%)
12/22 09:31:20午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/159] Final Prec@1 56.7000%
12/22 09:31:20午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:31:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][100/703]	Step 40456	lr 0.02175	Loss 1.2000 (1.1384)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.4%)	
12/22 09:32:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][200/703]	Step 40556	lr 0.02175	Loss 1.0507 (1.1395)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.3%)	
12/22 09:32:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][300/703]	Step 40656	lr 0.02175	Loss 0.8990 (1.1577)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.0%)	
12/22 09:32:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][400/703]	Step 40756	lr 0.02175	Loss 1.1895 (1.1703)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 90.9%)	
12/22 09:33:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][500/703]	Step 40856	lr 0.02175	Loss 1.4386 (1.1795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 90.8%)	
12/22 09:33:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][600/703]	Step 40956	lr 0.02175	Loss 0.9967 (1.1862)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 90.7%)	
12/22 09:33:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][700/703]	Step 41056	lr 0.02175	Loss 1.3917 (1.1901)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.7%)	
12/22 09:33:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][703/703]	Step 41059	lr 0.02175	Loss 1.1959 (1.1893)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 90.7%)	
12/22 09:33:46午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 84/159] Final Prec@1 65.4267%
12/22 09:33:52午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][78/79]	Step 41060	Loss 1.6720	Prec@(1,5) (55.4%, 84.6%)
12/22 09:33:52午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/159] Final Prec@1 55.3600%
12/22 09:33:52午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:34:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][100/703]	Step 41160	lr 0.02149	Loss 1.1463 (1.1002)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.1%)	
12/22 09:34:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][200/703]	Step 41260	lr 0.02149	Loss 1.2430 (1.1300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.7%)	
12/22 09:34:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][300/703]	Step 41360	lr 0.02149	Loss 1.1120 (1.1452)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.4%, 91.5%)	
12/22 09:35:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][400/703]	Step 41460	lr 0.02149	Loss 1.4007 (1.1511)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.3%)	
12/22 09:35:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][500/703]	Step 41560	lr 0.02149	Loss 1.2967 (1.1573)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.2%)	
12/22 09:35:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][600/703]	Step 41660	lr 0.02149	Loss 1.2104 (1.1677)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.0%)	
12/22 09:36:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][700/703]	Step 41760	lr 0.02149	Loss 1.0253 (1.1712)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.0%)	
12/22 09:36:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][703/703]	Step 41763	lr 0.02149	Loss 1.3026 (1.1715)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.0%)	
12/22 09:36:19午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 85/159] Final Prec@1 65.8244%
12/22 09:36:25午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][78/79]	Step 41764	Loss 1.7197	Prec@(1,5) (54.1%, 83.0%)
12/22 09:36:25午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/159] Final Prec@1 54.1400%
12/22 09:36:25午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:36:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][100/703]	Step 41864	lr 0.02121	Loss 1.2895 (1.0969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.2%)	
12/22 09:37:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][200/703]	Step 41964	lr 0.02121	Loss 0.9480 (1.1109)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.3%, 92.0%)	
12/22 09:37:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][300/703]	Step 42064	lr 0.02121	Loss 1.0419 (1.1304)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.1%, 91.7%)	
12/22 09:37:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][400/703]	Step 42164	lr 0.02121	Loss 1.3283 (1.1399)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.5%)	
12/22 09:38:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][500/703]	Step 42264	lr 0.02121	Loss 1.0962 (1.1494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.3%)	
12/22 09:38:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][600/703]	Step 42364	lr 0.02121	Loss 0.8477 (1.1579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.2%)	
12/22 09:38:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][700/703]	Step 42464	lr 0.02121	Loss 1.1079 (1.1628)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.2%)	
12/22 09:38:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][703/703]	Step 42467	lr 0.02121	Loss 1.0320 (1.1633)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.2%)	
12/22 09:38:52午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 86/159] Final Prec@1 66.1889%
12/22 09:38:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][78/79]	Step 42468	Loss 1.7960	Prec@(1,5) (52.5%, 82.2%)
12/22 09:38:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/159] Final Prec@1 52.4800%
12/22 09:38:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:39:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][100/703]	Step 42568	lr 0.02094	Loss 0.8475 (1.1126)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 91.7%)	
12/22 09:39:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][200/703]	Step 42668	lr 0.02094	Loss 1.2789 (1.1090)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 91.7%)	
12/22 09:40:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][300/703]	Step 42768	lr 0.02094	Loss 1.3503 (1.1183)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.6%)	
12/22 09:40:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][400/703]	Step 42868	lr 0.02094	Loss 1.3443 (1.1322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.5%)	
12/22 09:40:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][500/703]	Step 42968	lr 0.02094	Loss 1.4148 (1.1380)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 91.4%)	
12/22 09:41:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][600/703]	Step 43068	lr 0.02094	Loss 1.4246 (1.1394)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.4%)	
12/22 09:41:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][700/703]	Step 43168	lr 0.02094	Loss 1.1790 (1.1450)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.3%)	
12/22 09:41:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][703/703]	Step 43171	lr 0.02094	Loss 1.4445 (1.1468)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.3%)	
12/22 09:41:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 87/159] Final Prec@1 66.5489%
12/22 09:41:32午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][78/79]	Step 43172	Loss 1.6471	Prec@(1,5) (55.4%, 84.7%)
12/22 09:41:32午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/159] Final Prec@1 55.3600%
12/22 09:41:32午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:41:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][100/703]	Step 43272	lr 0.02065	Loss 1.2644 (1.0859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.3%)	
12/22 09:42:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][200/703]	Step 43372	lr 0.02065	Loss 1.0139 (1.0909)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.3%)	
12/22 09:42:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][300/703]	Step 43472	lr 0.02065	Loss 1.5844 (1.1056)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.2%)	
12/22 09:42:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][400/703]	Step 43572	lr 0.02065	Loss 1.1383 (1.1200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 92.0%)	
12/22 09:43:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][500/703]	Step 43672	lr 0.02065	Loss 1.3343 (1.1251)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 92.0%)	
12/22 09:43:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][600/703]	Step 43772	lr 0.02065	Loss 1.5680 (1.1333)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.8%)	
12/22 09:43:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][700/703]	Step 43872	lr 0.02065	Loss 1.3916 (1.1375)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.8%)	
12/22 09:43:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][703/703]	Step 43875	lr 0.02065	Loss 1.2529 (1.1377)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.8%)	
12/22 09:43:59午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 88/159] Final Prec@1 66.1578%
12/22 09:44:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][78/79]	Step 43876	Loss 1.7742	Prec@(1,5) (53.6%, 83.1%)
12/22 09:44:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/159] Final Prec@1 53.6000%
12/22 09:44:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:44:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][100/703]	Step 43976	lr 0.02035	Loss 1.0467 (1.0846)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.8%)	
12/22 09:44:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][200/703]	Step 44076	lr 0.02035	Loss 0.7455 (1.0818)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.9%)	
12/22 09:45:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][300/703]	Step 44176	lr 0.02035	Loss 0.9577 (1.0922)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.4%, 92.5%)	
12/22 09:45:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][400/703]	Step 44276	lr 0.02035	Loss 1.2502 (1.1057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.2%)	
12/22 09:45:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][500/703]	Step 44376	lr 0.02035	Loss 1.1359 (1.1073)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 92.1%)	
12/22 09:46:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][600/703]	Step 44476	lr 0.02035	Loss 1.3536 (1.1149)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 92.0%)	
12/22 09:46:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][700/703]	Step 44576	lr 0.02035	Loss 1.2631 (1.1218)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.8%)	
12/22 09:46:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][703/703]	Step 44579	lr 0.02035	Loss 1.0382 (1.1213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.8%)	
12/22 09:46:32午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 89/159] Final Prec@1 66.9089%
12/22 09:46:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][78/79]	Step 44580	Loss 1.7459	Prec@(1,5) (53.7%, 83.3%)
12/22 09:46:39午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/159] Final Prec@1 53.7200%
12/22 09:46:39午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:47:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][100/703]	Step 44680	lr 0.02005	Loss 1.0962 (1.0663)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.4%)	
12/22 09:47:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][200/703]	Step 44780	lr 0.02005	Loss 1.3048 (1.0746)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.3%)	
12/22 09:47:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][300/703]	Step 44880	lr 0.02005	Loss 1.0651 (1.0842)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.1%)	
12/22 09:48:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][400/703]	Step 44980	lr 0.02005	Loss 1.0204 (1.0943)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.0%)	
12/22 09:48:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][500/703]	Step 45080	lr 0.02005	Loss 1.1147 (1.1018)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 91.9%)	
12/22 09:48:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][600/703]	Step 45180	lr 0.02005	Loss 1.2312 (1.1059)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.9%)	
12/22 09:49:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][700/703]	Step 45280	lr 0.02005	Loss 1.1541 (1.1140)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.8%)	
12/22 09:49:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][703/703]	Step 45283	lr 0.02005	Loss 1.1016 (1.1145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.8%)	
12/22 09:49:04午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 90/159] Final Prec@1 67.1956%
12/22 09:49:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][78/79]	Step 45284	Loss 1.6719	Prec@(1,5) (55.9%, 84.5%)
12/22 09:49:11午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/159] Final Prec@1 55.8600%
12/22 09:49:11午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:49:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][100/703]	Step 45384	lr 0.01975	Loss 1.0288 (1.0450)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 92.7%)	
12/22 09:49:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][200/703]	Step 45484	lr 0.01975	Loss 0.8886 (1.0648)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.4%)	
12/22 09:50:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][300/703]	Step 45584	lr 0.01975	Loss 1.2981 (1.0761)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.2%)	
12/22 09:50:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][400/703]	Step 45684	lr 0.01975	Loss 1.1206 (1.0852)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.2%)	
12/22 09:50:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][500/703]	Step 45784	lr 0.01975	Loss 1.2992 (1.0904)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.1%)	
12/22 09:51:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][600/703]	Step 45884	lr 0.01975	Loss 1.1582 (1.0955)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.8%, 92.0%)	
12/22 09:51:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][700/703]	Step 45984	lr 0.01975	Loss 0.9138 (1.1025)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 91.9%)	
12/22 09:51:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][703/703]	Step 45987	lr 0.01975	Loss 1.1429 (1.1030)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 91.9%)	
12/22 09:51:37午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 91/159] Final Prec@1 67.5867%
12/22 09:51:43午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][78/79]	Step 45988	Loss 1.6185	Prec@(1,5) (56.2%, 84.6%)
12/22 09:51:43午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/159] Final Prec@1 56.2400%
12/22 09:51:43午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7000%
12/22 09:52:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][100/703]	Step 46088	lr 0.01943	Loss 1.2092 (1.0253)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 92.7%)	
12/22 09:52:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][200/703]	Step 46188	lr 0.01943	Loss 0.8382 (1.0495)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.4%)	
12/22 09:52:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][300/703]	Step 46288	lr 0.01943	Loss 0.9971 (1.0552)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.6%)	
12/22 09:53:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][400/703]	Step 46388	lr 0.01943	Loss 0.9853 (1.0625)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.5%)	
12/22 09:53:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][500/703]	Step 46488	lr 0.01943	Loss 1.0779 (1.0692)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.3%)	
12/22 09:53:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][600/703]	Step 46588	lr 0.01943	Loss 1.2011 (1.0787)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.2%)	
12/22 09:54:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][700/703]	Step 46688	lr 0.01943	Loss 1.3564 (1.0862)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.2%)	
12/22 09:54:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][703/703]	Step 46691	lr 0.01943	Loss 0.9859 (1.0857)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.2%)	
12/22 09:54:09午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 92/159] Final Prec@1 68.1822%
12/22 09:54:16午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][78/79]	Step 46692	Loss 1.5967	Prec@(1,5) (56.7%, 85.7%)
12/22 09:54:16午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/159] Final Prec@1 56.7600%
12/22 09:54:16午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7600%
12/22 09:54:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][100/703]	Step 46792	lr 0.01911	Loss 0.8794 (0.9949)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.3%)	
12/22 09:54:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][200/703]	Step 46892	lr 0.01911	Loss 1.1435 (1.0238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.0%)	
12/22 09:55:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][300/703]	Step 46992	lr 0.01911	Loss 1.1264 (1.0412)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.9%)	
12/22 09:55:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][400/703]	Step 47092	lr 0.01911	Loss 1.3830 (1.0523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.7%)	
12/22 09:56:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][500/703]	Step 47192	lr 0.01911	Loss 1.1533 (1.0585)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 92.7%)	
12/22 09:56:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][600/703]	Step 47292	lr 0.01911	Loss 1.3229 (1.0731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.4%)	
12/22 09:56:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][700/703]	Step 47392	lr 0.01911	Loss 0.9921 (1.0813)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.3%)	
12/22 09:56:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][703/703]	Step 47395	lr 0.01911	Loss 1.1391 (1.0821)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.3%)	
12/22 09:56:43午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 93/159] Final Prec@1 68.2911%
12/22 09:56:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][78/79]	Step 47396	Loss 1.5990	Prec@(1,5) (56.5%, 84.4%)
12/22 09:56:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/159] Final Prec@1 56.5000%
12/22 09:56:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.7600%
12/22 09:57:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][100/703]	Step 47496	lr 0.01878	Loss 0.8646 (0.9761)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.5%)	
12/22 09:57:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][200/703]	Step 47596	lr 0.01878	Loss 1.0637 (1.0004)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.2%)	
12/22 09:57:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][300/703]	Step 47696	lr 0.01878	Loss 1.0097 (1.0129)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
12/22 09:58:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][400/703]	Step 47796	lr 0.01878	Loss 1.0351 (1.0235)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 93.0%)	
12/22 09:58:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][500/703]	Step 47896	lr 0.01878	Loss 1.2533 (1.0378)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.8%)	
12/22 09:58:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][600/703]	Step 47996	lr 0.01878	Loss 0.8189 (1.0501)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.7%)	
12/22 09:59:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][700/703]	Step 48096	lr 0.01878	Loss 1.0142 (1.0579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.6%)	
12/22 09:59:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][703/703]	Step 48099	lr 0.01878	Loss 1.6474 (1.0595)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.6%)	
12/22 09:59:16午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 94/159] Final Prec@1 68.6667%
12/22 09:59:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][78/79]	Step 48100	Loss 1.5897	Prec@(1,5) (57.5%, 85.4%)
12/22 09:59:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/159] Final Prec@1 57.5600%
12/22 09:59:23午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.5600%
12/22 09:59:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][100/703]	Step 48200	lr 0.01845	Loss 1.1921 (0.9870)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.5%)	
12/22 10:00:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][200/703]	Step 48300	lr 0.01845	Loss 1.1150 (0.9969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.3%)	
12/22 10:00:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][300/703]	Step 48400	lr 0.01845	Loss 0.7810 (1.0132)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.2%)	
12/22 10:00:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][400/703]	Step 48500	lr 0.01845	Loss 1.0320 (1.0232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.0%)	
12/22 10:01:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][500/703]	Step 48600	lr 0.01845	Loss 1.2158 (1.0274)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.0%)	
12/22 10:01:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][600/703]	Step 48700	lr 0.01845	Loss 1.2764 (1.0348)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.9%)	
12/22 10:01:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][700/703]	Step 48800	lr 0.01845	Loss 1.2471 (1.0442)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.8%)	
12/22 10:01:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][703/703]	Step 48803	lr 0.01845	Loss 0.9902 (1.0440)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.3%, 92.8%)	
12/22 10:01:49午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 95/159] Final Prec@1 69.2689%
12/22 10:01:56午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][78/79]	Step 48804	Loss 1.5909	Prec@(1,5) (57.4%, 86.0%)
12/22 10:01:56午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/159] Final Prec@1 57.3800%
12/22 10:01:56午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.5600%
12/22 10:02:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][100/703]	Step 48904	lr 0.01811	Loss 1.0071 (0.9755)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.5%)	
12/22 10:02:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][200/703]	Step 49004	lr 0.01811	Loss 0.9788 (0.9752)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.6%)	
12/22 10:02:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][300/703]	Step 49104	lr 0.01811	Loss 1.0558 (0.9940)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.3%)	
12/22 10:03:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][400/703]	Step 49204	lr 0.01811	Loss 1.2713 (0.9985)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.3%)	
12/22 10:03:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][500/703]	Step 49304	lr 0.01811	Loss 1.0366 (1.0141)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.1%)	
12/22 10:04:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][600/703]	Step 49404	lr 0.01811	Loss 1.0415 (1.0303)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.6%, 92.9%)	
12/22 10:04:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][700/703]	Step 49504	lr 0.01811	Loss 1.1660 (1.0361)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.8%)	
12/22 10:04:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][703/703]	Step 49507	lr 0.01811	Loss 1.0354 (1.0358)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 92.8%)	
12/22 10:04:22午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 96/159] Final Prec@1 69.5000%
12/22 10:04:28午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][78/79]	Step 49508	Loss 1.5309	Prec@(1,5) (59.0%, 86.2%)
12/22 10:04:28午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/159] Final Prec@1 58.9800%
12/22 10:04:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:04:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][100/703]	Step 49608	lr 0.01777	Loss 0.7000 (0.9601)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 94.3%)	
12/22 10:05:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][200/703]	Step 49708	lr 0.01777	Loss 0.7592 (0.9874)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.8%)	
12/22 10:05:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][300/703]	Step 49808	lr 0.01777	Loss 1.1453 (1.0010)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.5%)	
12/22 10:05:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][400/703]	Step 49908	lr 0.01777	Loss 1.4735 (1.0094)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.3%)	
12/22 10:06:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][500/703]	Step 50008	lr 0.01777	Loss 1.2351 (1.0119)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.3%)	
12/22 10:06:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][600/703]	Step 50108	lr 0.01777	Loss 0.8639 (1.0234)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.5%, 93.2%)	
12/22 10:06:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][700/703]	Step 50208	lr 0.01777	Loss 1.0701 (1.0310)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.1%)	
12/22 10:06:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][703/703]	Step 50211	lr 0.01777	Loss 0.8120 (1.0307)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.1%)	
12/22 10:06:55午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 97/159] Final Prec@1 69.3933%
12/22 10:07:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][78/79]	Step 50212	Loss 1.5792	Prec@(1,5) (57.2%, 85.9%)
12/22 10:07:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/159] Final Prec@1 57.2600%
12/22 10:07:01午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:07:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][100/703]	Step 50312	lr 0.01742	Loss 0.9287 (0.9792)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.6%)	
12/22 10:07:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][200/703]	Step 50412	lr 0.01742	Loss 0.8177 (0.9801)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.5%)	
12/22 10:08:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][300/703]	Step 50512	lr 0.01742	Loss 0.8708 (0.9951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.2%)	
12/22 10:08:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][400/703]	Step 50612	lr 0.01742	Loss 0.8879 (1.0009)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.1%)	
12/22 10:08:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][500/703]	Step 50712	lr 0.01742	Loss 1.2935 (1.0087)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.0%)	
12/22 10:09:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][600/703]	Step 50812	lr 0.01742	Loss 1.1975 (1.0125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.1%, 93.1%)	
12/22 10:09:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][700/703]	Step 50912	lr 0.01742	Loss 0.6584 (1.0189)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.0%)	
12/22 10:09:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][703/703]	Step 50915	lr 0.01742	Loss 1.0710 (1.0192)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.0%)	
12/22 10:09:28午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 98/159] Final Prec@1 70.0156%
12/22 10:09:34午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][78/79]	Step 50916	Loss 1.5726	Prec@(1,5) (57.5%, 85.6%)
12/22 10:09:34午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/159] Final Prec@1 57.5400%
12/22 10:09:34午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:09:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][100/703]	Step 51016	lr 0.01706	Loss 1.1055 (0.9176)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.5%)	
12/22 10:10:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][200/703]	Step 51116	lr 0.01706	Loss 1.0935 (0.9418)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.1%)	
12/22 10:10:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][300/703]	Step 51216	lr 0.01706	Loss 0.8472 (0.9651)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.7%)	
12/22 10:10:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][400/703]	Step 51316	lr 0.01706	Loss 0.9353 (0.9755)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.5%)	
12/22 10:11:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][500/703]	Step 51416	lr 0.01706	Loss 1.1842 (0.9823)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.4%)	
12/22 10:11:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][600/703]	Step 51516	lr 0.01706	Loss 1.2324 (0.9907)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.3%)	
12/22 10:12:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][700/703]	Step 51616	lr 0.01706	Loss 1.2949 (1.0030)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.2%)	
12/22 10:12:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][703/703]	Step 51619	lr 0.01706	Loss 0.7518 (1.0029)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.2%)	
12/22 10:12:01午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 99/159] Final Prec@1 70.3356%
12/22 10:12:07午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][78/79]	Step 51620	Loss 1.5241	Prec@(1,5) (58.5%, 85.6%)
12/22 10:12:07午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/159] Final Prec@1 58.5400%
12/22 10:12:07午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:12:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][100/703]	Step 51720	lr 0.01671	Loss 1.0763 (0.9128)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.2%)	
12/22 10:12:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][200/703]	Step 51820	lr 0.01671	Loss 1.1252 (0.9322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.2%, 94.2%)	
12/22 10:13:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][300/703]	Step 51920	lr 0.01671	Loss 1.0804 (0.9501)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.1%)	
12/22 10:13:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][400/703]	Step 52020	lr 0.01671	Loss 1.2372 (0.9638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.9%)	
12/22 10:13:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][500/703]	Step 52120	lr 0.01671	Loss 0.7176 (0.9730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.6%)	
12/22 10:14:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][600/703]	Step 52220	lr 0.01671	Loss 1.0686 (0.9728)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.1%, 93.6%)	
12/22 10:14:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][700/703]	Step 52320	lr 0.01671	Loss 0.8789 (0.9841)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.4%)	
12/22 10:14:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][703/703]	Step 52323	lr 0.01671	Loss 0.6685 (0.9828)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.4%)	
12/22 10:14:34午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [100/159] Final Prec@1 70.9578%
12/22 10:14:40午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][78/79]	Step 52324	Loss 1.5212	Prec@(1,5) (58.0%, 86.5%)
12/22 10:14:40午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/159] Final Prec@1 58.0200%
12/22 10:14:40午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:15:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][100/703]	Step 52424	lr 0.01635	Loss 0.9274 (0.9252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 93.9%)	
12/22 10:15:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][200/703]	Step 52524	lr 0.01635	Loss 0.8962 (0.9331)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.1%)	
12/22 10:15:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][300/703]	Step 52624	lr 0.01635	Loss 1.0640 (0.9302)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.0%)	
12/22 10:16:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][400/703]	Step 52724	lr 0.01635	Loss 0.9729 (0.9451)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 93.9%)	
12/22 10:16:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][500/703]	Step 52824	lr 0.01635	Loss 0.9569 (0.9523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 93.8%)	
12/22 10:16:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][600/703]	Step 52924	lr 0.01635	Loss 1.2272 (0.9638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.7%)	
12/22 10:17:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][700/703]	Step 53024	lr 0.01635	Loss 0.9217 (0.9729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.6%)	
12/22 10:17:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][703/703]	Step 53027	lr 0.01635	Loss 1.2769 (0.9734)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.6%)	
12/22 10:17:06午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [101/159] Final Prec@1 71.3267%
12/22 10:17:13午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][78/79]	Step 53028	Loss 1.5549	Prec@(1,5) (58.6%, 86.1%)
12/22 10:17:13午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/159] Final Prec@1 58.5800%
12/22 10:17:13午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:17:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][100/703]	Step 53128	lr 0.01598	Loss 0.9660 (0.9276)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.3%)	
12/22 10:17:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][200/703]	Step 53228	lr 0.01598	Loss 0.8659 (0.9343)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.0%)	
12/22 10:18:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][300/703]	Step 53328	lr 0.01598	Loss 0.9063 (0.9413)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.0%, 94.0%)	
12/22 10:18:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][400/703]	Step 53428	lr 0.01598	Loss 0.7945 (0.9432)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 93.9%)	
12/22 10:18:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][500/703]	Step 53528	lr 0.01598	Loss 1.0925 (0.9590)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.8%)	
12/22 10:19:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][600/703]	Step 53628	lr 0.01598	Loss 1.2477 (0.9578)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.8%)	
12/22 10:19:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][700/703]	Step 53728	lr 0.01598	Loss 0.8690 (0.9651)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.4%, 93.7%)	
12/22 10:19:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][703/703]	Step 53731	lr 0.01598	Loss 1.0035 (0.9657)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.7%)	
12/22 10:19:39午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [102/159] Final Prec@1 71.3378%
12/22 10:19:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][78/79]	Step 53732	Loss 1.5885	Prec@(1,5) (57.9%, 85.5%)
12/22 10:19:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/159] Final Prec@1 57.9800%
12/22 10:19:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:20:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][100/703]	Step 53832	lr 0.01562	Loss 1.0103 (0.8736)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.7%)	
12/22 10:20:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][200/703]	Step 53932	lr 0.01562	Loss 0.8872 (0.9024)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.3%)	
12/22 10:20:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][300/703]	Step 54032	lr 0.01562	Loss 1.2842 (0.9194)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.2%)	
12/22 10:21:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][400/703]	Step 54132	lr 0.01562	Loss 1.1437 (0.9296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.1%)	
12/22 10:21:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][500/703]	Step 54232	lr 0.01562	Loss 0.8265 (0.9380)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.0%)	
12/22 10:21:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][600/703]	Step 54332	lr 0.01562	Loss 0.8679 (0.9494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 93.8%)	
12/22 10:22:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][700/703]	Step 54432	lr 0.01562	Loss 1.0332 (0.9557)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.8%)	
12/22 10:22:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][703/703]	Step 54435	lr 0.01562	Loss 0.8239 (0.9556)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.8%)	
12/22 10:22:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [103/159] Final Prec@1 71.5044%
12/22 10:22:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][78/79]	Step 54436	Loss 1.5559	Prec@(1,5) (58.0%, 86.5%)
12/22 10:22:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/159] Final Prec@1 58.0000%
12/22 10:22:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.9800%
12/22 10:22:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][100/703]	Step 54536	lr 0.01525	Loss 0.8399 (0.8887)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.8%)	
12/22 10:23:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][200/703]	Step 54636	lr 0.01525	Loss 0.9862 (0.9037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.7%)	
12/22 10:23:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][300/703]	Step 54736	lr 0.01525	Loss 0.9342 (0.9078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.5%)	
12/22 10:23:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][400/703]	Step 54836	lr 0.01525	Loss 1.0548 (0.9191)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.4%)	
12/22 10:24:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][500/703]	Step 54936	lr 0.01525	Loss 0.7027 (0.9328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.2%)	
12/22 10:24:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][600/703]	Step 55036	lr 0.01525	Loss 0.7973 (0.9406)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.2%)	
12/22 10:24:43午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][700/703]	Step 55136	lr 0.01525	Loss 0.6896 (0.9456)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.0%)	
12/22 10:24:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][703/703]	Step 55139	lr 0.01525	Loss 1.3733 (0.9462)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 94.0%)	
12/22 10:24:44午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [104/159] Final Prec@1 71.5267%
12/22 10:24:50午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][78/79]	Step 55140	Loss 1.5135	Prec@(1,5) (59.1%, 86.7%)
12/22 10:24:50午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/159] Final Prec@1 59.1000%
12/22 10:24:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.1000%
12/22 10:25:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][100/703]	Step 55240	lr 0.01488	Loss 1.1159 (0.8706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.7%)	
12/22 10:25:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][200/703]	Step 55340	lr 0.01488	Loss 1.0718 (0.8993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.5%)	
12/22 10:25:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][300/703]	Step 55440	lr 0.01488	Loss 1.1529 (0.9058)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.4%)	
12/22 10:26:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][400/703]	Step 55540	lr 0.01488	Loss 0.9537 (0.9148)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.4%)	
12/22 10:26:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][500/703]	Step 55640	lr 0.01488	Loss 1.0842 (0.9164)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.3%)	
12/22 10:26:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][600/703]	Step 55740	lr 0.01488	Loss 1.1279 (0.9216)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.5%, 94.3%)	
12/22 10:27:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][700/703]	Step 55840	lr 0.01488	Loss 0.8863 (0.9275)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.1%)	
12/22 10:27:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][703/703]	Step 55843	lr 0.01488	Loss 0.8502 (0.9278)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.1%)	
12/22 10:27:17午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [105/159] Final Prec@1 72.2800%
12/22 10:27:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][78/79]	Step 55844	Loss 1.4875	Prec@(1,5) (59.5%, 87.3%)
12/22 10:27:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/159] Final Prec@1 59.4400%
12/22 10:27:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.4400%
12/22 10:27:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][100/703]	Step 55944	lr 0.0145	Loss 0.7924 (0.8657)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.8%)	
12/22 10:28:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][200/703]	Step 56044	lr 0.0145	Loss 0.9858 (0.8758)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.7%)	
12/22 10:28:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][300/703]	Step 56144	lr 0.0145	Loss 0.8477 (0.8854)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.6%)	
12/22 10:28:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][400/703]	Step 56244	lr 0.0145	Loss 0.9022 (0.8969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.5%)	
12/22 10:29:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][500/703]	Step 56344	lr 0.0145	Loss 0.8158 (0.8988)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.5%)	
12/22 10:29:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][600/703]	Step 56444	lr 0.0145	Loss 1.1044 (0.9048)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.9%, 94.5%)	
12/22 10:29:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][700/703]	Step 56544	lr 0.0145	Loss 1.1919 (0.9082)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.4%)	
12/22 10:29:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][703/703]	Step 56547	lr 0.0145	Loss 1.0219 (0.9087)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.4%)	
12/22 10:29:51午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [106/159] Final Prec@1 72.7822%
12/22 10:29:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][78/79]	Step 56548	Loss 1.5506	Prec@(1,5) (58.2%, 86.7%)
12/22 10:29:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/159] Final Prec@1 58.1600%
12/22 10:29:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.4400%
12/22 10:30:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][100/703]	Step 56648	lr 0.01413	Loss 0.7565 (0.8381)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.4%)	
12/22 10:30:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][200/703]	Step 56748	lr 0.01413	Loss 0.7748 (0.8633)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
12/22 10:31:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][300/703]	Step 56848	lr 0.01413	Loss 0.7900 (0.8661)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
12/22 10:31:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][400/703]	Step 56948	lr 0.01413	Loss 0.6401 (0.8763)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.8%)	
12/22 10:31:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][500/703]	Step 57048	lr 0.01413	Loss 0.9122 (0.8868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.7%)	
12/22 10:32:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][600/703]	Step 57148	lr 0.01413	Loss 0.8673 (0.8941)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.6%)	
12/22 10:32:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][700/703]	Step 57248	lr 0.01413	Loss 0.9304 (0.8999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.6%)	
12/22 10:32:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][703/703]	Step 57251	lr 0.01413	Loss 0.7749 (0.8996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.1%, 94.6%)	
12/22 10:32:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [107/159] Final Prec@1 73.1000%
12/22 10:32:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][78/79]	Step 57252	Loss 1.4515	Prec@(1,5) (60.6%, 87.9%)
12/22 10:32:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/159] Final Prec@1 60.6000%
12/22 10:32:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:32:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][100/703]	Step 57352	lr 0.01375	Loss 0.6070 (0.8124)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.7%, 95.7%)	
12/22 10:33:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][200/703]	Step 57452	lr 0.01375	Loss 0.8226 (0.8216)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.6%)	
12/22 10:33:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][300/703]	Step 57552	lr 0.01375	Loss 0.9894 (0.8494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.0%)	
12/22 10:33:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][400/703]	Step 57652	lr 0.01375	Loss 0.8362 (0.8542)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 94.9%)	
12/22 10:34:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][500/703]	Step 57752	lr 0.01375	Loss 1.0857 (0.8670)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.8%)	
12/22 10:34:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][600/703]	Step 57852	lr 0.01375	Loss 0.9241 (0.8733)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.7%)	
12/22 10:34:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][700/703]	Step 57952	lr 0.01375	Loss 0.7824 (0.8823)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.6%)	
12/22 10:34:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][703/703]	Step 57955	lr 0.01375	Loss 0.6938 (0.8824)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.7%)	
12/22 10:34:56午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [108/159] Final Prec@1 73.4111%
12/22 10:35:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][78/79]	Step 57956	Loss 1.4963	Prec@(1,5) (59.9%, 86.6%)
12/22 10:35:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/159] Final Prec@1 59.8000%
12/22 10:35:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:35:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][100/703]	Step 58056	lr 0.01338	Loss 0.8271 (0.8210)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.6%)	
12/22 10:35:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][200/703]	Step 58156	lr 0.01338	Loss 0.8186 (0.8327)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.3%)	
12/22 10:36:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][300/703]	Step 58256	lr 0.01338	Loss 0.9103 (0.8453)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.1%)	
12/22 10:36:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][400/703]	Step 58356	lr 0.01338	Loss 0.7461 (0.8481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 95.1%)	
12/22 10:36:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][500/703]	Step 58456	lr 0.01338	Loss 1.0199 (0.8538)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 95.1%)	
12/22 10:37:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][600/703]	Step 58556	lr 0.01338	Loss 0.9363 (0.8647)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 94.9%)	
12/22 10:37:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][700/703]	Step 58656	lr 0.01338	Loss 0.8878 (0.8713)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.8%)	
12/22 10:37:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][703/703]	Step 58659	lr 0.01338	Loss 1.3057 (0.8722)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.8%)	
12/22 10:37:29午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [109/159] Final Prec@1 73.5378%
12/22 10:37:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][78/79]	Step 58660	Loss 1.4861	Prec@(1,5) (59.5%, 87.0%)
12/22 10:37:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/159] Final Prec@1 59.5800%
12/22 10:37:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:37:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][100/703]	Step 58760	lr 0.013	Loss 1.0138 (0.8168)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.2%)	
12/22 10:38:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][200/703]	Step 58860	lr 0.013	Loss 1.1037 (0.8177)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.4%)	
12/22 10:38:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][300/703]	Step 58960	lr 0.013	Loss 0.8287 (0.8288)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.2%)	
12/22 10:38:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][400/703]	Step 59060	lr 0.013	Loss 0.7533 (0.8355)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.8%, 95.2%)	
12/22 10:39:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][500/703]	Step 59160	lr 0.013	Loss 1.0730 (0.8433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.1%)	
12/22 10:39:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][600/703]	Step 59260	lr 0.013	Loss 0.6169 (0.8476)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.1%)	
12/22 10:40:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][700/703]	Step 59360	lr 0.013	Loss 0.5850 (0.8570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.0%)	
12/22 10:40:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][703/703]	Step 59363	lr 0.013	Loss 0.9116 (0.8566)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.0%)	
12/22 10:40:02午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [110/159] Final Prec@1 74.2578%
12/22 10:40:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][78/79]	Step 59364	Loss 1.5490	Prec@(1,5) (59.0%, 85.9%)
12/22 10:40:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/159] Final Prec@1 58.9800%
12/22 10:40:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:40:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][100/703]	Step 59464	lr 0.01262	Loss 1.1142 (0.8180)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.5%)	
12/22 10:40:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][200/703]	Step 59564	lr 0.01262	Loss 0.5445 (0.8088)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.6%)	
12/22 10:41:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][300/703]	Step 59664	lr 0.01262	Loss 0.7834 (0.8177)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.5%)	
12/22 10:41:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][400/703]	Step 59764	lr 0.01262	Loss 0.7206 (0.8181)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.4%)	
12/22 10:41:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][500/703]	Step 59864	lr 0.01262	Loss 0.9662 (0.8292)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.3%)	
12/22 10:42:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][600/703]	Step 59964	lr 0.01262	Loss 0.9581 (0.8367)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.3%)	
12/22 10:42:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][700/703]	Step 60064	lr 0.01262	Loss 0.8733 (0.8433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.2%)	
12/22 10:42:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][703/703]	Step 60067	lr 0.01262	Loss 0.7265 (0.8430)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 95.2%)	
12/22 10:42:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [111/159] Final Prec@1 74.2089%
12/22 10:42:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][78/79]	Step 60068	Loss 1.5121	Prec@(1,5) (59.5%, 86.9%)
12/22 10:42:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/159] Final Prec@1 59.5000%
12/22 10:42:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:43:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][100/703]	Step 60168	lr 0.01225	Loss 0.9553 (0.7707)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 96.1%)	
12/22 10:43:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][200/703]	Step 60268	lr 0.01225	Loss 0.8256 (0.7694)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.9%)	
12/22 10:43:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][300/703]	Step 60368	lr 0.01225	Loss 0.8551 (0.7886)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.7%)	
12/22 10:44:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][400/703]	Step 60468	lr 0.01225	Loss 0.9599 (0.8011)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.5%)	
12/22 10:44:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][500/703]	Step 60568	lr 0.01225	Loss 1.0349 (0.8138)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.4%, 95.4%)	
12/22 10:44:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][600/703]	Step 60668	lr 0.01225	Loss 1.2050 (0.8191)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.4%)	
12/22 10:45:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][700/703]	Step 60768	lr 0.01225	Loss 0.8567 (0.8276)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
12/22 10:45:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][703/703]	Step 60771	lr 0.01225	Loss 0.6094 (0.8274)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
12/22 10:45:08午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [112/159] Final Prec@1 74.8778%
12/22 10:45:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][78/79]	Step 60772	Loss 1.5693	Prec@(1,5) (58.3%, 85.9%)
12/22 10:45:15午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/159] Final Prec@1 58.2800%
12/22 10:45:15午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:45:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][100/703]	Step 60872	lr 0.01187	Loss 0.9170 (0.7579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.0%)	
12/22 10:45:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][200/703]	Step 60972	lr 0.01187	Loss 0.9764 (0.7622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 96.1%)	
12/22 10:46:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][300/703]	Step 61072	lr 0.01187	Loss 0.8658 (0.7804)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.9%)	
12/22 10:46:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][400/703]	Step 61172	lr 0.01187	Loss 0.6298 (0.7941)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.8%)	
12/22 10:46:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][500/703]	Step 61272	lr 0.01187	Loss 0.7129 (0.8006)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.6%)	
12/22 10:47:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][600/703]	Step 61372	lr 0.01187	Loss 0.8203 (0.8081)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.5%)	
12/22 10:47:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][700/703]	Step 61472	lr 0.01187	Loss 0.9320 (0.8130)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.4%)	
12/22 10:47:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][703/703]	Step 61475	lr 0.01187	Loss 0.6579 (0.8125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.4%)	
12/22 10:47:41午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [113/159] Final Prec@1 75.1800%
12/22 10:47:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][78/79]	Step 61476	Loss 1.4563	Prec@(1,5) (60.6%, 87.9%)
12/22 10:47:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/159] Final Prec@1 60.6000%
12/22 10:47:48午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:48:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][100/703]	Step 61576	lr 0.0115	Loss 0.9395 (0.7807)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.6%)	
12/22 10:48:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][200/703]	Step 61676	lr 0.0115	Loss 0.7203 (0.7685)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.8%)	
12/22 10:48:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][300/703]	Step 61776	lr 0.0115	Loss 0.5848 (0.7729)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 95.7%)	
12/22 10:49:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][400/703]	Step 61876	lr 0.0115	Loss 0.6934 (0.7830)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.6%)	
12/22 10:49:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][500/703]	Step 61976	lr 0.0115	Loss 0.9422 (0.7855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.6%)	
12/22 10:49:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][600/703]	Step 62076	lr 0.0115	Loss 0.7495 (0.7904)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.5%)	
12/22 10:50:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][700/703]	Step 62176	lr 0.0115	Loss 0.6406 (0.7977)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.5%)	
12/22 10:50:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][703/703]	Step 62179	lr 0.0115	Loss 0.7092 (0.7984)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.5%)	
12/22 10:50:14午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [114/159] Final Prec@1 75.7978%
12/22 10:50:21午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][78/79]	Step 62180	Loss 1.4936	Prec@(1,5) (60.4%, 86.9%)
12/22 10:50:21午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/159] Final Prec@1 60.4000%
12/22 10:50:21午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.6000%
12/22 10:50:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][100/703]	Step 62280	lr 0.01112	Loss 0.7811 (0.7311)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.1%)	
12/22 10:51:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][200/703]	Step 62380	lr 0.01112	Loss 0.6804 (0.7389)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.1%)	
12/22 10:51:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][300/703]	Step 62480	lr 0.01112	Loss 0.9812 (0.7515)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.0%)	
12/22 10:51:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][400/703]	Step 62580	lr 0.01112	Loss 0.7390 (0.7553)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.0%)	
12/22 10:52:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][500/703]	Step 62680	lr 0.01112	Loss 0.9658 (0.7719)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.9%)	
12/22 10:52:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][600/703]	Step 62780	lr 0.01112	Loss 0.8259 (0.7768)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.9%)	
12/22 10:52:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][700/703]	Step 62880	lr 0.01112	Loss 1.0154 (0.7814)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.8%)	
12/22 10:52:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][703/703]	Step 62883	lr 0.01112	Loss 0.6429 (0.7810)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.8%)	
12/22 10:52:47午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [115/159] Final Prec@1 76.0667%
12/22 10:52:53午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][78/79]	Step 62884	Loss 1.5275	Prec@(1,5) (60.8%, 87.4%)
12/22 10:52:53午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/159] Final Prec@1 60.7600%
12/22 10:52:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7600%
12/22 10:53:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][100/703]	Step 62984	lr 0.01075	Loss 0.6383 (0.7067)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.0%, 96.6%)	
12/22 10:53:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][200/703]	Step 63084	lr 0.01075	Loss 0.7756 (0.7263)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.5%)	
12/22 10:53:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][300/703]	Step 63184	lr 0.01075	Loss 0.7854 (0.7358)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.3%)	
12/22 10:54:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][400/703]	Step 63284	lr 0.01075	Loss 0.6807 (0.7422)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
12/22 10:54:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][500/703]	Step 63384	lr 0.01075	Loss 0.7408 (0.7508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.0%)	
12/22 10:54:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][600/703]	Step 63484	lr 0.01075	Loss 0.6359 (0.7611)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.9%)	
12/22 10:55:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][700/703]	Step 63584	lr 0.01075	Loss 1.0616 (0.7661)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
12/22 10:55:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][703/703]	Step 63587	lr 0.01075	Loss 0.8624 (0.7670)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
12/22 10:55:20午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [116/159] Final Prec@1 76.4089%
12/22 10:55:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][78/79]	Step 63588	Loss 1.5337	Prec@(1,5) (59.8%, 86.5%)
12/22 10:55:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/159] Final Prec@1 59.8000%
12/22 10:55:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7600%
12/22 10:55:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][100/703]	Step 63688	lr 0.01038	Loss 0.6936 (0.6818)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 97.0%)	
12/22 10:56:09午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][200/703]	Step 63788	lr 0.01038	Loss 0.7386 (0.7125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.6%)	
12/22 10:56:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][300/703]	Step 63888	lr 0.01038	Loss 0.7119 (0.7203)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.5%)	
12/22 10:56:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][400/703]	Step 63988	lr 0.01038	Loss 0.8545 (0.7261)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.4%)	
12/22 10:57:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][500/703]	Step 64088	lr 0.01038	Loss 0.5553 (0.7336)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.3%)	
12/22 10:57:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][600/703]	Step 64188	lr 0.01038	Loss 1.0741 (0.7433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.3%, 96.2%)	
12/22 10:57:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][700/703]	Step 64288	lr 0.01038	Loss 0.7625 (0.7504)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.1%)	
12/22 10:57:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][703/703]	Step 64291	lr 0.01038	Loss 0.8198 (0.7503)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.1%)	
12/22 10:57:53午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [117/159] Final Prec@1 77.0467%
12/22 10:57:59午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][78/79]	Step 64292	Loss 1.5085	Prec@(1,5) (60.3%, 87.1%)
12/22 10:57:59午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/159] Final Prec@1 60.3600%
12/22 10:57:59午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7600%
12/22 10:58:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][100/703]	Step 64392	lr 0.01002	Loss 1.0229 (0.7037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.6%)	
12/22 10:58:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][200/703]	Step 64492	lr 0.01002	Loss 0.8504 (0.7028)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
12/22 10:59:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][300/703]	Step 64592	lr 0.01002	Loss 0.6880 (0.6979)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.6%)	
12/22 10:59:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][400/703]	Step 64692	lr 0.01002	Loss 0.8259 (0.7026)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.6%)	
12/22 10:59:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][500/703]	Step 64792	lr 0.01002	Loss 0.5853 (0.7134)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.2%, 96.5%)	
12/22 11:00:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][600/703]	Step 64892	lr 0.01002	Loss 0.8594 (0.7243)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
12/22 11:00:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][700/703]	Step 64992	lr 0.01002	Loss 0.5714 (0.7323)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
12/22 11:00:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][703/703]	Step 64995	lr 0.01002	Loss 0.7605 (0.7322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.2%)	
12/22 11:00:26午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [118/159] Final Prec@1 77.6378%
12/22 11:00:33午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][78/79]	Step 64996	Loss 1.5412	Prec@(1,5) (60.2%, 85.9%)
12/22 11:00:33午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/159] Final Prec@1 60.2400%
12/22 11:00:33午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7600%
12/22 11:00:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][100/703]	Step 65096	lr 0.00965	Loss 0.4141 (0.6698)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 97.1%)	
12/22 11:01:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][200/703]	Step 65196	lr 0.00965	Loss 0.4866 (0.6699)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 97.0%)	
12/22 11:01:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][300/703]	Step 65296	lr 0.00965	Loss 0.8075 (0.6825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.7%, 96.9%)	
12/22 11:01:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][400/703]	Step 65396	lr 0.00965	Loss 0.6039 (0.6887)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.8%)	
12/22 11:02:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][500/703]	Step 65496	lr 0.00965	Loss 0.5177 (0.6940)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.7%)	
12/22 11:02:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][600/703]	Step 65596	lr 0.00965	Loss 0.9710 (0.7067)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.6%)	
12/22 11:02:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][700/703]	Step 65696	lr 0.00965	Loss 0.4994 (0.7195)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.5%)	
12/22 11:02:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][703/703]	Step 65699	lr 0.00965	Loss 0.9434 (0.7198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.5%)	
12/22 11:02:59午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [119/159] Final Prec@1 77.6822%
12/22 11:03:05午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][78/79]	Step 65700	Loss 1.5127	Prec@(1,5) (60.2%, 86.9%)
12/22 11:03:05午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/159] Final Prec@1 60.1600%
12/22 11:03:05午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.7600%
12/22 11:03:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][100/703]	Step 65800	lr 0.00929	Loss 0.6082 (0.6623)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 97.1%)	
12/22 11:03:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][200/703]	Step 65900	lr 0.00929	Loss 0.6355 (0.6716)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.9%)	
12/22 11:04:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][300/703]	Step 66000	lr 0.00929	Loss 0.9531 (0.6775)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.6%)	
12/22 11:04:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][400/703]	Step 66100	lr 0.00929	Loss 0.6590 (0.6841)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.6%)	
12/22 11:04:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][500/703]	Step 66200	lr 0.00929	Loss 0.6262 (0.6913)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.5%)	
12/22 11:05:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][600/703]	Step 66300	lr 0.00929	Loss 0.8705 (0.6994)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.5%)	
12/22 11:05:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][700/703]	Step 66400	lr 0.00929	Loss 1.0203 (0.7079)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.4%)	
12/22 11:05:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][703/703]	Step 66403	lr 0.00929	Loss 0.7264 (0.7081)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.4%)	
12/22 11:05:32午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [120/159] Final Prec@1 78.2533%
12/22 11:05:38午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][78/79]	Step 66404	Loss 1.4868	Prec@(1,5) (61.0%, 87.6%)
12/22 11:05:38午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/159] Final Prec@1 61.0200%
12/22 11:05:38午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.0200%
12/22 11:06:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][100/703]	Step 66504	lr 0.00894	Loss 0.8580 (0.6552)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 96.8%)	
12/22 11:06:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][200/703]	Step 66604	lr 0.00894	Loss 0.6219 (0.6441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.0%)	
12/22 11:06:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][300/703]	Step 66704	lr 0.00894	Loss 0.6776 (0.6434)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.1%)	
12/22 11:07:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][400/703]	Step 66804	lr 0.00894	Loss 0.6393 (0.6564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 96.9%)	
12/22 11:07:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][500/703]	Step 66904	lr 0.00894	Loss 0.9145 (0.6650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.8%)	
12/22 11:07:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][600/703]	Step 67004	lr 0.00894	Loss 0.7505 (0.6722)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.8%)	
12/22 11:08:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][700/703]	Step 67104	lr 0.00894	Loss 0.7365 (0.6805)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.8%)	
12/22 11:08:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][703/703]	Step 67107	lr 0.00894	Loss 0.6780 (0.6807)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.1%, 96.8%)	
12/22 11:08:05午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [121/159] Final Prec@1 79.1089%
12/22 11:08:11午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][78/79]	Step 67108	Loss 1.4386	Prec@(1,5) (62.4%, 88.1%)
12/22 11:08:12午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/159] Final Prec@1 62.3600%
12/22 11:08:12午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3600%
12/22 11:08:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][100/703]	Step 67208	lr 0.00858	Loss 0.6611 (0.6060)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.5%, 97.4%)	
12/22 11:08:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][200/703]	Step 67308	lr 0.00858	Loss 0.6215 (0.6151)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.3%)	
12/22 11:09:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][300/703]	Step 67408	lr 0.00858	Loss 0.6908 (0.6391)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.5%, 97.2%)	
12/22 11:09:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][400/703]	Step 67508	lr 0.00858	Loss 0.7436 (0.6535)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
12/22 11:09:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][500/703]	Step 67608	lr 0.00858	Loss 0.5346 (0.6559)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
12/22 11:10:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][600/703]	Step 67708	lr 0.00858	Loss 0.7269 (0.6639)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.6%, 96.9%)	
12/22 11:10:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][700/703]	Step 67808	lr 0.00858	Loss 0.5557 (0.6740)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.8%)	
12/22 11:10:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][703/703]	Step 67811	lr 0.00858	Loss 0.8448 (0.6742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.8%)	
12/22 11:10:38午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [122/159] Final Prec@1 79.2356%
12/22 11:10:45午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][78/79]	Step 67812	Loss 1.4901	Prec@(1,5) (61.8%, 87.2%)
12/22 11:10:45午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/159] Final Prec@1 61.7600%
12/22 11:10:45午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.3600%
12/22 11:11:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][100/703]	Step 67912	lr 0.00823	Loss 0.6536 (0.6021)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.7%)	
12/22 11:11:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][200/703]	Step 68012	lr 0.00823	Loss 0.3495 (0.6200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
12/22 11:11:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][300/703]	Step 68112	lr 0.00823	Loss 0.9107 (0.6359)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.2%)	
12/22 11:12:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][400/703]	Step 68212	lr 0.00823	Loss 0.4596 (0.6437)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
12/22 11:12:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][500/703]	Step 68312	lr 0.00823	Loss 0.8258 (0.6508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
12/22 11:12:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][600/703]	Step 68412	lr 0.00823	Loss 0.7401 (0.6551)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
12/22 11:13:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][700/703]	Step 68512	lr 0.00823	Loss 0.6102 (0.6605)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
12/22 11:13:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][703/703]	Step 68515	lr 0.00823	Loss 0.6341 (0.6605)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
12/22 11:13:12午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [123/159] Final Prec@1 79.6556%
12/22 11:13:18午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][78/79]	Step 68516	Loss 1.4413	Prec@(1,5) (63.0%, 88.1%)
12/22 11:13:18午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/159] Final Prec@1 62.9800%
12/22 11:13:18午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.9800%
12/22 11:13:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][100/703]	Step 68616	lr 0.00789	Loss 0.5759 (0.6010)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.7%)	
12/22 11:14:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][200/703]	Step 68716	lr 0.00789	Loss 0.4961 (0.6154)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.6%)	
12/22 11:14:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][300/703]	Step 68816	lr 0.00789	Loss 0.8503 (0.6121)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.9%, 97.5%)	
12/22 11:14:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][400/703]	Step 68916	lr 0.00789	Loss 0.6657 (0.6279)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.4%)	
12/22 11:15:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][500/703]	Step 69016	lr 0.00789	Loss 0.7839 (0.6365)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.2%)	
12/22 11:15:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][600/703]	Step 69116	lr 0.00789	Loss 0.4099 (0.6402)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
12/22 11:15:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][700/703]	Step 69216	lr 0.00789	Loss 0.8160 (0.6440)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.2%)	
12/22 11:15:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][703/703]	Step 69219	lr 0.00789	Loss 0.6475 (0.6441)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.2%)	
12/22 11:15:45午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [124/159] Final Prec@1 79.9400%
12/22 11:15:51午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][78/79]	Step 69220	Loss 1.4746	Prec@(1,5) (62.2%, 88.4%)
12/22 11:15:51午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/159] Final Prec@1 62.2400%
12/22 11:15:51午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.9800%
12/22 11:16:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][100/703]	Step 69320	lr 0.00755	Loss 0.5996 (0.5711)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
12/22 11:16:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][200/703]	Step 69420	lr 0.00755	Loss 0.6013 (0.5852)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.7%)	
12/22 11:16:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][300/703]	Step 69520	lr 0.00755	Loss 0.5864 (0.5955)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.6%)	
12/22 11:17:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][400/703]	Step 69620	lr 0.00755	Loss 0.5030 (0.6051)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.5%)	
12/22 11:17:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][500/703]	Step 69720	lr 0.00755	Loss 0.8519 (0.6123)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.5%)	
12/22 11:17:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][600/703]	Step 69820	lr 0.00755	Loss 0.4493 (0.6179)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.5%)	
12/22 11:18:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][700/703]	Step 69920	lr 0.00755	Loss 0.3948 (0.6206)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
12/22 11:18:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][703/703]	Step 69923	lr 0.00755	Loss 0.5049 (0.6204)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.4%)	
12/22 11:18:18午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [125/159] Final Prec@1 80.6556%
12/22 11:18:24午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][78/79]	Step 69924	Loss 1.5523	Prec@(1,5) (60.4%, 86.6%)
12/22 11:18:24午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/159] Final Prec@1 60.4000%
12/22 11:18:24午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.9800%
12/22 11:18:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][100/703]	Step 70024	lr 0.00722	Loss 0.5380 (0.5614)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 98.0%)	
12/22 11:19:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][200/703]	Step 70124	lr 0.00722	Loss 0.5760 (0.5635)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.9%)	
12/22 11:19:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][300/703]	Step 70224	lr 0.00722	Loss 0.5756 (0.5705)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.8%)	
12/22 11:19:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][400/703]	Step 70324	lr 0.00722	Loss 0.3630 (0.5740)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.7%)	
12/22 11:20:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][500/703]	Step 70424	lr 0.00722	Loss 0.6368 (0.5839)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.6%)	
12/22 11:20:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][600/703]	Step 70524	lr 0.00722	Loss 0.5555 (0.5917)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.6%)	
12/22 11:20:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][700/703]	Step 70624	lr 0.00722	Loss 0.6970 (0.5993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.6%)	
12/22 11:20:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][703/703]	Step 70627	lr 0.00722	Loss 1.0011 (0.5996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.6%, 97.6%)	
12/22 11:20:51午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [126/159] Final Prec@1 81.5600%
12/22 11:20:57午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][78/79]	Step 70628	Loss 1.4379	Prec@(1,5) (62.8%, 88.3%)
12/22 11:20:57午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/159] Final Prec@1 62.8200%
12/22 11:20:57午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.9800%
12/22 11:21:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][100/703]	Step 70728	lr 0.00689	Loss 0.4622 (0.5479)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 98.0%)	
12/22 11:21:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][200/703]	Step 70828	lr 0.00689	Loss 0.4016 (0.5446)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 98.1%)	
12/22 11:22:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][300/703]	Step 70928	lr 0.00689	Loss 0.5199 (0.5483)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 98.0%)	
12/22 11:22:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][400/703]	Step 71028	lr 0.00689	Loss 0.8016 (0.5586)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.9%)	
12/22 11:22:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][500/703]	Step 71128	lr 0.00689	Loss 0.4783 (0.5674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.8%)	
12/22 11:23:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][600/703]	Step 71228	lr 0.00689	Loss 0.4803 (0.5753)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.7%)	
12/22 11:23:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][700/703]	Step 71328	lr 0.00689	Loss 0.7609 (0.5817)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.6%)	
12/22 11:23:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][703/703]	Step 71331	lr 0.00689	Loss 0.3988 (0.5814)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.8%, 97.6%)	
12/22 11:23:23午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [127/159] Final Prec@1 81.8378%
12/22 11:23:30午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][78/79]	Step 71332	Loss 1.4159	Prec@(1,5) (62.4%, 88.8%)
12/22 11:23:30午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/159] Final Prec@1 62.4200%
12/22 11:23:30午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.9800%
12/22 11:23:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][100/703]	Step 71432	lr 0.00657	Loss 0.5622 (0.5350)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.4%, 97.8%)	
12/22 11:24:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][200/703]	Step 71532	lr 0.00657	Loss 0.6428 (0.5397)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.8%)	
12/22 11:24:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][300/703]	Step 71632	lr 0.00657	Loss 0.5976 (0.5459)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.8%)	
12/22 11:24:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][400/703]	Step 71732	lr 0.00657	Loss 0.7702 (0.5540)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 97.8%)	
12/22 11:25:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][500/703]	Step 71832	lr 0.00657	Loss 0.5954 (0.5573)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
12/22 11:25:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][600/703]	Step 71932	lr 0.00657	Loss 0.5102 (0.5661)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
12/22 11:25:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][700/703]	Step 72032	lr 0.00657	Loss 0.5637 (0.5702)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.6%)	
12/22 11:25:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][703/703]	Step 72035	lr 0.00657	Loss 0.5495 (0.5702)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.6%)	
12/22 11:25:56午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [128/159] Final Prec@1 82.1889%
12/22 11:26:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][78/79]	Step 72036	Loss 1.4262	Prec@(1,5) (62.3%, 88.8%)
12/22 11:26:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/159] Final Prec@1 62.2600%
12/22 11:26:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.9800%
12/22 11:26:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][100/703]	Step 72136	lr 0.00625	Loss 0.6428 (0.5335)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.1%)	
12/22 11:26:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][200/703]	Step 72236	lr 0.00625	Loss 0.9625 (0.5282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.2%)	
12/22 11:27:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][300/703]	Step 72336	lr 0.00625	Loss 0.7983 (0.5379)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 98.1%)	
12/22 11:27:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][400/703]	Step 72436	lr 0.00625	Loss 0.7347 (0.5421)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 98.0%)	
12/22 11:27:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][500/703]	Step 72536	lr 0.00625	Loss 0.6329 (0.5475)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 98.0%)	
12/22 11:28:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][600/703]	Step 72636	lr 0.00625	Loss 0.2065 (0.5508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.7%, 98.0%)	
12/22 11:28:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][700/703]	Step 72736	lr 0.00625	Loss 0.5276 (0.5563)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.9%)	
12/22 11:28:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][703/703]	Step 72739	lr 0.00625	Loss 0.4728 (0.5564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.9%)	
12/22 11:28:30午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [129/159] Final Prec@1 82.5911%
12/22 11:28:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][78/79]	Step 72740	Loss 1.4488	Prec@(1,5) (62.8%, 88.3%)
12/22 11:28:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/159] Final Prec@1 62.8000%
12/22 11:28:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.9800%
12/22 11:28:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][100/703]	Step 72840	lr 0.00595	Loss 0.3624 (0.4909)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.2%)	
12/22 11:29:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][200/703]	Step 72940	lr 0.00595	Loss 0.5535 (0.4887)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.3%)	
12/22 11:29:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][300/703]	Step 73040	lr 0.00595	Loss 0.5383 (0.5050)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.2%)	
12/22 11:29:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][400/703]	Step 73140	lr 0.00595	Loss 0.7351 (0.5201)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.0%)	
12/22 11:30:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][500/703]	Step 73240	lr 0.00595	Loss 0.6163 (0.5243)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.1%)	
12/22 11:30:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][600/703]	Step 73340	lr 0.00595	Loss 0.5142 (0.5305)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.0%)	
12/22 11:31:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][700/703]	Step 73440	lr 0.00595	Loss 0.5103 (0.5363)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.9%)	
12/22 11:31:02午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][703/703]	Step 73443	lr 0.00595	Loss 0.6159 (0.5365)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.9%)	
12/22 11:31:03午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [130/159] Final Prec@1 83.2933%
12/22 11:31:09午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][78/79]	Step 73444	Loss 1.4570	Prec@(1,5) (63.2%, 88.4%)
12/22 11:31:09午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/159] Final Prec@1 63.1800%
12/22 11:31:09午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.1800%
12/22 11:31:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][100/703]	Step 73544	lr 0.00565	Loss 0.5314 (0.4701)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.5%)	
12/22 11:31:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][200/703]	Step 73644	lr 0.00565	Loss 0.4485 (0.4767)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.5%)	
12/22 11:32:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][300/703]	Step 73744	lr 0.00565	Loss 0.4606 (0.4868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.9%, 98.4%)	
12/22 11:32:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][400/703]	Step 73844	lr 0.00565	Loss 0.5997 (0.5044)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.2%)	
12/22 11:32:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][500/703]	Step 73944	lr 0.00565	Loss 0.7116 (0.5101)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.2%)	
12/22 11:33:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][600/703]	Step 74044	lr 0.00565	Loss 0.6055 (0.5127)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.2%)	
12/22 11:33:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][700/703]	Step 74144	lr 0.00565	Loss 0.5998 (0.5139)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.2%)	
12/22 11:33:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][703/703]	Step 74147	lr 0.00565	Loss 0.4567 (0.5136)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.9%, 98.2%)	
12/22 11:33:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [131/159] Final Prec@1 83.9089%
12/22 11:33:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][78/79]	Step 74148	Loss 1.4682	Prec@(1,5) (63.3%, 88.2%)
12/22 11:33:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/159] Final Prec@1 63.3000%
12/22 11:33:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.3000%
12/22 11:34:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][100/703]	Step 74248	lr 0.00535	Loss 0.5572 (0.4692)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
12/22 11:34:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][200/703]	Step 74348	lr 0.00535	Loss 0.5888 (0.4831)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.3%)	
12/22 11:34:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][300/703]	Step 74448	lr 0.00535	Loss 0.3723 (0.4872)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.3%)	
12/22 11:35:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][400/703]	Step 74548	lr 0.00535	Loss 0.5537 (0.4899)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.3%)	
12/22 11:35:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][500/703]	Step 74648	lr 0.00535	Loss 0.4242 (0.4939)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
12/22 11:35:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][600/703]	Step 74748	lr 0.00535	Loss 0.6113 (0.4960)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
12/22 11:36:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][700/703]	Step 74848	lr 0.00535	Loss 0.5891 (0.5032)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
12/22 11:36:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][703/703]	Step 74851	lr 0.00535	Loss 0.7349 (0.5036)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
12/22 11:36:09午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [132/159] Final Prec@1 84.1067%
12/22 11:36:15午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][78/79]	Step 74852	Loss 1.4050	Prec@(1,5) (63.5%, 89.5%)
12/22 11:36:15午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/159] Final Prec@1 63.5200%
12/22 11:36:15午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5200%
12/22 11:36:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][100/703]	Step 74952	lr 0.00506	Loss 0.4614 (0.4348)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.8%)	
12/22 11:36:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][200/703]	Step 75052	lr 0.00506	Loss 0.7364 (0.4574)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.6%)	
12/22 11:37:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][300/703]	Step 75152	lr 0.00506	Loss 0.7690 (0.4591)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.6%)	
12/22 11:37:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][400/703]	Step 75252	lr 0.00506	Loss 0.4149 (0.4642)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.5%)	
12/22 11:38:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][500/703]	Step 75352	lr 0.00506	Loss 0.6383 (0.4709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.5%)	
12/22 11:38:21午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][600/703]	Step 75452	lr 0.00506	Loss 0.5913 (0.4761)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.2%, 98.5%)	
12/22 11:38:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][700/703]	Step 75552	lr 0.00506	Loss 0.4288 (0.4794)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
12/22 11:38:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][703/703]	Step 75555	lr 0.00506	Loss 0.5924 (0.4797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.1%, 98.4%)	
12/22 11:38:42午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [133/159] Final Prec@1 85.0578%
12/22 11:38:49午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][78/79]	Step 75556	Loss 1.4170	Prec@(1,5) (63.7%, 89.0%)
12/22 11:38:49午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/159] Final Prec@1 63.7000%
12/22 11:38:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.7000%
12/22 11:39:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][100/703]	Step 75656	lr 0.00479	Loss 0.3319 (0.4200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.8%)	
12/22 11:39:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][200/703]	Step 75756	lr 0.00479	Loss 0.3517 (0.4201)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.8%)	
12/22 11:39:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][300/703]	Step 75856	lr 0.00479	Loss 0.4901 (0.4300)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.8%)	
12/22 11:40:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][400/703]	Step 75956	lr 0.00479	Loss 0.4596 (0.4403)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.3%, 98.7%)	
12/22 11:40:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][500/703]	Step 76056	lr 0.00479	Loss 0.3555 (0.4486)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.7%)	
12/22 11:40:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][600/703]	Step 76156	lr 0.00479	Loss 0.5211 (0.4555)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.6%)	
12/22 11:41:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][700/703]	Step 76256	lr 0.00479	Loss 0.8351 (0.4632)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.5%)	
12/22 11:41:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][703/703]	Step 76259	lr 0.00479	Loss 0.5139 (0.4635)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.4%, 98.5%)	
12/22 11:41:15午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [134/159] Final Prec@1 85.4178%
12/22 11:41:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][78/79]	Step 76260	Loss 1.4593	Prec@(1,5) (62.7%, 88.5%)
12/22 11:41:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/159] Final Prec@1 62.7000%
12/22 11:41:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.7000%
12/22 11:41:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][100/703]	Step 76360	lr 0.00451	Loss 0.4057 (0.4304)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 99.0%)	
12/22 11:42:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][200/703]	Step 76460	lr 0.00451	Loss 0.3180 (0.4269)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.9%)	
12/22 11:42:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][300/703]	Step 76560	lr 0.00451	Loss 0.3609 (0.4328)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.9%)	
12/22 11:42:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][400/703]	Step 76660	lr 0.00451	Loss 0.5515 (0.4392)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.8%)	
12/22 11:43:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][500/703]	Step 76760	lr 0.00451	Loss 0.3671 (0.4433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.8%)	
12/22 11:43:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][600/703]	Step 76860	lr 0.00451	Loss 0.3570 (0.4480)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.7%)	
12/22 11:43:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][700/703]	Step 76960	lr 0.00451	Loss 0.6067 (0.4490)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.7%)	
12/22 11:43:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][703/703]	Step 76963	lr 0.00451	Loss 0.6591 (0.4494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.7%)	
12/22 11:43:49午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [135/159] Final Prec@1 85.9689%
12/22 11:43:55午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][78/79]	Step 76964	Loss 1.4292	Prec@(1,5) (63.4%, 88.8%)
12/22 11:43:55午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/159] Final Prec@1 63.4200%
12/22 11:43:55午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.7000%
12/22 11:44:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][100/703]	Step 77064	lr 0.00425	Loss 0.3568 (0.3869)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 98.7%)	
12/22 11:44:37午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][200/703]	Step 77164	lr 0.00425	Loss 0.3844 (0.3944)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 98.9%)	
12/22 11:44:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][300/703]	Step 77264	lr 0.00425	Loss 0.4674 (0.4070)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.8%)	
12/22 11:45:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][400/703]	Step 77364	lr 0.00425	Loss 0.5120 (0.4174)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.8%)	
12/22 11:45:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][500/703]	Step 77464	lr 0.00425	Loss 0.6132 (0.4227)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
12/22 11:46:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][600/703]	Step 77564	lr 0.00425	Loss 0.4599 (0.4282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 98.8%)	
12/22 11:46:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][700/703]	Step 77664	lr 0.00425	Loss 0.4719 (0.4339)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.7%)	
12/22 11:46:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][703/703]	Step 77667	lr 0.00425	Loss 0.5114 (0.4340)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.5%, 98.7%)	
12/22 11:46:22午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [136/159] Final Prec@1 86.4667%
12/22 11:46:29午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][78/79]	Step 77668	Loss 1.4553	Prec@(1,5) (63.4%, 88.7%)
12/22 11:46:29午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/159] Final Prec@1 63.4400%
12/22 11:46:29午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.7000%
12/22 11:46:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][100/703]	Step 77768	lr 0.004	Loss 0.4594 (0.3942)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 99.1%)	
12/22 11:47:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][200/703]	Step 77868	lr 0.004	Loss 0.2551 (0.3902)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.0%)	
12/22 11:47:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][300/703]	Step 77968	lr 0.004	Loss 0.3368 (0.3967)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 99.0%)	
12/22 11:47:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][400/703]	Step 78068	lr 0.004	Loss 0.3307 (0.4045)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 99.0%)	
12/22 11:48:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][500/703]	Step 78168	lr 0.004	Loss 0.4213 (0.4091)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.3%, 99.0%)	
12/22 11:48:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][600/703]	Step 78268	lr 0.004	Loss 0.4529 (0.4149)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.9%)	
12/22 11:48:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][700/703]	Step 78368	lr 0.004	Loss 0.3040 (0.4171)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.9%)	
12/22 11:48:55午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][703/703]	Step 78371	lr 0.004	Loss 0.3533 (0.4170)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.1%, 98.9%)	
12/22 11:48:55午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [137/159] Final Prec@1 87.0622%
12/22 11:49:01午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][78/79]	Step 78372	Loss 1.4183	Prec@(1,5) (64.2%, 89.2%)
12/22 11:49:01午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/159] Final Prec@1 64.1800%
12/22 11:49:02午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.1800%
12/22 11:49:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][100/703]	Step 78472	lr 0.00375	Loss 0.3393 (0.3587)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.2%)	
12/22 11:49:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][200/703]	Step 78572	lr 0.00375	Loss 0.2325 (0.3706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.0%)	
12/22 11:50:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][300/703]	Step 78672	lr 0.00375	Loss 0.3882 (0.3731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.1%)	
12/22 11:50:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][400/703]	Step 78772	lr 0.00375	Loss 0.5028 (0.3784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/22 11:50:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][500/703]	Step 78872	lr 0.00375	Loss 0.5339 (0.3836)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.3%, 99.0%)	
12/22 11:51:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][600/703]	Step 78972	lr 0.00375	Loss 0.6000 (0.3911)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 99.0%)	
12/22 11:51:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][700/703]	Step 79072	lr 0.00375	Loss 0.5585 (0.3942)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
12/22 11:51:28午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][703/703]	Step 79075	lr 0.00375	Loss 0.5885 (0.3946)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 98.9%)	
12/22 11:51:28午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [138/159] Final Prec@1 87.7933%
12/22 11:51:35午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][78/79]	Step 79076	Loss 1.4306	Prec@(1,5) (64.3%, 89.3%)
12/22 11:51:35午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/159] Final Prec@1 64.3400%
12/22 11:51:35午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3400%
12/22 11:51:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][100/703]	Step 79176	lr 0.00352	Loss 0.2243 (0.3385)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.4%)	
12/22 11:52:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][200/703]	Step 79276	lr 0.00352	Loss 0.3507 (0.3512)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.2%)	
12/22 11:52:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][300/703]	Step 79376	lr 0.00352	Loss 0.4705 (0.3650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
12/22 11:52:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][400/703]	Step 79476	lr 0.00352	Loss 0.4247 (0.3741)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.1%)	
12/22 11:53:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][500/703]	Step 79576	lr 0.00352	Loss 0.3734 (0.3749)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.1%)	
12/22 11:53:40午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][600/703]	Step 79676	lr 0.00352	Loss 0.3838 (0.3793)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.1%)	
12/22 11:54:00午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][700/703]	Step 79776	lr 0.00352	Loss 0.3526 (0.3820)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/22 11:54:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][703/703]	Step 79779	lr 0.00352	Loss 0.3589 (0.3821)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/22 11:54:01午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [139/159] Final Prec@1 88.3556%
12/22 11:54:08午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][78/79]	Step 79780	Loss 1.3971	Prec@(1,5) (64.3%, 89.6%)
12/22 11:54:08午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/159] Final Prec@1 64.3200%
12/22 11:54:08午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3400%
12/22 11:54:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][100/703]	Step 79880	lr 0.00329	Loss 0.4360 (0.3351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.2%)	
12/22 11:54:50午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][200/703]	Step 79980	lr 0.00329	Loss 0.2589 (0.3412)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
12/22 11:55:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][300/703]	Step 80080	lr 0.00329	Loss 0.2527 (0.3429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.3%)	
12/22 11:55:32午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][400/703]	Step 80180	lr 0.00329	Loss 0.2655 (0.3508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
12/22 11:55:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][500/703]	Step 80280	lr 0.00329	Loss 0.2542 (0.3551)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.2%)	
12/22 11:56:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][600/703]	Step 80380	lr 0.00329	Loss 0.3383 (0.3601)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.9%, 99.2%)	
12/22 11:56:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][700/703]	Step 80480	lr 0.00329	Loss 0.3144 (0.3658)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.2%)	
12/22 11:56:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][703/703]	Step 80483	lr 0.00329	Loss 0.3902 (0.3661)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.7%, 99.1%)	
12/22 11:56:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [140/159] Final Prec@1 88.6800%
12/22 11:56:41午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][78/79]	Step 80484	Loss 1.4275	Prec@(1,5) (64.0%, 89.2%)
12/22 11:56:41午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/159] Final Prec@1 63.9800%
12/22 11:56:41午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.3400%
12/22 11:57:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][100/703]	Step 80584	lr 0.00308	Loss 0.2805 (0.3266)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.4%)	
12/22 11:57:23午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][200/703]	Step 80684	lr 0.00308	Loss 0.4647 (0.3348)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.4%)	
12/22 11:57:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][300/703]	Step 80784	lr 0.00308	Loss 0.2071 (0.3402)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.2%)	
12/22 11:58:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][400/703]	Step 80884	lr 0.00308	Loss 0.2983 (0.3408)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
12/22 11:58:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][500/703]	Step 80984	lr 0.00308	Loss 0.3322 (0.3426)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.7%, 99.2%)	
12/22 11:58:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][600/703]	Step 81084	lr 0.00308	Loss 0.3100 (0.3466)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.2%)	
12/22 11:59:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][700/703]	Step 81184	lr 0.00308	Loss 0.4529 (0.3497)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.2%)	
12/22 11:59:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][703/703]	Step 81187	lr 0.00308	Loss 0.4068 (0.3503)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.2%)	
12/22 11:59:08午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [141/159] Final Prec@1 89.4156%
12/22 11:59:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][78/79]	Step 81188	Loss 1.4544	Prec@(1,5) (64.5%, 89.2%)
12/22 11:59:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/159] Final Prec@1 64.4600%
12/22 11:59:15午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4600%
12/22 11:59:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][100/703]	Step 81288	lr 0.00287	Loss 0.2810 (0.3146)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.4%)	
12/22 11:59:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][200/703]	Step 81388	lr 0.00287	Loss 0.2498 (0.3134)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.5%)	
12/22 12:00:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][300/703]	Step 81488	lr 0.00287	Loss 0.3256 (0.3238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.4%)	
12/22 12:00:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][400/703]	Step 81588	lr 0.00287	Loss 0.2938 (0.3282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
12/22 12:00:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][500/703]	Step 81688	lr 0.00287	Loss 0.2813 (0.3280)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
12/22 12:01:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][600/703]	Step 81788	lr 0.00287	Loss 0.4131 (0.3340)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
12/22 12:01:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][700/703]	Step 81888	lr 0.00287	Loss 0.2882 (0.3356)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
12/22 12:01:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][703/703]	Step 81891	lr 0.00287	Loss 0.3540 (0.3356)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.3%)	
12/22 12:01:41午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [142/159] Final Prec@1 89.7844%
12/22 12:01:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][78/79]	Step 81892	Loss 1.4059	Prec@(1,5) (64.6%, 89.3%)
12/22 12:01:47午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/159] Final Prec@1 64.6000%
12/22 12:01:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.6000%
12/22 12:02:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][100/703]	Step 81992	lr 0.00267	Loss 0.2176 (0.3081)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
12/22 12:02:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][200/703]	Step 82092	lr 0.00267	Loss 0.1947 (0.3051)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.5%)	
12/22 12:02:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][300/703]	Step 82192	lr 0.00267	Loss 0.4469 (0.3131)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.4%)	
12/22 12:03:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][400/703]	Step 82292	lr 0.00267	Loss 0.1876 (0.3133)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.4%)	
12/22 12:03:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][500/703]	Step 82392	lr 0.00267	Loss 0.5111 (0.3183)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.4%)	
12/22 12:03:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][600/703]	Step 82492	lr 0.00267	Loss 0.3922 (0.3220)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.4%)	
12/22 12:04:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][700/703]	Step 82592	lr 0.00267	Loss 0.2938 (0.3265)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
12/22 12:04:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][703/703]	Step 82595	lr 0.00267	Loss 0.3684 (0.3265)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.3%)	
12/22 12:04:14午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [143/159] Final Prec@1 90.0267%
12/22 12:04:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][78/79]	Step 82596	Loss 1.4131	Prec@(1,5) (64.7%, 89.5%)
12/22 12:04:21午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/159] Final Prec@1 64.6800%
12/22 12:04:21午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.6800%
12/22 12:04:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][100/703]	Step 82696	lr 0.00248	Loss 0.3411 (0.2939)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.5%)	
12/22 12:05:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][200/703]	Step 82796	lr 0.00248	Loss 0.2841 (0.3016)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
12/22 12:05:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][300/703]	Step 82896	lr 0.00248	Loss 0.3455 (0.3065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.4%)	
12/22 12:05:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][400/703]	Step 82996	lr 0.00248	Loss 0.2905 (0.3068)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.8%, 99.4%)	
12/22 12:06:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][500/703]	Step 83096	lr 0.00248	Loss 0.3988 (0.3079)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
12/22 12:06:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][600/703]	Step 83196	lr 0.00248	Loss 0.4332 (0.3101)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.7%, 99.4%)	
12/22 12:06:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][700/703]	Step 83296	lr 0.00248	Loss 0.3303 (0.3125)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.6%, 99.4%)	
12/22 12:06:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][703/703]	Step 83299	lr 0.00248	Loss 0.3745 (0.3129)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.4%)	
12/22 12:06:47午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [144/159] Final Prec@1 90.5356%
12/22 12:06:53午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][78/79]	Step 83300	Loss 1.4420	Prec@(1,5) (64.9%, 89.7%)
12/22 12:06:53午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/159] Final Prec@1 64.9600%
12/22 12:06:54午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9600%
12/22 12:07:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][100/703]	Step 83400	lr 0.00231	Loss 0.3735 (0.2882)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.3%)	
12/22 12:07:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][200/703]	Step 83500	lr 0.00231	Loss 0.2411 (0.2859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.4%)	
12/22 12:07:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][300/703]	Step 83600	lr 0.00231	Loss 0.3005 (0.2888)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
12/22 12:08:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][400/703]	Step 83700	lr 0.00231	Loss 0.3031 (0.2914)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
12/22 12:08:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][500/703]	Step 83800	lr 0.00231	Loss 0.3710 (0.2948)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.4%)	
12/22 12:08:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][600/703]	Step 83900	lr 0.00231	Loss 0.3023 (0.2978)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
12/22 12:09:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][700/703]	Step 84000	lr 0.00231	Loss 0.2172 (0.2998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
12/22 12:09:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][703/703]	Step 84003	lr 0.00231	Loss 0.2603 (0.3000)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
12/22 12:09:20午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [145/159] Final Prec@1 90.9556%
12/22 12:09:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][78/79]	Step 84004	Loss 1.4138	Prec@(1,5) (64.5%, 89.9%)
12/22 12:09:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/159] Final Prec@1 64.4800%
12/22 12:09:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.9600%
12/22 12:09:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][100/703]	Step 84104	lr 0.00214	Loss 0.3323 (0.2797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.6%)	
12/22 12:10:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][200/703]	Step 84204	lr 0.00214	Loss 0.1666 (0.2779)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.6%)	
12/22 12:10:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][300/703]	Step 84304	lr 0.00214	Loss 0.2716 (0.2795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.5%)	
12/22 12:10:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][400/703]	Step 84404	lr 0.00214	Loss 0.2406 (0.2825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.5%)	
12/22 12:11:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][500/703]	Step 84504	lr 0.00214	Loss 0.4060 (0.2848)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.5%)	
12/22 12:11:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][600/703]	Step 84604	lr 0.00214	Loss 0.3943 (0.2851)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.5%)	
12/22 12:11:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][700/703]	Step 84704	lr 0.00214	Loss 0.4833 (0.2882)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
12/22 12:11:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][703/703]	Step 84707	lr 0.00214	Loss 0.2558 (0.2884)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.5%)	
12/22 12:11:53午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [146/159] Final Prec@1 91.4511%
12/22 12:12:00午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][78/79]	Step 84708	Loss 1.4542	Prec@(1,5) (65.1%, 89.5%)
12/22 12:12:00午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/159] Final Prec@1 65.0800%
12/22 12:12:00午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.0800%
12/22 12:12:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][100/703]	Step 84808	lr 0.00199	Loss 0.1807 (0.2628)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
12/22 12:12:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][200/703]	Step 84908	lr 0.00199	Loss 0.2196 (0.2646)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.5%)	
12/22 12:13:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][300/703]	Step 85008	lr 0.00199	Loss 0.3653 (0.2639)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
12/22 12:13:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][400/703]	Step 85108	lr 0.00199	Loss 0.2477 (0.2687)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.2%, 99.6%)	
12/22 12:13:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][500/703]	Step 85208	lr 0.00199	Loss 0.3741 (0.2711)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.6%)	
12/22 12:14:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][600/703]	Step 85308	lr 0.00199	Loss 0.1733 (0.2733)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.6%)	
12/22 12:14:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][700/703]	Step 85408	lr 0.00199	Loss 0.3914 (0.2747)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.6%)	
12/22 12:14:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][703/703]	Step 85411	lr 0.00199	Loss 0.1591 (0.2745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.6%)	
12/22 12:14:27午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [147/159] Final Prec@1 91.9089%
12/22 12:14:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][78/79]	Step 85412	Loss 1.4367	Prec@(1,5) (64.4%, 89.3%)
12/22 12:14:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/159] Final Prec@1 64.4600%
12/22 12:14:33午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.0800%
12/22 12:14:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][100/703]	Step 85512	lr 0.00184	Loss 0.3490 (0.2507)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
12/22 12:15:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][200/703]	Step 85612	lr 0.00184	Loss 0.2131 (0.2546)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
12/22 12:15:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][300/703]	Step 85712	lr 0.00184	Loss 0.3516 (0.2563)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.6%)	
12/22 12:15:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][400/703]	Step 85812	lr 0.00184	Loss 0.3521 (0.2562)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
12/22 12:16:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][500/703]	Step 85912	lr 0.00184	Loss 0.1668 (0.2571)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
12/22 12:16:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][600/703]	Step 86012	lr 0.00184	Loss 0.2800 (0.2579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
12/22 12:16:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][700/703]	Step 86112	lr 0.00184	Loss 0.3609 (0.2619)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
12/22 12:17:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][703/703]	Step 86115	lr 0.00184	Loss 0.1886 (0.2618)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
12/22 12:17:00午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [148/159] Final Prec@1 92.4133%
12/22 12:17:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][78/79]	Step 86116	Loss 1.4530	Prec@(1,5) (64.9%, 89.3%)
12/22 12:17:06午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/159] Final Prec@1 64.9200%
12/22 12:17:06午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.0800%
12/22 12:17:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][100/703]	Step 86216	lr 0.00171	Loss 0.2331 (0.2405)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.6%)	
12/22 12:17:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][200/703]	Step 86316	lr 0.00171	Loss 0.1667 (0.2446)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.6%)	
12/22 12:18:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][300/703]	Step 86416	lr 0.00171	Loss 0.2118 (0.2492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.6%)	
12/22 12:18:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][400/703]	Step 86516	lr 0.00171	Loss 0.1311 (0.2514)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
12/22 12:18:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][500/703]	Step 86616	lr 0.00171	Loss 0.2233 (0.2537)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
12/22 12:19:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][600/703]	Step 86716	lr 0.00171	Loss 0.2233 (0.2549)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.6%)	
12/22 12:19:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][700/703]	Step 86816	lr 0.00171	Loss 0.4100 (0.2588)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
12/22 12:19:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][703/703]	Step 86819	lr 0.00171	Loss 0.3808 (0.2590)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.6%)	
12/22 12:19:33午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [149/159] Final Prec@1 92.4422%
12/22 12:19:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][78/79]	Step 86820	Loss 1.4459	Prec@(1,5) (64.9%, 89.6%)
12/22 12:19:39午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/159] Final Prec@1 64.8800%
12/22 12:19:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.0800%
12/22 12:20:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][100/703]	Step 86920	lr 0.00159	Loss 0.1476 (0.2215)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.8%)	
12/22 12:20:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][200/703]	Step 87020	lr 0.00159	Loss 0.2607 (0.2281)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.8%)	
12/22 12:20:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][300/703]	Step 87120	lr 0.00159	Loss 0.3198 (0.2332)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.8%)	
12/22 12:21:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][400/703]	Step 87220	lr 0.00159	Loss 0.3168 (0.2388)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:21:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][500/703]	Step 87320	lr 0.00159	Loss 0.2302 (0.2411)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
12/22 12:21:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][600/703]	Step 87420	lr 0.00159	Loss 0.3152 (0.2455)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
12/22 12:22:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][700/703]	Step 87520	lr 0.00159	Loss 0.1179 (0.2459)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.7%)	
12/22 12:22:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [150][703/703]	Step 87523	lr 0.00159	Loss 0.2092 (0.2457)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.9%, 99.7%)	
12/22 12:22:06午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [150/159] Final Prec@1 92.9444%
12/22 12:22:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [150][78/79]	Step 87524	Loss 1.4233	Prec@(1,5) (65.4%, 89.7%)
12/22 12:22:12午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [150/159] Final Prec@1 65.3600%
12/22 12:22:12午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.3600%
12/22 12:22:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][100/703]	Step 87624	lr 0.00148	Loss 0.1402 (0.2214)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.8%)	
12/22 12:22:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][200/703]	Step 87724	lr 0.00148	Loss 0.1861 (0.2284)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:23:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][300/703]	Step 87824	lr 0.00148	Loss 0.2131 (0.2304)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
12/22 12:23:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][400/703]	Step 87924	lr 0.00148	Loss 0.2380 (0.2323)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:23:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][500/703]	Step 88024	lr 0.00148	Loss 0.2027 (0.2354)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
12/22 12:24:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][600/703]	Step 88124	lr 0.00148	Loss 0.4012 (0.2385)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
12/22 12:24:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][700/703]	Step 88224	lr 0.00148	Loss 0.1771 (0.2403)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
12/22 12:24:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [151][703/703]	Step 88227	lr 0.00148	Loss 0.1733 (0.2400)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
12/22 12:24:38午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [151/159] Final Prec@1 93.0600%
12/22 12:24:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [151][78/79]	Step 88228	Loss 1.4348	Prec@(1,5) (65.1%, 90.0%)
12/22 12:24:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [151/159] Final Prec@1 65.1600%
12/22 12:24:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.3600%
12/22 12:25:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][100/703]	Step 88328	lr 0.00138	Loss 0.4378 (0.2354)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
12/22 12:25:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][200/703]	Step 88428	lr 0.00138	Loss 0.1513 (0.2332)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.2%, 99.7%)	
12/22 12:25:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][300/703]	Step 88528	lr 0.00138	Loss 0.1696 (0.2309)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
12/22 12:26:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][400/703]	Step 88628	lr 0.00138	Loss 0.2508 (0.2302)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:26:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][500/703]	Step 88728	lr 0.00138	Loss 0.2710 (0.2303)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:26:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][600/703]	Step 88828	lr 0.00138	Loss 0.2441 (0.2305)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:27:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][700/703]	Step 88928	lr 0.00138	Loss 0.2037 (0.2316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:27:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [152][703/703]	Step 88931	lr 0.00138	Loss 0.4772 (0.2321)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 12:27:12午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [152/159] Final Prec@1 93.3689%
12/22 12:27:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [152][78/79]	Step 88932	Loss 1.4301	Prec@(1,5) (64.8%, 89.4%)
12/22 12:27:18午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [152/159] Final Prec@1 64.7800%
12/22 12:27:18午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.3600%
12/22 12:27:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][100/703]	Step 89032	lr 0.00129	Loss 0.2020 (0.2121)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:28:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][200/703]	Step 89132	lr 0.00129	Loss 0.1952 (0.2121)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:28:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][300/703]	Step 89232	lr 0.00129	Loss 0.1785 (0.2180)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.7%)	
12/22 12:28:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][400/703]	Step 89332	lr 0.00129	Loss 0.1044 (0.2230)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.9%, 99.7%)	
12/22 12:29:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][500/703]	Step 89432	lr 0.00129	Loss 0.1978 (0.2258)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 12:29:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][600/703]	Step 89532	lr 0.00129	Loss 0.1451 (0.2255)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 12:29:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][700/703]	Step 89632	lr 0.00129	Loss 0.3479 (0.2281)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:29:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [153][703/703]	Step 89635	lr 0.00129	Loss 0.3704 (0.2284)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:29:45午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [153/159] Final Prec@1 93.6956%
12/22 12:29:51午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [153][78/79]	Step 89636	Loss 1.4354	Prec@(1,5) (65.1%, 89.6%)
12/22 12:29:51午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [153/159] Final Prec@1 65.1200%
12/22 12:29:51午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.3600%
12/22 12:30:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][100/703]	Step 89736	lr 0.00121	Loss 0.1754 (0.2174)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.9%)	
12/22 12:30:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][200/703]	Step 89836	lr 0.00121	Loss 0.1762 (0.2210)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.8%)	
12/22 12:30:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][300/703]	Step 89936	lr 0.00121	Loss 0.2139 (0.2232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.9%, 99.8%)	
12/22 12:31:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][400/703]	Step 90036	lr 0.00121	Loss 0.1515 (0.2243)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 12:31:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][500/703]	Step 90136	lr 0.00121	Loss 0.2509 (0.2269)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 12:31:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][600/703]	Step 90236	lr 0.00121	Loss 0.1668 (0.2261)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 12:32:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][700/703]	Step 90336	lr 0.00121	Loss 0.2161 (0.2278)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:32:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [154][703/703]	Step 90339	lr 0.00121	Loss 0.2381 (0.2280)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:32:17午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [154/159] Final Prec@1 93.6800%
12/22 12:32:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [154][78/79]	Step 90340	Loss 1.4343	Prec@(1,5) (65.6%, 89.3%)
12/22 12:32:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [154/159] Final Prec@1 65.6200%
12/22 12:32:24午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6200%
12/22 12:32:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][100/703]	Step 90440	lr 0.00115	Loss 0.1490 (0.2100)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:33:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][200/703]	Step 90540	lr 0.00115	Loss 0.1422 (0.2151)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.9%, 99.7%)	
12/22 12:33:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][300/703]	Step 90640	lr 0.00115	Loss 0.2378 (0.2231)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:33:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][400/703]	Step 90740	lr 0.00115	Loss 0.2175 (0.2205)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:34:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][500/703]	Step 90840	lr 0.00115	Loss 0.2133 (0.2217)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:34:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][600/703]	Step 90940	lr 0.00115	Loss 0.1992 (0.2215)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 12:34:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][700/703]	Step 91040	lr 0.00115	Loss 0.2379 (0.2208)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 12:34:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [155][703/703]	Step 91043	lr 0.00115	Loss 0.2007 (0.2211)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 12:34:51午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [155/159] Final Prec@1 93.7489%
12/22 12:34:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [155][78/79]	Step 91044	Loss 1.4350	Prec@(1,5) (65.1%, 89.7%)
12/22 12:34:58午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [155/159] Final Prec@1 65.1800%
12/22 12:34:58午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6200%
12/22 12:35:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][100/703]	Step 91144	lr 0.00109	Loss 0.1770 (0.2043)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.9%)	
12/22 12:35:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][200/703]	Step 91244	lr 0.00109	Loss 0.2647 (0.2058)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:36:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][300/703]	Step 91344	lr 0.00109	Loss 0.1307 (0.2057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:36:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][400/703]	Step 91444	lr 0.00109	Loss 0.1731 (0.2084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:36:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][500/703]	Step 91544	lr 0.00109	Loss 0.2169 (0.2092)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:37:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][600/703]	Step 91644	lr 0.00109	Loss 0.2556 (0.2122)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.8%)	
12/22 12:37:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][700/703]	Step 91744	lr 0.00109	Loss 0.2073 (0.2142)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.8%)	
12/22 12:37:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [156][703/703]	Step 91747	lr 0.00109	Loss 0.2429 (0.2142)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.8%)	
12/22 12:37:24午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [156/159] Final Prec@1 94.0267%
12/22 12:37:30午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [156][78/79]	Step 91748	Loss 1.4367	Prec@(1,5) (65.1%, 89.6%)
12/22 12:37:30午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [156/159] Final Prec@1 65.1600%
12/22 12:37:30午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6200%
12/22 12:37:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][100/703]	Step 91848	lr 0.00105	Loss 0.1546 (0.1981)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/22 12:38:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][200/703]	Step 91948	lr 0.00105	Loss 0.2081 (0.1993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/22 12:38:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][300/703]	Step 92048	lr 0.00105	Loss 0.2043 (0.2020)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/22 12:38:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][400/703]	Step 92148	lr 0.00105	Loss 0.1717 (0.2061)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
12/22 12:39:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][500/703]	Step 92248	lr 0.00105	Loss 0.1989 (0.2086)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:39:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][600/703]	Step 92348	lr 0.00105	Loss 0.2176 (0.2097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:39:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][700/703]	Step 92448	lr 0.00105	Loss 0.3039 (0.2098)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:39:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [157][703/703]	Step 92451	lr 0.00105	Loss 0.3117 (0.2100)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:39:56午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [157/159] Final Prec@1 94.2311%
12/22 12:40:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [157][78/79]	Step 92452	Loss 1.4435	Prec@(1,5) (65.6%, 89.7%)
12/22 12:40:03午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [157/159] Final Prec@1 65.6000%
12/22 12:40:03午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6200%
12/22 12:40:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][100/703]	Step 92552	lr 0.00102	Loss 0.2828 (0.1977)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/22 12:40:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][200/703]	Step 92652	lr 0.00102	Loss 0.1752 (0.1966)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/22 12:41:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][300/703]	Step 92752	lr 0.00102	Loss 0.2260 (0.2020)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/22 12:41:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][400/703]	Step 92852	lr 0.00102	Loss 0.2747 (0.2055)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:41:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][500/703]	Step 92952	lr 0.00102	Loss 0.2026 (0.2072)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 12:42:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][600/703]	Step 93052	lr 0.00102	Loss 0.1937 (0.2089)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:42:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][700/703]	Step 93152	lr 0.00102	Loss 0.2208 (0.2095)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:42:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [158][703/703]	Step 93155	lr 0.00102	Loss 0.3041 (0.2097)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:42:30午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [158/159] Final Prec@1 94.1533%
12/22 12:42:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [158][78/79]	Step 93156	Loss 1.4632	Prec@(1,5) (64.8%, 89.5%)
12/22 12:42:36午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [158/159] Final Prec@1 64.7800%
12/22 12:42:36午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6200%
12/22 12:42:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][100/703]	Step 93256	lr 0.00101	Loss 0.1721 (0.1914)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/22 12:43:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][200/703]	Step 93356	lr 0.00101	Loss 0.1143 (0.1950)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/22 12:43:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][300/703]	Step 93456	lr 0.00101	Loss 0.2214 (0.1994)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/22 12:43:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][400/703]	Step 93556	lr 0.00101	Loss 0.2148 (0.2020)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/22 12:44:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][500/703]	Step 93656	lr 0.00101	Loss 0.3376 (0.2042)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
12/22 12:44:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][600/703]	Step 93756	lr 0.00101	Loss 0.3830 (0.2052)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
12/22 12:45:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][700/703]	Step 93856	lr 0.00101	Loss 0.2064 (0.2074)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:45:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [159][703/703]	Step 93859	lr 0.00101	Loss 0.1837 (0.2074)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 12:45:02午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [159/159] Final Prec@1 94.2356%
12/22 12:45:08午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [159][78/79]	Step 93860	Loss 1.4456	Prec@(1,5) (65.9%, 89.2%)
12/22 12:45:08午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [159/159] Final Prec@1 65.8600%
12/22 12:45:09午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.8600%
12/22 12:45:09午後 searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 65.8600%
12/22 12:45:09午後 searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('avg_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[3, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 04:23:13PM parser.py:28 [INFO] 
12/22 04:23:13PM parser.py:29 [INFO] Parameters:
12/22 04:23:13PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30/DAG
12/22 04:23:13PM parser.py:31 [INFO] T=10.0
12/22 04:23:13PM parser.py:31 [INFO] ADVANCED=1
12/22 04:23:13PM parser.py:31 [INFO] ALPHA_LR=0.0003
12/22 04:23:13PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/22 04:23:13PM parser.py:31 [INFO] ARCH_CRITERION=expected
12/22 04:23:13PM parser.py:31 [INFO] BATCH_SIZE=64
12/22 04:23:13PM parser.py:31 [INFO] CASCADE=0
12/22 04:23:13PM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/22 04:23:13PM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 30]
12/22 04:23:13PM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/22 04:23:13PM parser.py:31 [INFO] DATA_PATH=../data/
12/22 04:23:13PM parser.py:31 [INFO] DATASET=cifar100
12/22 04:23:13PM parser.py:31 [INFO] DEPTH_COEF=0.0
12/22 04:23:13PM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/22 04:23:13PM parser.py:31 [INFO] DISCRETE=1
12/22 04:23:13PM parser.py:31 [INFO] EPOCHS=50
12/22 04:23:13PM parser.py:31 [INFO] EVAL_EPOCHS=90
12/22 04:23:13PM parser.py:31 [INFO] EXP_NAME=s0-expected2-sw3-g1_30-30
12/22 04:23:13PM parser.py:31 [INFO] FINAL_L=0.0
12/22 04:23:13PM parser.py:31 [INFO] G=1.0
12/22 04:23:13PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/22 04:23:13PM parser.py:31 [INFO] GPUS=[0]
12/22 04:23:13PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/22 04:23:13PM parser.py:31 [INFO] INIT_CHANNELS=16
12/22 04:23:13PM parser.py:31 [INFO] L=0.0
12/22 04:23:13PM parser.py:31 [INFO] LAYERS=32
12/22 04:23:13PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/22 04:23:13PM parser.py:31 [INFO] NAME=Curriculum
12/22 04:23:13PM parser.py:31 [INFO] NONKD=1
12/22 04:23:13PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30
12/22 04:23:13PM parser.py:31 [INFO] PCDARTS=0
12/22 04:23:13PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30/plots
12/22 04:23:13PM parser.py:31 [INFO] PRINT_FREQ=100
12/22 04:23:13PM parser.py:31 [INFO] RESET=0
12/22 04:23:13PM parser.py:31 [INFO] RESUME_PATH=None
12/22 04:23:13PM parser.py:31 [INFO] SAVE=s0-expected2-sw3-g1_30-30
12/22 04:23:13PM parser.py:31 [INFO] SEED=0
12/22 04:23:13PM parser.py:31 [INFO] SHARE_STAGE=0
12/22 04:23:13PM parser.py:31 [INFO] SLIDE_WINDOW=3
12/22 04:23:13PM parser.py:31 [INFO] SPEC_CELL=1
12/22 04:23:13PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/22 04:23:13PM parser.py:31 [INFO] TEACHER_NAME=none
12/22 04:23:13PM parser.py:31 [INFO] TEACHER_PATH=none
12/22 04:23:13PM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/22 04:23:13PM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
12/22 04:23:13PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/22 04:23:13PM parser.py:31 [INFO] W_LR=0.025
12/22 04:23:13PM parser.py:31 [INFO] W_LR_MIN=0.001
12/22 04:23:13PM parser.py:31 [INFO] W_MOMENTUM=0.9
12/22 04:23:13PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/22 04:23:13PM parser.py:31 [INFO] WORKERS=4
12/22 04:23:13PM parser.py:32 [INFO] 
12/22 04:23:14PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/22 04:24:12PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3694 (4.5194)	Arch Loss 4.4417 (4.5190)	Arch Hard Loss 4.4417 (4.5190)	Arch Beta Loss 6.1922 (6.1934)	Arch depth Loss -0.0037 (-0.0013)	Prec@(1,5) (2.2%, 9.5%)	
12/22 04:25:06PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1349 (4.4059)	Arch Loss 4.2587 (4.4071)	Arch Hard Loss 4.2587 (4.4071)	Arch Beta Loss 6.1863 (6.1910)	Arch depth Loss -0.0055 (-0.0032)	Prec@(1,5) (2.8%, 13.1%)	
12/22 04:25:59PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 3.9842 (4.3044)	Arch Loss 4.0299 (4.3103)	Arch Hard Loss 4.0299 (4.3103)	Arch Beta Loss 6.1811 (6.1883)	Arch depth Loss -0.0086 (-0.0046)	Prec@(1,5) (4.0%, 16.4%)	
12/22 04:26:47PM searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9282 (4.2423)	Arch Loss 3.9136 (4.2409)	Arch Hard Loss 3.9136 (4.2409)	Arch Beta Loss 6.1731 (6.1856)	Arch depth Loss -0.0079 (-0.0054)	Prec@(1,5) (4.7%, 18.4%)	
12/22 04:26:48PM searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  0/149] Final Prec@1 4.7440%
12/22 04:26:56PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 3.9390	Prec@(1,5) (7.6%, 28.4%)
12/22 04:27:04PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 3.9303	Prec@(1,5) (8.0%, 28.4%)
12/22 04:27:12PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 3.9266	Prec@(1,5) (8.1%, 28.7%)
12/22 04:27:19PM SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 3.9236	Prec@(1,5) (8.2%, 28.6%)
12/22 04:27:20PM SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  0/149] Final Prec@1 8.1720%
12/22 04:27:20PM searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('avg_pool_3x3', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 1)], [('max_pool_3x3', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 3)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 8), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG3_concat=[10, 11])
12/22 04:27:20PM searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 8.1720%
12/22 04:28:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.025	Loss 3.8652 (3.9237)	Arch Loss 3.8876 (3.9150)	Arch Hard Loss 3.8876 (3.9150)	Arch Beta Loss 6.1616 (6.1675)	Arch depth Loss -0.0096 (-0.0090)	Prec@(1,5) (8.5%, 28.5%)	
12/22 04:29:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.025	Loss 3.8150 (3.8830)	Arch Loss 3.8589 (3.8717)	Arch Hard Loss 3.8589 (3.8717)	Arch Beta Loss 6.1530 (6.1624)	Arch depth Loss -0.0087 (-0.0091)	Prec@(1,5) (9.0%, 30.3%)	
12/22 04:30:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.025	Loss 3.6657 (3.8433)	Arch Loss 3.4919 (3.8275)	Arch Hard Loss 3.4919 (3.8275)	Arch Beta Loss 6.1425 (6.1576)	Arch depth Loss -0.0069 (-0.0087)	Prec@(1,5) (9.9%, 31.5%)	
12/22 04:30:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.025	Loss 3.8416 (3.8034)	Arch Loss 3.8971 (3.7929)	Arch Hard Loss 3.8971 (3.7929)	Arch Beta Loss 6.1333 (6.1530)	Arch depth Loss -0.0060 (-0.0081)	Prec@(1,5) (10.5%, 32.8%)	
12/22 04:30:53午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  1/149] Final Prec@1 10.4680%
12/22 04:31:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.6803	Prec@(1,5) (12.2%, 36.4%)
12/22 04:31:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.6680	Prec@(1,5) (12.4%, 36.7%)
12/22 04:31:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.6718	Prec@(1,5) (12.4%, 36.5%)
12/22 04:31:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.6695	Prec@(1,5) (12.4%, 36.5%)
12/22 04:31:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  1/149] Final Prec@1 12.3920%
12/22 04:31:24午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('avg_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 7)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 4)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/22 04:31:25午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 12.3920%
12/22 04:32:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02499	Loss 3.7584 (3.6109)	Arch Loss 3.5583 (3.6097)	Arch Hard Loss 3.5583 (3.6097)	Arch Beta Loss 6.1250 (6.1290)	Arch depth Loss -0.0052 (-0.0057)	Prec@(1,5) (13.7%, 38.0%)	
12/22 04:33:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02499	Loss 3.4824 (3.5700)	Arch Loss 3.3766 (3.5762)	Arch Hard Loss 3.3766 (3.5762)	Arch Beta Loss 6.1147 (6.1249)	Arch depth Loss -0.0061 (-0.0053)	Prec@(1,5) (14.4%, 39.5%)	
12/22 04:34:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02499	Loss 3.3415 (3.5273)	Arch Loss 3.4828 (3.5411)	Arch Hard Loss 3.4828 (3.5411)	Arch Beta Loss 6.1031 (6.1198)	Arch depth Loss -0.0080 (-0.0058)	Prec@(1,5) (15.3%, 40.9%)	
12/22 04:34:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02499	Loss 3.4015 (3.4958)	Arch Loss 3.3587 (3.5079)	Arch Hard Loss 3.3587 (3.5079)	Arch Beta Loss 6.0885 (6.1141)	Arch depth Loss -0.0106 (-0.0066)	Prec@(1,5) (15.9%, 41.9%)	
12/22 04:34:57午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  2/149] Final Prec@1 15.8560%
12/22 04:35:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.3529	Prec@(1,5) (17.8%, 46.6%)
12/22 04:35:14午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.3696	Prec@(1,5) (17.5%, 45.9%)
12/22 04:35:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.3750	Prec@(1,5) (17.5%, 45.7%)
12/22 04:35:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.3762	Prec@(1,5) (17.6%, 45.5%)
12/22 04:35:29午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  2/149] Final Prec@1 17.6200%
12/22 04:35:29午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('avg_pool_3x3', 7)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/22 04:35:29午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 17.6200%
12/22 04:36:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02498	Loss 3.7894 (3.3569)	Arch Loss 3.3326 (3.3512)	Arch Hard Loss 3.3326 (3.3512)	Arch Beta Loss 6.0768 (6.0825)	Arch depth Loss -0.0093 (-0.0102)	Prec@(1,5) (17.5%, 45.5%)	
12/22 04:37:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02498	Loss 3.1124 (3.3147)	Arch Loss 3.5110 (3.3329)	Arch Hard Loss 3.5110 (3.3329)	Arch Beta Loss 6.0619 (6.0759)	Arch depth Loss -0.0106 (-0.0102)	Prec@(1,5) (18.5%, 46.5%)	
12/22 04:38:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02498	Loss 3.1127 (3.2814)	Arch Loss 3.4974 (3.3047)	Arch Hard Loss 3.4974 (3.3047)	Arch Beta Loss 6.0525 (6.0696)	Arch depth Loss -0.0119 (-0.0106)	Prec@(1,5) (19.1%, 47.6%)	
12/22 04:39:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02498	Loss 3.1134 (3.2557)	Arch Loss 3.2260 (3.2847)	Arch Hard Loss 3.2260 (3.2847)	Arch Beta Loss 6.0501 (6.0654)	Arch depth Loss -0.0129 (-0.0112)	Prec@(1,5) (19.8%, 48.3%)	
12/22 04:39:02午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  3/149] Final Prec@1 19.7400%
12/22 04:39:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.2028	Prec@(1,5) (21.0%, 49.9%)
12/22 04:39:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.2050	Prec@(1,5) (21.0%, 49.9%)
12/22 04:39:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.2126	Prec@(1,5) (20.7%, 49.9%)
12/22 04:39:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.2159	Prec@(1,5) (20.9%, 49.8%)
12/22 04:39:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  3/149] Final Prec@1 20.9000%
12/22 04:39:33午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 4), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/22 04:39:33午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 20.9000%
12/22 04:40:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02496	Loss 2.9573 (3.0855)	Arch Loss 2.9497 (3.1871)	Arch Hard Loss 2.9497 (3.1871)	Arch Beta Loss 6.0404 (6.0455)	Arch depth Loss -0.0123 (-0.0126)	Prec@(1,5) (23.0%, 53.3%)	
12/22 04:41:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02496	Loss 3.2240 (3.0771)	Arch Loss 3.1104 (3.1575)	Arch Hard Loss 3.1104 (3.1575)	Arch Beta Loss 6.0282 (6.0398)	Arch depth Loss -0.0128 (-0.0129)	Prec@(1,5) (23.3%, 53.2%)	
12/22 04:42:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02496	Loss 2.6710 (3.0692)	Arch Loss 3.0120 (3.1343)	Arch Hard Loss 3.0120 (3.1343)	Arch Beta Loss 6.0170 (6.0339)	Arch depth Loss -0.0120 (-0.0126)	Prec@(1,5) (23.6%, 53.6%)	
12/22 04:43:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02496	Loss 2.9937 (3.0614)	Arch Loss 2.8158 (3.1109)	Arch Hard Loss 2.8158 (3.1109)	Arch Beta Loss 6.0079 (6.0287)	Arch depth Loss -0.0159 (-0.0129)	Prec@(1,5) (23.6%, 53.8%)	
12/22 04:43:07午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  4/149] Final Prec@1 23.6600%
12/22 04:43:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.1410	Prec@(1,5) (23.0%, 52.6%)
12/22 04:43:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.1028	Prec@(1,5) (23.4%, 53.2%)
12/22 04:43:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.0943	Prec@(1,5) (23.5%, 53.5%)
12/22 04:43:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.0927	Prec@(1,5) (23.7%, 53.6%)
12/22 04:43:39午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  4/149] Final Prec@1 23.6800%
12/22 04:43:39午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('max_pool_3x3', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/22 04:43:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 23.6800%
12/22 04:44:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02493	Loss 3.1351 (2.9084)	Arch Loss 3.1141 (2.9723)	Arch Hard Loss 3.1141 (2.9723)	Arch Beta Loss 6.0009 (6.0058)	Arch depth Loss -0.0149 (-0.0143)	Prec@(1,5) (26.2%, 57.9%)	
12/22 04:45:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02493	Loss 3.2432 (2.9027)	Arch Loss 3.5069 (2.9879)	Arch Hard Loss 3.5069 (2.9879)	Arch Beta Loss 5.9903 (6.0003)	Arch depth Loss -0.0177 (-0.0158)	Prec@(1,5) (26.9%, 57.9%)	
12/22 04:46:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02493	Loss 2.8523 (2.9083)	Arch Loss 2.6290 (2.9664)	Arch Hard Loss 2.6290 (2.9664)	Arch Beta Loss 5.9771 (5.9944)	Arch depth Loss -0.0154 (-0.0163)	Prec@(1,5) (26.6%, 57.5%)	
12/22 04:47:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02493	Loss 2.6623 (2.8935)	Arch Loss 2.6164 (2.9455)	Arch Hard Loss 2.6164 (2.9455)	Arch Beta Loss 5.9661 (5.9890)	Arch depth Loss -0.0152 (-0.0160)	Prec@(1,5) (26.6%, 58.0%)	
12/22 04:47:13午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  5/149] Final Prec@1 26.6040%
12/22 04:47:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 2.8610	Prec@(1,5) (27.3%, 59.4%)
12/22 04:47:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 2.8754	Prec@(1,5) (27.3%, 59.3%)
12/22 04:47:37午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 2.8763	Prec@(1,5) (27.0%, 58.9%)
12/22 04:47:44午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 2.8706	Prec@(1,5) (27.1%, 59.0%)
12/22 04:47:44午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  5/149] Final Prec@1 27.1200%
12/22 04:47:44午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/22 04:47:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 27.1200%
12/22 04:48:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02491	Loss 2.8040 (2.7512)	Arch Loss 2.9987 (2.8535)	Arch Hard Loss 2.9987 (2.8535)	Arch Beta Loss 5.9512 (5.9595)	Arch depth Loss -0.0182 (-0.0157)	Prec@(1,5) (29.8%, 61.5%)	
12/22 04:49:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02491	Loss 2.8077 (2.7591)	Arch Loss 3.0086 (2.8373)	Arch Hard Loss 3.0086 (2.8373)	Arch Beta Loss 5.9395 (5.9533)	Arch depth Loss -0.0210 (-0.0177)	Prec@(1,5) (29.4%, 61.0%)	
12/22 04:50:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02491	Loss 2.8012 (2.7457)	Arch Loss 2.6598 (2.8136)	Arch Hard Loss 2.6598 (2.8136)	Arch Beta Loss 5.9295 (5.9476)	Arch depth Loss -0.0192 (-0.0182)	Prec@(1,5) (29.4%, 61.4%)	
12/22 04:51:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02491	Loss 2.8704 (2.7363)	Arch Loss 2.8387 (2.8149)	Arch Hard Loss 2.8387 (2.8149)	Arch Beta Loss 5.9211 (5.9423)	Arch depth Loss -0.0200 (-0.0184)	Prec@(1,5) (29.5%, 61.7%)	
12/22 04:51:18午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  6/149] Final Prec@1 29.5120%
12/22 04:51:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 2.7267	Prec@(1,5) (30.8%, 61.7%)
12/22 04:51:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 2.7103	Prec@(1,5) (31.1%, 62.3%)
12/22 04:51:42午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 2.7203	Prec@(1,5) (31.0%, 62.4%)
12/22 04:51:49午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 2.7296	Prec@(1,5) (30.8%, 62.0%)
12/22 04:51:49午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  6/149] Final Prec@1 30.8240%
12/22 04:51:49午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=[10, 11])
12/22 04:51:49午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 30.8240%
12/22 04:52:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02487	Loss 2.8815 (2.5780)	Arch Loss 2.6099 (2.7338)	Arch Hard Loss 2.6099 (2.7338)	Arch Beta Loss 5.9075 (5.9142)	Arch depth Loss -0.0231 (-0.0220)	Prec@(1,5) (32.8%, 65.5%)	
12/22 04:53:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02487	Loss 2.6492 (2.5842)	Arch Loss 2.7507 (2.7085)	Arch Hard Loss 2.7507 (2.7085)	Arch Beta Loss 5.8965 (5.9078)	Arch depth Loss -0.0234 (-0.0225)	Prec@(1,5) (32.9%, 65.2%)	
12/22 04:54:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02487	Loss 2.9609 (2.5799)	Arch Loss 3.2104 (2.7004)	Arch Hard Loss 3.2104 (2.7004)	Arch Beta Loss 5.8871 (5.9027)	Arch depth Loss -0.0230 (-0.0227)	Prec@(1,5) (33.0%, 65.6%)	
12/22 04:55:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02487	Loss 2.6884 (2.5716)	Arch Loss 2.7444 (2.6834)	Arch Hard Loss 2.7444 (2.6834)	Arch Beta Loss 5.8814 (5.8980)	Arch depth Loss -0.0241 (-0.0230)	Prec@(1,5) (33.0%, 65.8%)	
12/22 04:55:23午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  7/149] Final Prec@1 33.0240%
12/22 04:55:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.6587	Prec@(1,5) (32.0%, 64.4%)
12/22 04:55:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.6435	Prec@(1,5) (32.0%, 64.6%)
12/22 04:55:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.6428	Prec@(1,5) (32.0%, 64.7%)
12/22 04:55:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.6527	Prec@(1,5) (31.8%, 64.4%)
12/22 04:55:54午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  7/149] Final Prec@1 31.8320%
12/22 04:55:54午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG3_concat=[10, 11])
12/22 04:55:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 31.8320%
12/22 04:56:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02483	Loss 2.5806 (2.4527)	Arch Loss 2.7871 (2.6042)	Arch Hard Loss 2.7871 (2.6042)	Arch Beta Loss 5.8721 (5.8766)	Arch depth Loss -0.0254 (-0.0243)	Prec@(1,5) (35.3%, 68.3%)	
12/22 04:57:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02483	Loss 2.1551 (2.4609)	Arch Loss 2.7097 (2.5991)	Arch Hard Loss 2.7097 (2.5991)	Arch Beta Loss 5.8593 (5.8718)	Arch depth Loss -0.0263 (-0.0247)	Prec@(1,5) (35.1%, 68.1%)	
12/22 04:58:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02483	Loss 2.4074 (2.4575)	Arch Loss 2.8038 (2.5981)	Arch Hard Loss 2.8038 (2.5981)	Arch Beta Loss 5.8502 (5.8663)	Arch depth Loss -0.0267 (-0.0253)	Prec@(1,5) (35.2%, 68.2%)	
12/22 04:59:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02483	Loss 2.0931 (2.4558)	Arch Loss 2.6771 (2.5788)	Arch Hard Loss 2.6771 (2.5788)	Arch Beta Loss 5.8479 (5.8624)	Arch depth Loss -0.0230 (-0.0252)	Prec@(1,5) (35.4%, 68.3%)	
12/22 04:59:27午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  8/149] Final Prec@1 35.3920%
12/22 04:59:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.4832	Prec@(1,5) (34.8%, 68.3%)
12/22 04:59:43午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.4810	Prec@(1,5) (34.9%, 68.0%)
12/22 04:59:51午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.4996	Prec@(1,5) (34.9%, 67.4%)
12/22 04:59:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.5004	Prec@(1,5) (34.7%, 67.4%)
12/22 04:59:58午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  8/149] Final Prec@1 34.7600%
12/22 04:59:58午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 04:59:58午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 34.7600%
12/22 05:00:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02479	Loss 2.2528 (2.3322)	Arch Loss 2.4740 (2.4995)	Arch Hard Loss 2.4740 (2.4995)	Arch Beta Loss 5.8393 (5.8445)	Arch depth Loss -0.0226 (-0.0228)	Prec@(1,5) (37.8%, 71.0%)	
12/22 05:01:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02479	Loss 2.1857 (2.3412)	Arch Loss 2.4161 (2.4906)	Arch Hard Loss 2.4161 (2.4906)	Arch Beta Loss 5.8284 (5.8385)	Arch depth Loss -0.0244 (-0.0236)	Prec@(1,5) (37.6%, 70.8%)	
12/22 05:02:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02479	Loss 2.4423 (2.3417)	Arch Loss 2.2976 (2.4916)	Arch Hard Loss 2.2976 (2.4916)	Arch Beta Loss 5.8234 (5.8340)	Arch depth Loss -0.0213 (-0.0237)	Prec@(1,5) (37.6%, 70.7%)	
12/22 05:03:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02479	Loss 2.1855 (2.3397)	Arch Loss 2.6283 (2.4838)	Arch Hard Loss 2.6283 (2.4838)	Arch Beta Loss 5.8170 (5.8305)	Arch depth Loss -0.0197 (-0.0230)	Prec@(1,5) (37.6%, 70.9%)	
12/22 05:03:30午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [  9/149] Final Prec@1 37.5800%
12/22 05:03:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.4194	Prec@(1,5) (36.1%, 69.2%)
12/22 05:03:46午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.4089	Prec@(1,5) (36.6%, 69.0%)
12/22 05:03:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.4079	Prec@(1,5) (36.6%, 69.0%)
12/22 05:04:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.4077	Prec@(1,5) (36.5%, 69.2%)
12/22 05:04:01午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [  9/149] Final Prec@1 36.5160%
12/22 05:04:01午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 10), ('max_pool_3x3', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:04:01午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 36.5160%
12/22 05:04:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02474	Loss 2.3763 (2.2044)	Arch Loss 2.4362 (2.4497)	Arch Hard Loss 2.4362 (2.4497)	Arch Beta Loss 5.8104 (5.8141)	Arch depth Loss -0.0208 (-0.0204)	Prec@(1,5) (40.2%, 74.1%)	
12/22 05:05:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02474	Loss 2.4623 (2.2345)	Arch Loss 2.2113 (2.4285)	Arch Hard Loss 2.2113 (2.4285)	Arch Beta Loss 5.8045 (5.8112)	Arch depth Loss -0.0207 (-0.0205)	Prec@(1,5) (39.8%, 73.2%)	
12/22 05:06:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02474	Loss 2.2183 (2.2466)	Arch Loss 2.3686 (2.4191)	Arch Hard Loss 2.3686 (2.4191)	Arch Beta Loss 5.7971 (5.8074)	Arch depth Loss -0.0229 (-0.0209)	Prec@(1,5) (39.9%, 73.0%)	
12/22 05:08:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02474	Loss 2.3426 (2.2441)	Arch Loss 2.2513 (2.4084)	Arch Hard Loss 2.2513 (2.4084)	Arch Beta Loss 5.7923 (5.8044)	Arch depth Loss -0.0219 (-0.0212)	Prec@(1,5) (40.0%, 73.1%)	
12/22 05:08:02午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 10/149] Final Prec@1 39.9640%
12/22 05:08:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.3941	Prec@(1,5) (37.7%, 69.6%)
12/22 05:08:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.3451	Prec@(1,5) (38.4%, 70.5%)
12/22 05:08:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.3673	Prec@(1,5) (38.1%, 70.2%)
12/22 05:08:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.3591	Prec@(1,5) (38.2%, 70.4%)
12/22 05:08:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 10/149] Final Prec@1 38.2240%
12/22 05:08:33午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 10), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('max_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 10)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:08:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 38.2240%
12/22 05:09:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02468	Loss 2.0429 (2.1592)	Arch Loss 2.6483 (2.3724)	Arch Hard Loss 2.6483 (2.3724)	Arch Beta Loss 5.7845 (5.7893)	Arch depth Loss -0.0219 (-0.0212)	Prec@(1,5) (42.0%, 75.3%)	
12/22 05:12:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02468	Loss 2.3781 (2.1495)	Arch Loss 2.4302 (2.3538)	Arch Hard Loss 2.4302 (2.3538)	Arch Beta Loss 5.7769 (5.7857)	Arch depth Loss -0.0223 (-0.0216)	Prec@(1,5) (41.6%, 75.3%)	
12/22 05:21:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02468	Loss 2.2551 (2.1528)	Arch Loss 2.1464 (2.3449)	Arch Hard Loss 2.1464 (2.3449)	Arch Beta Loss 5.7688 (5.7813)	Arch depth Loss -0.0222 (-0.0219)	Prec@(1,5) (41.4%, 75.2%)	
12/22 05:22:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02468	Loss 2.0609 (2.1569)	Arch Loss 2.2704 (2.3409)	Arch Hard Loss 2.2704 (2.3409)	Arch Beta Loss 5.7638 (5.7778)	Arch depth Loss -0.0224 (-0.0220)	Prec@(1,5) (41.4%, 75.1%)	
12/22 05:22:03午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 11/149] Final Prec@1 41.3760%
12/22 05:22:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.2832	Prec@(1,5) (39.8%, 72.1%)
12/22 05:22:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.2601	Prec@(1,5) (40.4%, 72.3%)
12/22 05:22:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.2576	Prec@(1,5) (40.3%, 72.6%)
12/22 05:22:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.2572	Prec@(1,5) (40.4%, 72.7%)
12/22 05:22:35午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 11/149] Final Prec@1 40.4240%
12/22 05:22:35午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:22:35午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 40.4240%
12/22 05:23:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02462	Loss 1.9617 (2.0427)	Arch Loss 2.1065 (2.3212)	Arch Hard Loss 2.1065 (2.3212)	Arch Beta Loss 5.7577 (5.7606)	Arch depth Loss -0.0181 (-0.0200)	Prec@(1,5) (43.7%, 77.5%)	
12/22 05:24:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02462	Loss 2.4067 (2.0730)	Arch Loss 2.0844 (2.3112)	Arch Hard Loss 2.0844 (2.3112)	Arch Beta Loss 5.7542 (5.7582)	Arch depth Loss -0.0147 (-0.0180)	Prec@(1,5) (43.2%, 76.6%)	
12/22 05:25:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02462	Loss 1.9115 (2.0738)	Arch Loss 2.5251 (2.2923)	Arch Hard Loss 2.5251 (2.2923)	Arch Beta Loss 5.7437 (5.7555)	Arch depth Loss -0.0153 (-0.0170)	Prec@(1,5) (43.5%, 76.4%)	
12/22 05:26:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02462	Loss 1.7535 (2.0746)	Arch Loss 2.1975 (2.2779)	Arch Hard Loss 2.1975 (2.2779)	Arch Beta Loss 5.7385 (5.7522)	Arch depth Loss -0.0173 (-0.0168)	Prec@(1,5) (43.3%, 76.3%)	
12/22 05:26:06午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 12/149] Final Prec@1 43.2880%
12/22 05:26:14午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.3159	Prec@(1,5) (39.7%, 71.6%)
12/22 05:26:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.3050	Prec@(1,5) (39.5%, 71.8%)
12/22 05:26:30午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.3057	Prec@(1,5) (39.6%, 71.6%)
12/22 05:26:37午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.3117	Prec@(1,5) (39.4%, 71.5%)
12/22 05:26:37午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 12/149] Final Prec@1 39.4280%
12/22 05:26:37午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 9), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:26:37午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 40.4240%
12/22 05:27:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02456	Loss 2.1000 (1.9574)	Arch Loss 2.3070 (2.2371)	Arch Hard Loss 2.3070 (2.2371)	Arch Beta Loss 5.7279 (5.7324)	Arch depth Loss -0.0174 (-0.0181)	Prec@(1,5) (45.7%, 79.2%)	
12/22 05:28:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02456	Loss 1.7169 (2.0101)	Arch Loss 2.2202 (2.2412)	Arch Hard Loss 2.2202 (2.2412)	Arch Beta Loss 5.7185 (5.7276)	Arch depth Loss -0.0160 (-0.0175)	Prec@(1,5) (44.6%, 77.8%)	
12/22 05:29:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02456	Loss 1.8245 (2.0040)	Arch Loss 2.1470 (2.2369)	Arch Hard Loss 2.1470 (2.2369)	Arch Beta Loss 5.7178 (5.7248)	Arch depth Loss -0.0138 (-0.0166)	Prec@(1,5) (44.9%, 78.0%)	
12/22 05:30:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02456	Loss 1.8310 (2.0072)	Arch Loss 2.0638 (2.2316)	Arch Hard Loss 2.0638 (2.2316)	Arch Beta Loss 5.7161 (5.7230)	Arch depth Loss -0.0130 (-0.0160)	Prec@(1,5) (44.9%, 77.9%)	
12/22 05:30:08午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 13/149] Final Prec@1 44.8520%
12/22 05:30:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.1561	Prec@(1,5) (42.3%, 75.0%)
12/22 05:30:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.1793	Prec@(1,5) (41.8%, 74.5%)
12/22 05:30:32午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.1709	Prec@(1,5) (42.2%, 74.4%)
12/22 05:30:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.1764	Prec@(1,5) (42.0%, 74.3%)
12/22 05:30:40午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 13/149] Final Prec@1 42.0120%
12/22 05:30:40午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 3)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:30:40午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.0120%
12/22 05:31:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02449	Loss 1.9746 (1.9236)	Arch Loss 2.2265 (2.2316)	Arch Hard Loss 2.2265 (2.2316)	Arch Beta Loss 5.7056 (5.7107)	Arch depth Loss -0.0106 (-0.0121)	Prec@(1,5) (47.0%, 79.4%)	
12/22 05:32:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02449	Loss 2.0437 (1.9435)	Arch Loss 2.1653 (2.2107)	Arch Hard Loss 2.1653 (2.2107)	Arch Beta Loss 5.6993 (5.7070)	Arch depth Loss -0.0101 (-0.0111)	Prec@(1,5) (46.3%, 78.9%)	
12/22 05:33:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02449	Loss 2.0470 (1.9421)	Arch Loss 2.3626 (2.2053)	Arch Hard Loss 2.3626 (2.2053)	Arch Beta Loss 5.6929 (5.7033)	Arch depth Loss -0.0098 (-0.0107)	Prec@(1,5) (46.5%, 79.0%)	
12/22 05:34:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02449	Loss 1.8734 (1.9457)	Arch Loss 2.1042 (2.1953)	Arch Hard Loss 2.1042 (2.1953)	Arch Beta Loss 5.6919 (5.7007)	Arch depth Loss -0.0090 (-0.0103)	Prec@(1,5) (46.4%, 78.9%)	
12/22 05:34:10午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 14/149] Final Prec@1 46.3760%
12/22 05:34:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.1473	Prec@(1,5) (43.2%, 75.2%)
12/22 05:34:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.1717	Prec@(1,5) (42.4%, 74.7%)
12/22 05:34:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.1753	Prec@(1,5) (42.2%, 74.5%)
12/22 05:34:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.1771	Prec@(1,5) (42.1%, 74.5%)
12/22 05:34:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 14/149] Final Prec@1 42.1120%
12/22 05:34:41午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:34:42午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 42.1120%
12/22 05:35:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02441	Loss 2.2465 (1.8430)	Arch Loss 2.0847 (2.1474)	Arch Hard Loss 2.0847 (2.1474)	Arch Beta Loss 5.6896 (5.6900)	Arch depth Loss -0.0081 (-0.0096)	Prec@(1,5) (49.4%, 80.6%)	
12/22 05:36:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02441	Loss 1.6540 (1.8535)	Arch Loss 2.1931 (2.1509)	Arch Hard Loss 2.1931 (2.1509)	Arch Beta Loss 5.6861 (5.6883)	Arch depth Loss -0.0040 (-0.0077)	Prec@(1,5) (48.8%, 80.5%)	
12/22 05:37:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02441	Loss 1.9599 (1.8581)	Arch Loss 1.9529 (2.1579)	Arch Hard Loss 1.9529 (2.1579)	Arch Beta Loss 5.6783 (5.6863)	Arch depth Loss -0.0038 (-0.0066)	Prec@(1,5) (48.7%, 80.4%)	
12/22 05:38:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02441	Loss 1.5915 (1.8711)	Arch Loss 1.9312 (2.1531)	Arch Hard Loss 1.9312 (2.1531)	Arch Beta Loss 5.6727 (5.6839)	Arch depth Loss -0.0037 (-0.0058)	Prec@(1,5) (48.3%, 80.1%)	
12/22 05:38:11午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 15/149] Final Prec@1 48.3360%
12/22 05:38:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.1218	Prec@(1,5) (42.3%, 76.1%)
12/22 05:38:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.0936	Prec@(1,5) (43.5%, 76.6%)
12/22 05:38:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.1000	Prec@(1,5) (43.3%, 76.3%)
12/22 05:38:42午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.0922	Prec@(1,5) (43.6%, 76.4%)
12/22 05:38:42午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 15/149] Final Prec@1 43.5400%
12/22 05:38:42午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 8), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:38:42午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 43.5400%
12/22 05:39:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.02433	Loss 1.6815 (1.7786)	Arch Loss 1.8020 (2.1119)	Arch Hard Loss 1.8020 (2.1119)	Arch Beta Loss 5.6690 (5.6710)	Arch depth Loss -0.0023 (-0.0029)	Prec@(1,5) (51.5%, 81.9%)	
12/22 05:40:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.02433	Loss 1.8669 (1.8002)	Arch Loss 1.9278 (2.1094)	Arch Hard Loss 1.9278 (2.1094)	Arch Beta Loss 5.6593 (5.6679)	Arch depth Loss -0.0034 (-0.0028)	Prec@(1,5) (50.1%, 81.4%)	
12/22 05:41:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.02433	Loss 1.7966 (1.8151)	Arch Loss 2.4566 (2.1238)	Arch Hard Loss 2.4566 (2.1238)	Arch Beta Loss 5.6554 (5.6647)	Arch depth Loss -0.0031 (-0.0030)	Prec@(1,5) (49.9%, 81.0%)	
12/22 05:42:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.02433	Loss 2.0173 (1.8190)	Arch Loss 1.9414 (2.1148)	Arch Hard Loss 1.9414 (2.1148)	Arch Beta Loss 5.6526 (5.6620)	Arch depth Loss -0.0018 (-0.0028)	Prec@(1,5) (49.8%, 81.0%)	
12/22 05:42:13午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 16/149] Final Prec@1 49.7800%
12/22 05:42:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.1073	Prec@(1,5) (44.8%, 75.1%)
12/22 05:42:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.0837	Prec@(1,5) (44.9%, 75.8%)
12/22 05:42:37午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.0854	Prec@(1,5) (44.3%, 75.9%)
12/22 05:42:44午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.0787	Prec@(1,5) (44.4%, 76.1%)
12/22 05:42:44午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 16/149] Final Prec@1 44.3840%
12/22 05:42:44午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 6), ('skip_connect', 5)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:42:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 44.3840%
12/22 05:43:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.02425	Loss 1.6584 (1.7191)	Arch Loss 2.1505 (2.0786)	Arch Hard Loss 2.1505 (2.0786)	Arch Beta Loss 5.6508 (5.6522)	Arch depth Loss 0.0011 (-0.0003)	Prec@(1,5) (51.5%, 82.9%)	
12/22 05:44:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.02425	Loss 1.6840 (1.7438)	Arch Loss 2.0763 (2.0844)	Arch Hard Loss 2.0763 (2.0844)	Arch Beta Loss 5.6444 (5.6501)	Arch depth Loss 0.0038 (0.0010)	Prec@(1,5) (51.3%, 82.6%)	
12/22 05:45:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.02425	Loss 1.8288 (1.7569)	Arch Loss 1.8870 (2.0892)	Arch Hard Loss 1.8870 (2.0892)	Arch Beta Loss 5.6393 (5.6470)	Arch depth Loss 0.0103 (0.0035)	Prec@(1,5) (51.1%, 82.3%)	
12/22 05:46:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.02425	Loss 1.3244 (1.7727)	Arch Loss 1.9423 (2.0847)	Arch Hard Loss 1.9423 (2.0847)	Arch Beta Loss 5.6371 (5.6450)	Arch depth Loss 0.0100 (0.0049)	Prec@(1,5) (50.6%, 82.2%)	
12/22 05:46:15午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 17/149] Final Prec@1 50.6080%
12/22 05:46:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.0743	Prec@(1,5) (44.5%, 76.5%)
12/22 05:46:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.0638	Prec@(1,5) (44.8%, 76.6%)
12/22 05:46:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.0721	Prec@(1,5) (44.6%, 76.3%)
12/22 05:46:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.0736	Prec@(1,5) (44.4%, 76.4%)
12/22 05:46:46午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 17/149] Final Prec@1 44.4280%
12/22 05:46:46午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:46:46午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 44.4280%
12/22 05:47:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.02416	Loss 1.5847 (1.6741)	Arch Loss 2.0160 (2.0273)	Arch Hard Loss 2.0160 (2.0273)	Arch Beta Loss 5.6317 (5.6348)	Arch depth Loss 0.0112 (0.0105)	Prec@(1,5) (52.5%, 83.8%)	
12/22 05:48:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.02416	Loss 1.4882 (1.7132)	Arch Loss 1.8634 (2.0563)	Arch Hard Loss 1.8634 (2.0563)	Arch Beta Loss 5.6251 (5.6317)	Arch depth Loss 0.0129 (0.0115)	Prec@(1,5) (51.7%, 83.2%)	
12/22 05:49:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.02416	Loss 1.7094 (1.7148)	Arch Loss 2.2226 (2.0614)	Arch Hard Loss 2.2226 (2.0614)	Arch Beta Loss 5.6213 (5.6291)	Arch depth Loss 0.0150 (0.0128)	Prec@(1,5) (51.7%, 83.2%)	
12/22 05:50:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.02416	Loss 1.8761 (1.7226)	Arch Loss 1.5054 (2.0505)	Arch Hard Loss 1.5054 (2.0505)	Arch Beta Loss 5.6160 (5.6265)	Arch depth Loss 0.0164 (0.0134)	Prec@(1,5) (51.6%, 83.1%)	
12/22 05:50:15午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 18/149] Final Prec@1 51.5920%
12/22 05:50:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.0529	Prec@(1,5) (45.3%, 76.6%)
12/22 05:50:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.0572	Prec@(1,5) (45.3%, 76.6%)
12/22 05:50:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.0618	Prec@(1,5) (45.4%, 76.6%)
12/22 05:50:46午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.0606	Prec@(1,5) (45.2%, 76.7%)
12/22 05:50:46午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 18/149] Final Prec@1 45.1840%
12/22 05:50:46午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('avg_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:50:46午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1840%
12/22 05:51:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.02406	Loss 1.3374 (1.6139)	Arch Loss 2.1953 (2.0388)	Arch Hard Loss 2.1953 (2.0388)	Arch Beta Loss 5.6121 (5.6142)	Arch depth Loss 0.0253 (0.0209)	Prec@(1,5) (55.0%, 84.6%)	
12/22 05:52:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.02406	Loss 2.0000 (1.6470)	Arch Loss 2.2618 (2.0455)	Arch Hard Loss 2.2618 (2.0455)	Arch Beta Loss 5.6112 (5.6126)	Arch depth Loss 0.0243 (0.0231)	Prec@(1,5) (54.1%, 84.2%)	
12/22 05:53:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.02406	Loss 1.9148 (1.6609)	Arch Loss 1.6125 (2.0272)	Arch Hard Loss 1.6125 (2.0272)	Arch Beta Loss 5.6049 (5.6111)	Arch depth Loss 0.0266 (0.0240)	Prec@(1,5) (53.6%, 84.0%)	
12/22 05:54:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.02406	Loss 1.5433 (1.6704)	Arch Loss 2.0185 (2.0210)	Arch Hard Loss 2.0185 (2.0210)	Arch Beta Loss 5.6039 (5.6093)	Arch depth Loss 0.0276 (0.0247)	Prec@(1,5) (53.5%, 83.9%)	
12/22 05:54:15午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 19/149] Final Prec@1 53.4800%
12/22 05:54:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.0610	Prec@(1,5) (45.3%, 77.0%)
12/22 05:54:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.0602	Prec@(1,5) (45.2%, 76.9%)
12/22 05:54:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.0485	Prec@(1,5) (45.3%, 76.9%)
12/22 05:54:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.0432	Prec@(1,5) (45.1%, 77.0%)
12/22 05:54:46午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 19/149] Final Prec@1 45.1320%
12/22 05:54:46午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 5)], [('avg_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 10), ('skip_connect', 8)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:54:46午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 45.1840%
12/22 05:55:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.02396	Loss 1.6376 (1.5874)	Arch Loss 2.0411 (2.0186)	Arch Hard Loss 2.0411 (2.0186)	Arch Beta Loss 5.5995 (5.6003)	Arch depth Loss 0.0310 (0.0287)	Prec@(1,5) (55.0%, 85.3%)	
12/22 05:56:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.02396	Loss 1.4876 (1.6103)	Arch Loss 2.7518 (2.0219)	Arch Hard Loss 2.7518 (2.0219)	Arch Beta Loss 5.5960 (5.5994)	Arch depth Loss 0.0356 (0.0308)	Prec@(1,5) (54.5%, 84.7%)	
12/22 05:57:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.02396	Loss 1.2780 (1.6163)	Arch Loss 1.8274 (2.0110)	Arch Hard Loss 1.8274 (2.0110)	Arch Beta Loss 5.5908 (5.5977)	Arch depth Loss 0.0354 (0.0325)	Prec@(1,5) (54.5%, 84.7%)	
12/22 05:58:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.02396	Loss 1.9001 (1.6350)	Arch Loss 1.6035 (2.0032)	Arch Hard Loss 1.6035 (2.0032)	Arch Beta Loss 5.5896 (5.5959)	Arch depth Loss 0.0386 (0.0334)	Prec@(1,5) (54.1%, 84.2%)	
12/22 05:58:13午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 20/149] Final Prec@1 54.1120%
12/22 05:58:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 1.9836	Prec@(1,5) (47.0%, 78.2%)
12/22 05:58:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 1.9856	Prec@(1,5) (47.2%, 78.2%)
12/22 05:58:37午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 1.9864	Prec@(1,5) (47.1%, 78.2%)
12/22 05:58:44午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 1.9907	Prec@(1,5) (46.8%, 78.1%)
12/22 05:58:44午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 20/149] Final Prec@1 46.8520%
12/22 05:58:44午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 05:58:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.8520%
12/22 05:59:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.02386	Loss 1.5784 (1.5276)	Arch Loss 2.3452 (2.0043)	Arch Hard Loss 2.3452 (2.0043)	Arch Beta Loss 5.5871 (5.5876)	Arch depth Loss 0.0423 (0.0406)	Prec@(1,5) (56.1%, 86.8%)	
12/22 06:00:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.02386	Loss 1.7206 (1.5611)	Arch Loss 2.0648 (2.0045)	Arch Hard Loss 2.0648 (2.0045)	Arch Beta Loss 5.5871 (5.5878)	Arch depth Loss 0.0490 (0.0437)	Prec@(1,5) (55.0%, 86.1%)	
12/22 06:01:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.02386	Loss 1.5180 (1.5854)	Arch Loss 1.8103 (1.9955)	Arch Hard Loss 1.8103 (1.9955)	Arch Beta Loss 5.5824 (5.5870)	Arch depth Loss 0.0511 (0.0457)	Prec@(1,5) (54.3%, 85.5%)	
12/22 06:02:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.02386	Loss 1.7285 (1.6026)	Arch Loss 1.9094 (1.9888)	Arch Hard Loss 1.9094 (1.9888)	Arch Beta Loss 5.5791 (5.5856)	Arch depth Loss 0.0562 (0.0476)	Prec@(1,5) (54.1%, 85.2%)	
12/22 06:02:14午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 21/149] Final Prec@1 54.0720%
12/22 06:02:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.0384	Prec@(1,5) (45.9%, 76.5%)
12/22 06:02:30午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.0344	Prec@(1,5) (45.8%, 76.8%)
12/22 06:02:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.0332	Prec@(1,5) (45.9%, 76.8%)
12/22 06:02:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.0325	Prec@(1,5) (46.0%, 76.9%)
12/22 06:02:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 21/149] Final Prec@1 46.0560%
12/22 06:02:45午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:02:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.8520%
12/22 06:03:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.02375	Loss 1.6245 (1.4981)	Arch Loss 2.2147 (2.0016)	Arch Hard Loss 2.2147 (2.0016)	Arch Beta Loss 5.5760 (5.5769)	Arch depth Loss 0.0617 (0.0591)	Prec@(1,5) (57.3%, 87.1%)	
12/22 06:04:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.02375	Loss 1.4072 (1.5261)	Arch Loss 1.7198 (1.9744)	Arch Hard Loss 1.7198 (1.9744)	Arch Beta Loss 5.5757 (5.5763)	Arch depth Loss 0.0610 (0.0600)	Prec@(1,5) (56.6%, 86.1%)	
12/22 06:05:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.02375	Loss 1.2814 (1.5447)	Arch Loss 2.1412 (1.9677)	Arch Hard Loss 2.1412 (1.9677)	Arch Beta Loss 5.5704 (5.5753)	Arch depth Loss 0.0637 (0.0608)	Prec@(1,5) (56.2%, 85.8%)	
12/22 06:06:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.02375	Loss 1.5942 (1.5631)	Arch Loss 1.9073 (1.9669)	Arch Hard Loss 1.9073 (1.9669)	Arch Beta Loss 5.5683 (5.5740)	Arch depth Loss 0.0661 (0.0619)	Prec@(1,5) (55.6%, 85.5%)	
12/22 06:06:12午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 22/149] Final Prec@1 55.6480%
12/22 06:06:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 1.9949	Prec@(1,5) (47.4%, 77.7%)
12/22 06:06:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.0015	Prec@(1,5) (46.6%, 77.5%)
12/22 06:06:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 1.9997	Prec@(1,5) (46.4%, 77.6%)
12/22 06:06:43午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.0061	Prec@(1,5) (46.4%, 77.6%)
12/22 06:06:43午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 22/149] Final Prec@1 46.4040%
12/22 06:06:43午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 9), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:06:44午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.8520%
12/22 06:07:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.02363	Loss 1.7450 (1.4364)	Arch Loss 1.9265 (1.9540)	Arch Hard Loss 1.9265 (1.9540)	Arch Beta Loss 5.5653 (5.5672)	Arch depth Loss 0.0691 (0.0673)	Prec@(1,5) (58.5%, 87.8%)	
12/22 06:08:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.02363	Loss 1.4590 (1.4896)	Arch Loss 2.0377 (1.9564)	Arch Hard Loss 2.0377 (1.9564)	Arch Beta Loss 5.5623 (5.5650)	Arch depth Loss 0.0747 (0.0699)	Prec@(1,5) (57.5%, 86.8%)	
12/22 06:09:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.02363	Loss 1.5135 (1.5007)	Arch Loss 1.9018 (1.9601)	Arch Hard Loss 1.9018 (1.9601)	Arch Beta Loss 5.5600 (5.5637)	Arch depth Loss 0.0773 (0.0724)	Prec@(1,5) (57.1%, 86.8%)	
12/22 06:10:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.02363	Loss 1.7134 (1.5181)	Arch Loss 2.0100 (1.9502)	Arch Hard Loss 2.0100 (1.9502)	Arch Beta Loss 5.5583 (5.5627)	Arch depth Loss 0.0797 (0.0738)	Prec@(1,5) (56.6%, 86.4%)	
12/22 06:10:11午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 23/149] Final Prec@1 56.6360%
12/22 06:10:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 1.9722	Prec@(1,5) (47.3%, 78.0%)
12/22 06:10:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 1.9725	Prec@(1,5) (46.9%, 78.4%)
12/22 06:10:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 1.9771	Prec@(1,5) (46.9%, 78.2%)
12/22 06:10:42午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 1.9766	Prec@(1,5) (46.9%, 78.3%)
12/22 06:10:42午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 23/149] Final Prec@1 46.9200%
12/22 06:10:42午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 9), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('max_pool_3x3', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:10:42午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.9200%
12/22 06:11:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.02352	Loss 1.1552 (1.4332)	Arch Loss 2.0502 (1.9298)	Arch Hard Loss 2.0502 (1.9298)	Arch Beta Loss 5.5594 (5.5578)	Arch depth Loss 0.0863 (0.0828)	Prec@(1,5) (58.5%, 87.6%)	
12/22 06:12:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.02352	Loss 1.4108 (1.4517)	Arch Loss 1.9733 (1.9456)	Arch Hard Loss 1.9733 (1.9456)	Arch Beta Loss 5.5544 (5.5574)	Arch depth Loss 0.0909 (0.0860)	Prec@(1,5) (58.1%, 87.4%)	
12/22 06:13:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.02352	Loss 1.8019 (1.4690)	Arch Loss 1.6526 (1.9450)	Arch Hard Loss 1.6526 (1.9450)	Arch Beta Loss 5.5521 (5.5562)	Arch depth Loss 0.0915 (0.0877)	Prec@(1,5) (57.8%, 87.0%)	
12/22 06:14:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.02352	Loss 1.4440 (1.4856)	Arch Loss 1.9470 (1.9433)	Arch Hard Loss 1.9470 (1.9433)	Arch Beta Loss 5.5501 (5.5547)	Arch depth Loss 0.0961 (0.0890)	Prec@(1,5) (57.3%, 86.8%)	
12/22 06:14:11午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 24/149] Final Prec@1 57.3360%
12/22 06:14:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.0867	Prec@(1,5) (45.1%, 77.0%)
12/22 06:14:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.0817	Prec@(1,5) (45.3%, 77.2%)
12/22 06:14:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.0924	Prec@(1,5) (45.2%, 77.0%)
12/22 06:14:42午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.0766	Prec@(1,5) (45.6%, 77.3%)
12/22 06:14:42午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 24/149] Final Prec@1 45.5600%
12/22 06:14:42午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:14:43午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 46.9200%
12/22 06:15:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.02339	Loss 1.5241 (1.4126)	Arch Loss 2.1437 (1.9036)	Arch Hard Loss 2.1437 (1.9036)	Arch Beta Loss 5.5459 (5.5487)	Arch depth Loss 0.0971 (0.0968)	Prec@(1,5) (59.2%, 88.5%)	
12/22 06:16:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.02339	Loss 1.5327 (1.4266)	Arch Loss 2.1952 (1.9033)	Arch Hard Loss 2.1952 (1.9033)	Arch Beta Loss 5.5440 (5.5471)	Arch depth Loss 0.0994 (0.0977)	Prec@(1,5) (58.8%, 88.2%)	
12/22 06:17:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.02339	Loss 1.3120 (1.4411)	Arch Loss 1.5765 (1.9129)	Arch Hard Loss 1.5765 (1.9129)	Arch Beta Loss 5.5407 (5.5457)	Arch depth Loss 0.1056 (0.0992)	Prec@(1,5) (58.5%, 87.8%)	
12/22 06:18:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.02339	Loss 1.3453 (1.4545)	Arch Loss 1.8924 (1.9135)	Arch Hard Loss 1.8924 (1.9135)	Arch Beta Loss 5.5377 (5.5441)	Arch depth Loss 0.1080 (0.1009)	Prec@(1,5) (58.2%, 87.6%)	
12/22 06:18:12午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 25/149] Final Prec@1 58.1520%
12/22 06:18:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 1.9065	Prec@(1,5) (48.7%, 79.9%)
12/22 06:18:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 1.9026	Prec@(1,5) (49.3%, 79.9%)
12/22 06:18:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 1.8815	Prec@(1,5) (49.7%, 80.1%)
12/22 06:18:43午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 1.8807	Prec@(1,5) (49.5%, 80.1%)
12/22 06:18:43午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 25/149] Final Prec@1 49.5440%
12/22 06:18:43午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('skip_connect', 10)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:18:44午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.5440%
12/22 06:19:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.02326	Loss 1.7483 (1.3694)	Arch Loss 1.6249 (1.8124)	Arch Hard Loss 1.6249 (1.8124)	Arch Beta Loss 5.5348 (5.5368)	Arch depth Loss 0.1098 (0.1082)	Prec@(1,5) (60.3%, 88.6%)	
12/22 06:20:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.02326	Loss 0.9638 (1.3946)	Arch Loss 2.0025 (1.8619)	Arch Hard Loss 2.0025 (1.8619)	Arch Beta Loss 5.5289 (5.5350)	Arch depth Loss 0.1130 (0.1097)	Prec@(1,5) (59.7%, 88.3%)	
12/22 06:21:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.02326	Loss 1.2862 (1.4012)	Arch Loss 1.8913 (1.8769)	Arch Hard Loss 1.8913 (1.8769)	Arch Beta Loss 5.5281 (5.5329)	Arch depth Loss 0.1166 (0.1118)	Prec@(1,5) (59.4%, 88.4%)	
12/22 06:22:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.02326	Loss 1.2078 (1.4262)	Arch Loss 2.0987 (1.8897)	Arch Hard Loss 2.0987 (1.8897)	Arch Beta Loss 5.5245 (5.5312)	Arch depth Loss 0.1179 (0.1131)	Prec@(1,5) (58.7%, 87.9%)	
12/22 06:22:10午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 26/149] Final Prec@1 58.7400%
12/22 06:22:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 1.9345	Prec@(1,5) (48.3%, 79.5%)
12/22 06:22:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 1.9180	Prec@(1,5) (48.8%, 79.6%)
12/22 06:22:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 1.9272	Prec@(1,5) (48.4%, 79.5%)
12/22 06:22:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 1.9259	Prec@(1,5) (48.3%, 79.4%)
12/22 06:22:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 26/149] Final Prec@1 48.3120%
12/22 06:22:41午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:22:41午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 49.5440%
12/22 06:23:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.02313	Loss 1.1732 (1.3204)	Arch Loss 2.4152 (1.8845)	Arch Hard Loss 2.4152 (1.8845)	Arch Beta Loss 5.5233 (5.5245)	Arch depth Loss 0.1228 (0.1198)	Prec@(1,5) (61.6%, 89.4%)	
12/22 06:24:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.02313	Loss 1.9029 (1.3691)	Arch Loss 1.7724 (1.8753)	Arch Hard Loss 1.7724 (1.8753)	Arch Beta Loss 5.5210 (5.5227)	Arch depth Loss 0.1241 (0.1217)	Prec@(1,5) (60.2%, 88.8%)	
12/22 06:25:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.02313	Loss 1.4113 (1.3785)	Arch Loss 1.8896 (1.8772)	Arch Hard Loss 1.8896 (1.8772)	Arch Beta Loss 5.5193 (5.5221)	Arch depth Loss 0.1306 (0.1240)	Prec@(1,5) (59.9%, 88.6%)	
12/22 06:26:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.02313	Loss 1.1708 (1.3950)	Arch Loss 1.6209 (1.8715)	Arch Hard Loss 1.6209 (1.8715)	Arch Beta Loss 5.5150 (5.5212)	Arch depth Loss 0.1314 (0.1258)	Prec@(1,5) (59.7%, 88.3%)	
12/22 06:26:07午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 27/149] Final Prec@1 59.6520%
12/22 06:26:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 1.8977	Prec@(1,5) (49.8%, 79.7%)
12/22 06:26:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 1.8792	Prec@(1,5) (50.5%, 80.0%)
12/22 06:26:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 1.8809	Prec@(1,5) (50.4%, 80.0%)
12/22 06:26:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 1.8740	Prec@(1,5) (50.2%, 80.1%)
12/22 06:26:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 27/149] Final Prec@1 50.1360%
12/22 06:26:38午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:26:38午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1360%
12/22 06:27:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.023	Loss 1.5332 (1.3098)	Arch Loss 2.0767 (1.8397)	Arch Hard Loss 2.0767 (1.8397)	Arch Beta Loss 5.5150 (5.5147)	Arch depth Loss 0.1361 (0.1343)	Prec@(1,5) (61.8%, 89.5%)	
12/22 06:28:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.023	Loss 1.2416 (1.3405)	Arch Loss 1.4033 (1.8688)	Arch Hard Loss 1.4033 (1.8688)	Arch Beta Loss 5.5100 (5.5132)	Arch depth Loss 0.1399 (0.1363)	Prec@(1,5) (61.2%, 88.9%)	
12/22 06:29:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.023	Loss 1.4736 (1.3493)	Arch Loss 1.6906 (1.8706)	Arch Hard Loss 1.6906 (1.8706)	Arch Beta Loss 5.5105 (5.5124)	Arch depth Loss 0.1395 (0.1374)	Prec@(1,5) (61.1%, 88.8%)	
12/22 06:30:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.023	Loss 1.2606 (1.3708)	Arch Loss 1.5245 (1.8780)	Arch Hard Loss 1.5245 (1.8780)	Arch Beta Loss 5.5067 (5.5112)	Arch depth Loss 0.1428 (0.1385)	Prec@(1,5) (60.4%, 88.4%)	
12/22 06:30:07午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 28/149] Final Prec@1 60.3680%
12/22 06:30:16午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 1.9086	Prec@(1,5) (48.7%, 80.0%)
12/22 06:30:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 1.9187	Prec@(1,5) (48.4%, 79.9%)
12/22 06:30:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 1.9019	Prec@(1,5) (49.0%, 80.0%)
12/22 06:30:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 1.8904	Prec@(1,5) (49.3%, 80.1%)
12/22 06:30:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 28/149] Final Prec@1 49.3440%
12/22 06:30:38午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('max_pool_3x3', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 8)], [('max_pool_3x3', 7), ('max_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:30:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 50.1360%
12/22 06:31:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.02285	Loss 1.3691 (1.2944)	Arch Loss 1.8111 (1.8768)	Arch Hard Loss 1.8111 (1.8768)	Arch Beta Loss 5.5060 (5.5060)	Arch depth Loss 0.1430 (0.1423)	Prec@(1,5) (62.5%, 89.7%)	
12/22 06:32:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.02285	Loss 1.0313 (1.2975)	Arch Loss 1.6206 (1.8773)	Arch Hard Loss 1.6206 (1.8773)	Arch Beta Loss 5.4987 (5.5042)	Arch depth Loss 0.1495 (0.1448)	Prec@(1,5) (62.8%, 89.8%)	
12/22 06:33:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.02285	Loss 1.3263 (1.3185)	Arch Loss 2.1279 (1.8613)	Arch Hard Loss 2.1279 (1.8613)	Arch Beta Loss 5.4983 (5.5021)	Arch depth Loss 0.1550 (0.1476)	Prec@(1,5) (62.2%, 89.3%)	
12/22 06:34:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.02285	Loss 1.1513 (1.3353)	Arch Loss 1.8140 (1.8531)	Arch Hard Loss 1.8140 (1.8531)	Arch Beta Loss 5.4985 (5.5013)	Arch depth Loss 0.1572 (0.1497)	Prec@(1,5) (61.6%, 89.1%)	
12/22 06:34:05午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 29/149] Final Prec@1 61.6080%
12/22 06:34:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 1.8321	Prec@(1,5) (51.1%, 80.9%)
12/22 06:34:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 1.8217	Prec@(1,5) (51.3%, 81.2%)
12/22 06:34:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 1.8355	Prec@(1,5) (51.0%, 80.8%)
12/22 06:34:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 1.8233	Prec@(1,5) (51.1%, 81.2%)
12/22 06:34:36午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 29/149] Final Prec@1 51.1240%
12/22 06:34:36午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[10, 11], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('avg_pool_3x3', 5), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[10, 11], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 5)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG3_concat=[10, 11])
12/22 06:34:36午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1240%
12/22 06:34:36午後 searchEvalStage_curriculum_trainer.py:151 [INFO] --> Curriculum part A finished. Part B begins!
12/22 06:35:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.02271	Loss 1.3167 (1.2674)	Arch Loss 6.7226 (7.1494)	Arch Hard Loss 1.5406 (1.8406)	Arch Beta Loss 5.1821 (5.3088)	Arch depth Loss 0.1035 (0.1290)	Prec@(1,5) (63.1%, 90.4%)	
12/22 06:36:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.02271	Loss 1.5480 (1.2683)	Arch Loss 7.2914 (7.0552)	Arch Hard Loss 2.2774 (1.8545)	Arch Beta Loss 5.0140 (5.2008)	Arch depth Loss 0.0612 (0.1050)	Prec@(1,5) (63.0%, 90.3%)	
12/22 06:37:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.02271	Loss 1.3669 (1.2909)	Arch Loss 6.6736 (6.9543)	Arch Hard Loss 1.7897 (1.8384)	Arch Beta Loss 4.8839 (5.1159)	Arch depth Loss 0.0224 (0.0837)	Prec@(1,5) (62.4%, 89.8%)	
12/22 06:38:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.02271	Loss 1.5641 (1.3089)	Arch Loss 7.0356 (6.8907)	Arch Hard Loss 2.2510 (1.8403)	Arch Beta Loss 4.7846 (5.0505)	Arch depth Loss -0.0117 (0.0656)	Prec@(1,5) (61.8%, 89.7%)	
12/22 06:38:04午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 30/149] Final Prec@1 61.8280%
12/22 06:38:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 1.8308	Prec@(1,5) (50.7%, 80.8%)
12/22 06:38:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 1.8221	Prec@(1,5) (51.0%, 80.8%)
12/22 06:38:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 1.8290	Prec@(1,5) (51.0%, 80.7%)
12/22 06:38:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 1.8297	Prec@(1,5) (51.0%, 80.7%)
12/22 06:38:35午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 30/149] Final Prec@1 50.9840%
12/22 06:38:35午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 06:38:35午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1240%
12/22 06:39:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.02256	Loss 1.3025 (1.2417)	Arch Loss 6.2961 (6.5286)	Arch Hard Loss 1.6097 (1.7951)	Arch Beta Loss 4.6863 (4.7335)	Arch depth Loss -0.0490 (-0.0308)	Prec@(1,5) (64.4%, 90.0%)	
12/22 06:40:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.02256	Loss 1.1963 (1.2478)	Arch Loss 6.2844 (6.5049)	Arch Hard Loss 1.6857 (1.8175)	Arch Beta Loss 4.5988 (4.6873)	Arch depth Loss -0.0796 (-0.0477)	Prec@(1,5) (63.8%, 90.3%)	
12/22 06:41:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.02256	Loss 1.4919 (1.2726)	Arch Loss 6.6208 (6.4673)	Arch Hard Loss 2.1021 (1.8231)	Arch Beta Loss 4.5187 (4.6442)	Arch depth Loss -0.1069 (-0.0631)	Prec@(1,5) (63.0%, 89.9%)	
12/22 06:42:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.02256	Loss 1.3443 (1.2894)	Arch Loss 6.3610 (6.4226)	Arch Hard Loss 1.9085 (1.8152)	Arch Beta Loss 4.4525 (4.6074)	Arch depth Loss -0.1318 (-0.0762)	Prec@(1,5) (62.4%, 89.7%)	
12/22 06:42:03午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 31/149] Final Prec@1 62.4280%
12/22 06:42:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 1.8223	Prec@(1,5) (50.4%, 80.9%)
12/22 06:42:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 1.8328	Prec@(1,5) (50.5%, 80.6%)
12/22 06:42:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 1.8440	Prec@(1,5) (50.3%, 80.5%)
12/22 06:42:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 1.8488	Prec@(1,5) (50.1%, 80.5%)
12/22 06:42:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 31/149] Final Prec@1 50.1240%
12/22 06:42:34午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 06:42:35午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1240%
12/22 06:43:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.0224	Loss 1.4394 (1.2300)	Arch Loss 6.0056 (6.2230)	Arch Hard Loss 1.6232 (1.8068)	Arch Beta Loss 4.3824 (4.4162)	Arch depth Loss -0.1546 (-0.1426)	Prec@(1,5) (64.1%, 90.7%)	
12/22 06:44:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.0224	Loss 1.2075 (1.2459)	Arch Loss 6.4314 (6.2056)	Arch Hard Loss 2.1133 (1.8226)	Arch Beta Loss 4.3181 (4.3830)	Arch depth Loss -0.1770 (-0.1544)	Prec@(1,5) (63.7%, 90.5%)	
12/22 06:45:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.0224	Loss 1.2430 (1.2516)	Arch Loss 6.2396 (6.1812)	Arch Hard Loss 1.9816 (1.8300)	Arch Beta Loss 4.2580 (4.3511)	Arch depth Loss -0.2000 (-0.1658)	Prec@(1,5) (63.7%, 90.4%)	
12/22 06:46:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.0224	Loss 1.2609 (1.2654)	Arch Loss 5.7947 (6.1473)	Arch Hard Loss 1.5893 (1.8239)	Arch Beta Loss 4.2055 (4.3234)	Arch depth Loss -0.2168 (-0.1758)	Prec@(1,5) (63.2%, 90.3%)	
12/22 06:46:02午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 32/149] Final Prec@1 63.2520%
12/22 06:46:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 1.8661	Prec@(1,5) (50.1%, 80.8%)
12/22 06:46:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 1.8684	Prec@(1,5) (50.1%, 80.9%)
12/22 06:46:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 1.8596	Prec@(1,5) (50.0%, 80.8%)
12/22 06:46:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 1.8527	Prec@(1,5) (50.4%, 80.8%)
12/22 06:46:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 32/149] Final Prec@1 50.4040%
12/22 06:46:33午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 06:46:33午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.1240%
12/22 06:47:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.02225	Loss 1.2395 (1.1592)	Arch Loss 5.9143 (5.9751)	Arch Hard Loss 1.7647 (1.7983)	Arch Beta Loss 4.1496 (4.1768)	Arch depth Loss -0.2360 (-0.2265)	Prec@(1,5) (66.5%, 91.6%)	
12/22 06:48:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.02225	Loss 1.1521 (1.2127)	Arch Loss 5.7659 (5.9402)	Arch Hard Loss 1.6688 (1.7903)	Arch Beta Loss 4.0971 (4.1499)	Arch depth Loss -0.2515 (-0.2353)	Prec@(1,5) (64.5%, 90.7%)	
12/22 06:49:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.02225	Loss 1.1736 (1.2425)	Arch Loss 6.0694 (5.9384)	Arch Hard Loss 2.0222 (1.8147)	Arch Beta Loss 4.0472 (4.1238)	Arch depth Loss -0.2668 (-0.2433)	Prec@(1,5) (63.7%, 90.4%)	
12/22 06:50:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.02225	Loss 1.5481 (1.2606)	Arch Loss 5.5861 (5.9125)	Arch Hard Loss 1.5818 (1.8114)	Arch Beta Loss 4.0043 (4.1011)	Arch depth Loss -0.2805 (-0.2503)	Prec@(1,5) (63.3%, 90.2%)	
12/22 06:50:01午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 33/149] Final Prec@1 63.3280%
12/22 06:50:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 1.8338	Prec@(1,5) (50.6%, 80.7%)
12/22 06:50:16午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 1.8037	Prec@(1,5) (51.6%, 81.0%)
12/22 06:50:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 1.8072	Prec@(1,5) (51.4%, 81.1%)
12/22 06:50:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 1.8077	Prec@(1,5) (51.4%, 81.2%)
12/22 06:50:31午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 33/149] Final Prec@1 51.3480%
12/22 06:50:31午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 06:50:32午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.3480%
12/22 06:51:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.02208	Loss 1.0194 (1.1617)	Arch Loss 5.9071 (5.7257)	Arch Hard Loss 1.9495 (1.7455)	Arch Beta Loss 3.9575 (3.9802)	Arch depth Loss -0.2930 (-0.2874)	Prec@(1,5) (66.0%, 91.7%)	
12/22 06:52:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.02208	Loss 1.1930 (1.2050)	Arch Loss 5.8985 (5.7421)	Arch Hard Loss 1.9845 (1.7843)	Arch Beta Loss 3.9140 (3.9578)	Arch depth Loss -0.3057 (-0.2938)	Prec@(1,5) (64.7%, 91.1%)	
12/22 06:53:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.02208	Loss 1.5726 (1.2192)	Arch Loss 5.9207 (5.7271)	Arch Hard Loss 2.0494 (1.7912)	Arch Beta Loss 3.8713 (3.9359)	Arch depth Loss -0.3147 (-0.2994)	Prec@(1,5) (64.4%, 90.9%)	
12/22 06:54:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.02208	Loss 1.4228 (1.2380)	Arch Loss 5.7255 (5.7152)	Arch Hard Loss 1.8916 (1.7986)	Arch Beta Loss 3.8338 (3.9167)	Arch depth Loss -0.3239 (-0.3041)	Prec@(1,5) (64.0%, 90.6%)	
12/22 06:54:01午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 34/149] Final Prec@1 63.9840%
12/22 06:54:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 1.8281	Prec@(1,5) (52.0%, 81.0%)
12/22 06:54:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 1.8182	Prec@(1,5) (51.8%, 81.4%)
12/22 06:54:25午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 1.8157	Prec@(1,5) (51.8%, 81.4%)
12/22 06:54:32午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 1.8176	Prec@(1,5) (51.6%, 81.5%)
12/22 06:54:32午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 34/149] Final Prec@1 51.5760%
12/22 06:54:32午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 06:54:32午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 51.5760%
12/22 06:55:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.02192	Loss 1.1493 (1.1466)	Arch Loss 5.7047 (5.6218)	Arch Hard Loss 1.9106 (1.8085)	Arch Beta Loss 3.7941 (3.8133)	Arch depth Loss -0.3291 (-0.3271)	Prec@(1,5) (66.7%, 92.2%)	
12/22 06:56:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.02192	Loss 1.2453 (1.1876)	Arch Loss 5.4172 (5.6008)	Arch Hard Loss 1.6616 (1.8068)	Arch Beta Loss 3.7557 (3.7940)	Arch depth Loss -0.3352 (-0.3294)	Prec@(1,5) (65.3%, 91.4%)	
12/22 06:57:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.02192	Loss 1.5439 (1.2087)	Arch Loss 5.5370 (5.5641)	Arch Hard Loss 1.8172 (1.7889)	Arch Beta Loss 3.7198 (3.7752)	Arch depth Loss -0.3426 (-0.3327)	Prec@(1,5) (64.7%, 91.1%)	
12/22 06:58:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.02192	Loss 1.5117 (1.2182)	Arch Loss 5.3944 (5.5534)	Arch Hard Loss 1.7069 (1.7949)	Arch Beta Loss 3.6875 (3.7586)	Arch depth Loss -0.3476 (-0.3354)	Prec@(1,5) (64.4%, 90.9%)	
12/22 06:58:01午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 35/149] Final Prec@1 64.3560%
12/22 06:58:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 1.7366	Prec@(1,5) (52.9%, 82.2%)
12/22 06:58:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 1.7478	Prec@(1,5) (52.5%, 82.5%)
12/22 06:58:25午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 1.7516	Prec@(1,5) (52.9%, 82.3%)
12/22 06:58:32午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 1.7615	Prec@(1,5) (52.6%, 82.2%)
12/22 06:58:32午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 35/149] Final Prec@1 52.6320%
12/22 06:58:32午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 06:58:32午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 06:59:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.02175	Loss 1.3597 (1.1411)	Arch Loss 5.6869 (5.4805)	Arch Hard Loss 2.0336 (1.8105)	Arch Beta Loss 3.6533 (3.6700)	Arch depth Loss -0.3526 (-0.3502)	Prec@(1,5) (66.4%, 92.3%)	
12/22 07:00:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.02175	Loss 1.2407 (1.1744)	Arch Loss 5.0920 (5.4410)	Arch Hard Loss 1.4713 (1.7877)	Arch Beta Loss 3.6207 (3.6533)	Arch depth Loss -0.3550 (-0.3521)	Prec@(1,5) (65.6%, 91.7%)	
12/22 07:01:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.02175	Loss 1.2724 (1.1947)	Arch Loss 5.4761 (5.4245)	Arch Hard Loss 1.8874 (1.7875)	Arch Beta Loss 3.5888 (3.6370)	Arch depth Loss -0.3570 (-0.3532)	Prec@(1,5) (65.2%, 91.3%)	
12/22 07:02:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.02175	Loss 1.1343 (1.2041)	Arch Loss 5.2662 (5.4136)	Arch Hard Loss 1.7061 (1.7911)	Arch Beta Loss 3.5600 (3.6225)	Arch depth Loss -0.3592 (-0.3542)	Prec@(1,5) (65.0%, 91.2%)	
12/22 07:02:03午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 36/149] Final Prec@1 64.9480%
12/22 07:02:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 1.7807	Prec@(1,5) (51.8%, 81.6%)
12/22 07:02:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 1.7650	Prec@(1,5) (52.3%, 81.9%)
12/22 07:02:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 1.7825	Prec@(1,5) (52.2%, 81.8%)
12/22 07:02:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 1.7881	Prec@(1,5) (51.9%, 81.7%)
12/22 07:02:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 36/149] Final Prec@1 51.9280%
12/22 07:02:34午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('avg_pool_3x3', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 07:02:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 07:03:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.02157	Loss 1.1032 (1.1376)	Arch Loss 5.3950 (5.3092)	Arch Hard Loss 1.8648 (1.7644)	Arch Beta Loss 3.5301 (3.5449)	Arch depth Loss -0.3610 (-0.3596)	Prec@(1,5) (67.1%, 91.7%)	
12/22 07:04:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.02157	Loss 1.2317 (1.1499)	Arch Loss 5.8529 (5.2835)	Arch Hard Loss 2.3518 (1.7534)	Arch Beta Loss 3.5010 (3.5301)	Arch depth Loss -0.3620 (-0.3603)	Prec@(1,5) (66.4%, 91.9%)	
12/22 07:05:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.02157	Loss 1.2151 (1.1738)	Arch Loss 5.1411 (5.2808)	Arch Hard Loss 1.6684 (1.7652)	Arch Beta Loss 3.4727 (3.5157)	Arch depth Loss -0.3603 (-0.3607)	Prec@(1,5) (65.8%, 91.5%)	
12/22 07:06:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.02157	Loss 1.1280 (1.1865)	Arch Loss 5.1800 (5.2691)	Arch Hard Loss 1.7317 (1.7662)	Arch Beta Loss 3.4483 (3.5029)	Arch depth Loss -0.3618 (-0.3608)	Prec@(1,5) (65.3%, 91.4%)	
12/22 07:06:02午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 37/149] Final Prec@1 65.3280%
12/22 07:06:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 1.8283	Prec@(1,5) (51.4%, 81.1%)
12/22 07:06:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 1.8091	Prec@(1,5) (51.9%, 81.8%)
12/22 07:06:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 1.8013	Prec@(1,5) (52.0%, 81.8%)
12/22 07:06:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 1.8018	Prec@(1,5) (51.9%, 81.7%)
12/22 07:06:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 37/149] Final Prec@1 51.8560%
12/22 07:06:33午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 07:06:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 07:07:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.0214	Loss 1.1185 (1.1343)	Arch Loss 5.0373 (5.2142)	Arch Hard Loss 1.6153 (1.7793)	Arch Beta Loss 3.4220 (3.4349)	Arch depth Loss -0.3625 (-0.3617)	Prec@(1,5) (67.3%, 91.8%)	
12/22 07:08:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.0214	Loss 1.0532 (1.1495)	Arch Loss 5.1946 (5.1846)	Arch Hard Loss 1.7978 (1.7624)	Arch Beta Loss 3.3968 (3.4222)	Arch depth Loss -0.3620 (-0.3622)	Prec@(1,5) (66.7%, 91.7%)	
12/22 07:09:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.0214	Loss 1.3475 (1.1621)	Arch Loss 5.2131 (5.1687)	Arch Hard Loss 1.8413 (1.7592)	Arch Beta Loss 3.3718 (3.4095)	Arch depth Loss -0.3604 (-0.3617)	Prec@(1,5) (66.2%, 91.7%)	
12/22 07:09:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.0214	Loss 1.0679 (1.1755)	Arch Loss 5.0503 (5.1737)	Arch Hard Loss 1.7006 (1.7754)	Arch Beta Loss 3.3497 (3.3982)	Arch depth Loss -0.3585 (-0.3612)	Prec@(1,5) (65.9%, 91.5%)	
12/22 07:10:00午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 38/149] Final Prec@1 65.8800%
12/22 07:10:08午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.7957	Prec@(1,5) (52.4%, 81.5%)
12/22 07:10:16午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.7877	Prec@(1,5) (52.4%, 81.4%)
12/22 07:10:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.7812	Prec@(1,5) (52.3%, 81.5%)
12/22 07:10:31午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.7746	Prec@(1,5) (52.4%, 81.8%)
12/22 07:10:31午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 38/149] Final Prec@1 52.3840%
12/22 07:10:31午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('avg_pool_3x3', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 07:10:31午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 07:11:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.02121	Loss 1.0950 (1.0903)	Arch Loss 5.0079 (5.1069)	Arch Hard Loss 1.6820 (1.7693)	Arch Beta Loss 3.3259 (3.3376)	Arch depth Loss -0.3574 (-0.3581)	Prec@(1,5) (68.0%, 92.8%)	
12/22 07:12:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.02121	Loss 0.9473 (1.1251)	Arch Loss 4.9706 (5.0893)	Arch Hard Loss 1.6676 (1.7635)	Arch Beta Loss 3.3029 (3.3258)	Arch depth Loss -0.3546 (-0.3566)	Prec@(1,5) (67.2%, 92.2%)	
12/22 07:13:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.02121	Loss 1.0272 (1.1464)	Arch Loss 5.1295 (5.0820)	Arch Hard Loss 1.8492 (1.7676)	Arch Beta Loss 3.2803 (3.3143)	Arch depth Loss -0.3509 (-0.3555)	Prec@(1,5) (66.5%, 91.9%)	
12/22 07:13:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.02121	Loss 1.1269 (1.1554)	Arch Loss 5.0690 (5.0673)	Arch Hard Loss 1.8081 (1.7631)	Arch Beta Loss 3.2609 (3.3042)	Arch depth Loss -0.3463 (-0.3538)	Prec@(1,5) (66.1%, 91.7%)	
12/22 07:13:58午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 39/149] Final Prec@1 66.1320%
12/22 07:14:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 1.8135	Prec@(1,5) (51.2%, 81.4%)
12/22 07:14:14午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 1.8002	Prec@(1,5) (52.2%, 81.6%)
12/22 07:14:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 1.7975	Prec@(1,5) (52.2%, 81.6%)
12/22 07:14:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 1.8029	Prec@(1,5) (52.2%, 81.5%)
12/22 07:14:29午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 39/149] Final Prec@1 52.2080%
12/22 07:14:29午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('avg_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 07:14:29午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 07:15:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.02103	Loss 1.0654 (1.0920)	Arch Loss 5.0791 (5.0532)	Arch Hard Loss 1.8397 (1.8033)	Arch Beta Loss 3.2394 (3.2499)	Arch depth Loss -0.3424 (-0.3443)	Prec@(1,5) (69.1%, 92.6%)	
12/22 07:16:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.02103	Loss 1.2694 (1.1156)	Arch Loss 5.1763 (5.0213)	Arch Hard Loss 1.9578 (1.7819)	Arch Beta Loss 3.2185 (3.2394)	Arch depth Loss -0.3390 (-0.3429)	Prec@(1,5) (67.9%, 92.4%)	
12/22 07:17:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.02103	Loss 1.0340 (1.1503)	Arch Loss 4.9168 (5.0129)	Arch Hard Loss 1.7192 (1.7840)	Arch Beta Loss 3.1976 (3.2289)	Arch depth Loss -0.3355 (-0.3412)	Prec@(1,5) (66.7%, 91.9%)	
12/22 07:17:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.02103	Loss 1.4414 (1.1567)	Arch Loss 4.5876 (4.9929)	Arch Hard Loss 1.4083 (1.7733)	Arch Beta Loss 3.1793 (3.2195)	Arch depth Loss -0.3334 (-0.3396)	Prec@(1,5) (66.3%, 91.8%)	
12/22 07:17:57午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 40/149] Final Prec@1 66.3000%
12/22 07:18:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.7545	Prec@(1,5) (53.2%, 82.4%)
12/22 07:18:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.7697	Prec@(1,5) (52.7%, 82.1%)
12/22 07:18:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.7628	Prec@(1,5) (52.6%, 82.3%)
12/22 07:18:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.7685	Prec@(1,5) (52.5%, 82.3%)
12/22 07:18:28午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 40/149] Final Prec@1 52.5280%
12/22 07:18:28午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 3])
12/22 07:18:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 07:19:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.02084	Loss 1.0302 (1.0787)	Arch Loss 4.7552 (4.9245)	Arch Hard Loss 1.5955 (1.7553)	Arch Beta Loss 3.1598 (3.1692)	Arch depth Loss -0.3253 (-0.3291)	Prec@(1,5) (68.2%, 93.0%)	
12/22 07:20:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.02084	Loss 0.8776 (1.1045)	Arch Loss 4.8233 (4.9195)	Arch Hard Loss 1.6834 (1.7601)	Arch Beta Loss 3.1399 (3.1594)	Arch depth Loss -0.3208 (-0.3259)	Prec@(1,5) (67.7%, 92.7%)	
12/22 07:21:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.02084	Loss 0.9713 (1.1176)	Arch Loss 4.6245 (4.9118)	Arch Hard Loss 1.5038 (1.7622)	Arch Beta Loss 3.1206 (3.1497)	Arch depth Loss -0.3137 (-0.3229)	Prec@(1,5) (67.3%, 92.3%)	
12/22 07:21:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.02084	Loss 1.4421 (1.1348)	Arch Loss 4.7387 (4.9024)	Arch Hard Loss 1.6352 (1.7614)	Arch Beta Loss 3.1035 (3.1410)	Arch depth Loss -0.3088 (-0.3202)	Prec@(1,5) (66.9%, 92.1%)	
12/22 07:21:57午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 41/149] Final Prec@1 66.8600%
12/22 07:22:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 1.8421	Prec@(1,5) (50.6%, 80.9%)
12/22 07:22:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.8446	Prec@(1,5) (50.6%, 80.7%)
12/22 07:22:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 1.8374	Prec@(1,5) (50.9%, 80.9%)
12/22 07:22:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 1.8352	Prec@(1,5) (50.9%, 81.1%)
12/22 07:22:28午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 41/149] Final Prec@1 50.9240%
12/22 07:22:28午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('avg_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:22:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 07:23:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.02065	Loss 1.3011 (1.0654)	Arch Loss 4.9292 (4.8724)	Arch Hard Loss 1.8444 (1.7783)	Arch Beta Loss 3.0848 (3.0941)	Arch depth Loss -0.3052 (-0.3064)	Prec@(1,5) (68.8%, 93.4%)	
12/22 07:24:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.02065	Loss 0.9865 (1.0854)	Arch Loss 4.7229 (4.8256)	Arch Hard Loss 1.6568 (1.7409)	Arch Beta Loss 3.0662 (3.0847)	Arch depth Loss -0.3002 (-0.3041)	Prec@(1,5) (68.2%, 92.8%)	
12/22 07:25:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.02065	Loss 1.2401 (1.1096)	Arch Loss 5.1886 (4.8217)	Arch Hard Loss 2.1416 (1.7464)	Arch Beta Loss 3.0470 (3.0754)	Arch depth Loss -0.2919 (-0.3014)	Prec@(1,5) (67.5%, 92.4%)	
12/22 07:25:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.02065	Loss 0.9769 (1.1219)	Arch Loss 4.8008 (4.8161)	Arch Hard Loss 1.7708 (1.7493)	Arch Beta Loss 3.0300 (3.0668)	Arch depth Loss -0.2876 (-0.2988)	Prec@(1,5) (67.1%, 92.2%)	
12/22 07:25:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 42/149] Final Prec@1 67.1240%
12/22 07:26:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 1.7608	Prec@(1,5) (53.4%, 82.5%)
12/22 07:26:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.7796	Prec@(1,5) (52.3%, 82.4%)
12/22 07:26:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.7714	Prec@(1,5) (52.7%, 82.4%)
12/22 07:26:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.7799	Prec@(1,5) (52.6%, 82.3%)
12/22 07:26:26午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 42/149] Final Prec@1 52.5680%
12/22 07:26:26午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('max_pool_3x3', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:26:26午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 52.6320%
12/22 07:27:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.02045	Loss 1.0836 (1.0358)	Arch Loss 4.7333 (4.7648)	Arch Hard Loss 1.7216 (1.7442)	Arch Beta Loss 3.0117 (3.0206)	Arch depth Loss -0.2818 (-0.2832)	Prec@(1,5) (69.5%, 93.4%)	
12/22 07:28:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.02045	Loss 0.9476 (1.0755)	Arch Loss 4.5954 (4.7672)	Arch Hard Loss 1.6020 (1.7558)	Arch Beta Loss 2.9934 (3.0114)	Arch depth Loss -0.2748 (-0.2804)	Prec@(1,5) (68.3%, 92.9%)	
12/22 07:29:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.02045	Loss 1.2016 (1.0927)	Arch Loss 4.9803 (4.7546)	Arch Hard Loss 2.0052 (1.7524)	Arch Beta Loss 2.9750 (3.0023)	Arch depth Loss -0.2680 (-0.2773)	Prec@(1,5) (67.8%, 92.6%)	
12/22 07:29:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.02045	Loss 0.8945 (1.1060)	Arch Loss 4.4834 (4.7446)	Arch Hard Loss 1.5247 (1.7506)	Arch Beta Loss 2.9586 (2.9941)	Arch depth Loss -0.2612 (-0.2744)	Prec@(1,5) (67.4%, 92.5%)	
12/22 07:29:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 43/149] Final Prec@1 67.4200%
12/22 07:30:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.7153	Prec@(1,5) (53.8%, 82.8%)
12/22 07:30:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.7256	Prec@(1,5) (53.5%, 82.4%)
12/22 07:30:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.7202	Prec@(1,5) (53.5%, 82.6%)
12/22 07:30:25午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.7346	Prec@(1,5) (53.4%, 82.5%)
12/22 07:30:25午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 43/149] Final Prec@1 53.4000%
12/22 07:30:25午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:30:26午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.4000%
12/22 07:31:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.02026	Loss 1.0507 (1.0565)	Arch Loss 4.6840 (4.6923)	Arch Hard Loss 1.7438 (1.7430)	Arch Beta Loss 2.9401 (2.9493)	Arch depth Loss -0.2509 (-0.2569)	Prec@(1,5) (69.2%, 93.1%)	
12/22 07:32:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.02026	Loss 1.5031 (1.0812)	Arch Loss 5.1457 (4.6978)	Arch Hard Loss 2.2241 (1.7578)	Arch Beta Loss 2.9217 (2.9400)	Arch depth Loss -0.2463 (-0.2526)	Prec@(1,5) (68.6%, 92.8%)	
12/22 07:33:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.02026	Loss 1.1049 (1.1050)	Arch Loss 4.6918 (4.6799)	Arch Hard Loss 1.7881 (1.7490)	Arch Beta Loss 2.9036 (2.9308)	Arch depth Loss -0.2396 (-0.2494)	Prec@(1,5) (67.8%, 92.6%)	
12/22 07:33:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.02026	Loss 0.8824 (1.1084)	Arch Loss 4.6527 (4.6674)	Arch Hard Loss 1.7651 (1.7447)	Arch Beta Loss 2.8876 (2.9227)	Arch depth Loss -0.2333 (-0.2463)	Prec@(1,5) (67.5%, 92.6%)	
12/22 07:33:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 44/149] Final Prec@1 67.5520%
12/22 07:34:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 1.6956	Prec@(1,5) (54.2%, 83.4%)
12/22 07:34:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 1.7202	Prec@(1,5) (53.8%, 83.0%)
12/22 07:34:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 1.7222	Prec@(1,5) (53.8%, 83.0%)
12/22 07:34:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 1.7310	Prec@(1,5) (53.6%, 83.0%)
12/22 07:34:26午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 44/149] Final Prec@1 53.6160%
12/22 07:34:26午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[2, 4])
12/22 07:34:26午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.6160%
12/22 07:35:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.02005	Loss 0.9530 (1.0338)	Arch Loss 4.2875 (4.6008)	Arch Hard Loss 1.4183 (1.7225)	Arch Beta Loss 2.8692 (2.8783)	Arch depth Loss -0.2246 (-0.2280)	Prec@(1,5) (69.5%, 94.0%)	
12/22 07:36:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.02005	Loss 1.0293 (1.0481)	Arch Loss 4.8088 (4.5998)	Arch Hard Loss 1.9576 (1.7306)	Arch Beta Loss 2.8512 (2.8692)	Arch depth Loss -0.2126 (-0.2234)	Prec@(1,5) (69.2%, 93.4%)	
12/22 07:37:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.02005	Loss 1.2716 (1.0702)	Arch Loss 4.7947 (4.6011)	Arch Hard Loss 1.9606 (1.7408)	Arch Beta Loss 2.8341 (2.8603)	Arch depth Loss -0.2065 (-0.2188)	Prec@(1,5) (68.5%, 92.9%)	
12/22 07:37:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.02005	Loss 0.9544 (1.0830)	Arch Loss 4.6916 (4.5956)	Arch Hard Loss 1.8734 (1.7432)	Arch Beta Loss 2.8182 (2.8524)	Arch depth Loss -0.2001 (-0.2152)	Prec@(1,5) (68.2%, 92.7%)	
12/22 07:37:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 45/149] Final Prec@1 68.2320%
12/22 07:38:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.7686	Prec@(1,5) (53.0%, 81.9%)
12/22 07:38:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.7849	Prec@(1,5) (52.6%, 82.0%)
12/22 07:38:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.7873	Prec@(1,5) (52.5%, 82.0%)
12/22 07:38:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.7866	Prec@(1,5) (52.7%, 82.0%)
12/22 07:38:26午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 45/149] Final Prec@1 52.6720%
12/22 07:38:26午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 07:38:26午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.6160%
12/22 07:39:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.01985	Loss 1.1120 (0.9956)	Arch Loss 4.5451 (4.5280)	Arch Hard Loss 1.7447 (1.7190)	Arch Beta Loss 2.8004 (2.8091)	Arch depth Loss -0.1936 (-0.1962)	Prec@(1,5) (71.0%, 93.6%)	
12/22 07:40:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.01985	Loss 0.9854 (1.0406)	Arch Loss 4.2225 (4.5263)	Arch Hard Loss 1.4390 (1.7258)	Arch Beta Loss 2.7834 (2.8005)	Arch depth Loss -0.1853 (-0.1932)	Prec@(1,5) (69.5%, 93.1%)	
12/22 07:41:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.01985	Loss 0.9607 (1.0578)	Arch Loss 4.2849 (4.5218)	Arch Hard Loss 1.5195 (1.7301)	Arch Beta Loss 2.7654 (2.7917)	Arch depth Loss -0.1767 (-0.1893)	Prec@(1,5) (68.7%, 93.0%)	
12/22 07:41:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.01985	Loss 0.9510 (1.0765)	Arch Loss 4.9369 (4.5149)	Arch Hard Loss 2.1865 (1.7310)	Arch Beta Loss 2.7504 (2.7839)	Arch depth Loss -0.1725 (-0.1859)	Prec@(1,5) (68.3%, 92.8%)	
12/22 07:41:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 46/149] Final Prec@1 68.3400%
12/22 07:42:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 1.7583	Prec@(1,5) (54.1%, 82.2%)
12/22 07:42:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 1.7615	Prec@(1,5) (53.6%, 82.0%)
12/22 07:42:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 1.7573	Prec@(1,5) (53.4%, 82.1%)
12/22 07:42:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 1.7566	Prec@(1,5) (53.3%, 82.2%)
12/22 07:42:26午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 46/149] Final Prec@1 53.3240%
12/22 07:42:26午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 07:42:26午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.6160%
12/22 07:43:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.01964	Loss 0.8839 (1.0228)	Arch Loss 4.2188 (4.4482)	Arch Hard Loss 1.4854 (1.7067)	Arch Beta Loss 2.7334 (2.7415)	Arch depth Loss -0.1642 (-0.1696)	Prec@(1,5) (70.2%, 93.4%)	
12/22 07:44:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.01964	Loss 0.9713 (1.0332)	Arch Loss 4.2039 (4.4706)	Arch Hard Loss 1.4866 (1.7371)	Arch Beta Loss 2.7174 (2.7335)	Arch depth Loss -0.1579 (-0.1650)	Prec@(1,5) (69.5%, 93.4%)	
12/22 07:45:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.01964	Loss 0.9717 (1.0527)	Arch Loss 4.3770 (4.4490)	Arch Hard Loss 1.6759 (1.7237)	Arch Beta Loss 2.7011 (2.7253)	Arch depth Loss -0.1531 (-0.1618)	Prec@(1,5) (68.9%, 92.9%)	
12/22 07:45:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.01964	Loss 1.3143 (1.0639)	Arch Loss 4.5419 (4.4417)	Arch Hard Loss 1.8548 (1.7236)	Arch Beta Loss 2.6871 (2.7181)	Arch depth Loss -0.1453 (-0.1587)	Prec@(1,5) (68.6%, 92.9%)	
12/22 07:45:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 47/149] Final Prec@1 68.6480%
12/22 07:46:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 1.7875	Prec@(1,5) (51.7%, 82.6%)
12/22 07:46:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 1.7823	Prec@(1,5) (52.4%, 82.5%)
12/22 07:46:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 1.7779	Prec@(1,5) (52.5%, 82.6%)
12/22 07:46:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 1.7833	Prec@(1,5) (52.5%, 82.5%)
12/22 07:46:26午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 47/149] Final Prec@1 52.4520%
12/22 07:46:26午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 07:46:26午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.6160%
12/22 07:47:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.01943	Loss 0.9887 (1.0038)	Arch Loss 4.5590 (4.3859)	Arch Hard Loss 1.8874 (1.7068)	Arch Beta Loss 2.6716 (2.6791)	Arch depth Loss -0.1351 (-0.1397)	Prec@(1,5) (70.4%, 94.0%)	
12/22 07:48:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.01943	Loss 1.1763 (1.0244)	Arch Loss 4.5307 (4.4055)	Arch Hard Loss 1.8746 (1.7341)	Arch Beta Loss 2.6561 (2.6714)	Arch depth Loss -0.1317 (-0.1367)	Prec@(1,5) (69.8%, 93.8%)	
12/22 07:49:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.01943	Loss 1.1548 (1.0514)	Arch Loss 4.3653 (4.4036)	Arch Hard Loss 1.7244 (1.7399)	Arch Beta Loss 2.6410 (2.6637)	Arch depth Loss -0.1259 (-0.1336)	Prec@(1,5) (69.2%, 93.2%)	
12/22 07:49:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.01943	Loss 0.9520 (1.0665)	Arch Loss 4.3601 (4.3985)	Arch Hard Loss 1.7319 (1.7416)	Arch Beta Loss 2.6282 (2.6570)	Arch depth Loss -0.1189 (-0.1308)	Prec@(1,5) (68.8%, 93.0%)	
12/22 07:49:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 48/149] Final Prec@1 68.7960%
12/22 07:50:03午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.7462	Prec@(1,5) (53.0%, 82.6%)
12/22 07:50:11午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.7371	Prec@(1,5) (53.5%, 82.6%)
12/22 07:50:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.7358	Prec@(1,5) (53.5%, 82.6%)
12/22 07:50:26午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.7396	Prec@(1,5) (53.5%, 82.6%)
12/22 07:50:26午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 48/149] Final Prec@1 53.5160%
12/22 07:50:26午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 07:50:26午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.6160%
12/22 07:51:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.01922	Loss 0.8462 (1.0069)	Arch Loss 4.2920 (4.3703)	Arch Hard Loss 1.6784 (1.7493)	Arch Beta Loss 2.6136 (2.6210)	Arch depth Loss -0.1107 (-0.1148)	Prec@(1,5) (70.6%, 93.7%)	
12/22 07:52:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.01922	Loss 0.9124 (1.0179)	Arch Loss 4.5911 (4.3482)	Arch Hard Loss 1.9913 (1.7344)	Arch Beta Loss 2.5999 (2.6137)	Arch depth Loss -0.1046 (-0.1112)	Prec@(1,5) (69.7%, 93.5%)	
12/22 07:53:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.01922	Loss 1.0089 (1.0412)	Arch Loss 4.7690 (4.3400)	Arch Hard Loss 2.1818 (1.7330)	Arch Beta Loss 2.5872 (2.6070)	Arch depth Loss -0.0998 (-0.1081)	Prec@(1,5) (69.0%, 93.1%)	
12/22 07:53:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.01922	Loss 1.2881 (1.0555)	Arch Loss 3.8340 (4.3352)	Arch Hard Loss 1.2582 (1.7341)	Arch Beta Loss 2.5757 (2.6011)	Arch depth Loss -0.0948 (-0.1057)	Prec@(1,5) (68.8%, 92.9%)	
12/22 07:53:53午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 49/149] Final Prec@1 68.7680%
12/22 07:54:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 1.6979	Prec@(1,5) (54.5%, 83.1%)
12/22 07:54:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 1.7192	Prec@(1,5) (53.7%, 83.1%)
12/22 07:54:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 1.7285	Prec@(1,5) (53.4%, 82.8%)
12/22 07:54:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.7162	Prec@(1,5) (53.7%, 83.1%)
12/22 07:54:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 49/149] Final Prec@1 53.7040%
12/22 07:54:24午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 07:54:25午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.7040%
12/22 07:55:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][100/390]	Step 19650	lr 0.019	Loss 0.8389 (0.9895)	Arch Loss 4.4695 (4.3196)	Arch Hard Loss 1.9065 (1.7506)	Arch Beta Loss 2.5630 (2.5690)	Arch depth Loss -0.0880 (-0.0916)	Prec@(1,5) (71.4%, 94.2%)	
12/22 07:56:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][200/390]	Step 19750	lr 0.019	Loss 1.0198 (1.0134)	Arch Loss 4.3722 (4.3035)	Arch Hard Loss 1.8209 (1.7403)	Arch Beta Loss 2.5513 (2.5631)	Arch depth Loss -0.0820 (-0.0880)	Prec@(1,5) (70.3%, 93.7%)	
12/22 07:57:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][300/390]	Step 19850	lr 0.019	Loss 1.1211 (1.0263)	Arch Loss 4.1303 (4.2819)	Arch Hard Loss 1.5906 (1.7247)	Arch Beta Loss 2.5397 (2.5573)	Arch depth Loss -0.0749 (-0.0848)	Prec@(1,5) (69.9%, 93.5%)	
12/22 07:57:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [50][390/390]	Step 19940	lr 0.019	Loss 1.0265 (1.0393)	Arch Loss 3.8253 (4.2763)	Arch Hard Loss 1.2970 (1.7245)	Arch Beta Loss 2.5282 (2.5518)	Arch depth Loss -0.0695 (-0.0817)	Prec@(1,5) (69.4%, 93.4%)	
12/22 07:57:54午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 50/149] Final Prec@1 69.4440%
12/22 07:58:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][100/391]	Step 19941	Loss 1.7207	Prec@(1,5) (53.5%, 82.8%)
12/22 07:58:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][200/391]	Step 19941	Loss 1.7179	Prec@(1,5) (54.2%, 82.8%)
12/22 07:58:18午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][300/391]	Step 19941	Loss 1.7307	Prec@(1,5) (53.9%, 82.7%)
12/22 07:58:25午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [50][390/391]	Step 19941	Loss 1.7310	Prec@(1,5) (53.9%, 82.8%)
12/22 07:58:25午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 50/149] Final Prec@1 53.9000%
12/22 07:58:25午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('skip_connect', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 07:58:25午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9000%
12/22 07:59:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][100/390]	Step 20041	lr 0.01878	Loss 0.9995 (0.9486)	Arch Loss 4.0201 (4.1950)	Arch Hard Loss 1.5030 (1.6724)	Arch Beta Loss 2.5171 (2.5226)	Arch depth Loss -0.0626 (-0.0643)	Prec@(1,5) (71.9%, 94.8%)	
12/22 08:00:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][200/390]	Step 20141	lr 0.01878	Loss 1.0214 (0.9813)	Arch Loss 4.6117 (4.2289)	Arch Hard Loss 2.1057 (1.7120)	Arch Beta Loss 2.5059 (2.5169)	Arch depth Loss -0.0566 (-0.0624)	Prec@(1,5) (70.7%, 94.4%)	
12/22 08:01:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][300/390]	Step 20241	lr 0.01878	Loss 0.9954 (1.0019)	Arch Loss 4.3240 (4.2237)	Arch Hard Loss 1.8281 (1.7122)	Arch Beta Loss 2.4959 (2.5116)	Arch depth Loss -0.0483 (-0.0591)	Prec@(1,5) (70.2%, 94.0%)	
12/22 08:01:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [51][390/390]	Step 20331	lr 0.01878	Loss 1.0851 (1.0224)	Arch Loss 3.8254 (4.2172)	Arch Hard Loss 1.3384 (1.7103)	Arch Beta Loss 2.4871 (2.5069)	Arch depth Loss -0.0440 (-0.0562)	Prec@(1,5) (69.9%, 93.6%)	
12/22 08:01:52午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 51/149] Final Prec@1 69.8400%
12/22 08:02:00午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][100/391]	Step 20332	Loss 1.7385	Prec@(1,5) (52.7%, 82.9%)
12/22 08:02:08午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][200/391]	Step 20332	Loss 1.7451	Prec@(1,5) (52.9%, 82.7%)
12/22 08:02:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][300/391]	Step 20332	Loss 1.7408	Prec@(1,5) (53.4%, 82.7%)
12/22 08:02:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [51][390/391]	Step 20332	Loss 1.7504	Prec@(1,5) (53.2%, 82.5%)
12/22 08:02:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 51/149] Final Prec@1 53.2040%
12/22 08:02:22午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:02:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9000%
12/22 08:03:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][100/390]	Step 20432	lr 0.01856	Loss 1.0295 (0.9599)	Arch Loss 3.8860 (4.1920)	Arch Hard Loss 1.4084 (1.7097)	Arch Beta Loss 2.4777 (2.4823)	Arch depth Loss -0.0406 (-0.0417)	Prec@(1,5) (72.0%, 94.5%)	
12/22 08:04:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][200/390]	Step 20532	lr 0.01856	Loss 1.2209 (0.9767)	Arch Loss 4.3216 (4.1676)	Arch Hard Loss 1.8537 (1.6901)	Arch Beta Loss 2.4679 (2.4775)	Arch depth Loss -0.0369 (-0.0405)	Prec@(1,5) (71.1%, 94.1%)	
12/22 08:05:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][300/390]	Step 20632	lr 0.01856	Loss 1.0028 (1.0021)	Arch Loss 4.2797 (4.1809)	Arch Hard Loss 1.8219 (1.7083)	Arch Beta Loss 2.4578 (2.4726)	Arch depth Loss -0.0292 (-0.0381)	Prec@(1,5) (70.4%, 93.8%)	
12/22 08:05:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [52][390/390]	Step 20722	lr 0.01856	Loss 1.0555 (1.0190)	Arch Loss 3.9756 (4.1828)	Arch Hard Loss 1.5257 (1.7146)	Arch Beta Loss 2.4499 (2.4682)	Arch depth Loss -0.0238 (-0.0355)	Prec@(1,5) (70.0%, 93.5%)	
12/22 08:05:51午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 52/149] Final Prec@1 69.9880%
12/22 08:06:00午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][100/391]	Step 20723	Loss 1.7309	Prec@(1,5) (54.2%, 83.7%)
12/22 08:06:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][200/391]	Step 20723	Loss 1.7358	Prec@(1,5) (53.8%, 83.6%)
12/22 08:06:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][300/391]	Step 20723	Loss 1.7333	Prec@(1,5) (53.8%, 83.4%)
12/22 08:06:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [52][390/391]	Step 20723	Loss 1.7454	Prec@(1,5) (53.5%, 83.1%)
12/22 08:06:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 52/149] Final Prec@1 53.4720%
12/22 08:06:22午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:06:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 53.9000%
12/22 08:07:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][100/390]	Step 20823	lr 0.01834	Loss 0.8832 (1.0202)	Arch Loss 3.6256 (4.1381)	Arch Hard Loss 1.1839 (1.6923)	Arch Beta Loss 2.4417 (2.4458)	Arch depth Loss -0.0189 (-0.0227)	Prec@(1,5) (69.6%, 93.7%)	
12/22 08:08:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][200/390]	Step 20923	lr 0.01834	Loss 0.8525 (0.9982)	Arch Loss 4.2813 (4.1479)	Arch Hard Loss 1.8486 (1.7064)	Arch Beta Loss 2.4327 (2.4415)	Arch depth Loss -0.0171 (-0.0203)	Prec@(1,5) (70.5%, 94.0%)	
12/22 08:09:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][300/390]	Step 21023	lr 0.01834	Loss 0.9995 (1.0139)	Arch Loss 4.3073 (4.1611)	Arch Hard Loss 1.8827 (1.7240)	Arch Beta Loss 2.4246 (2.4372)	Arch depth Loss -0.0127 (-0.0181)	Prec@(1,5) (70.1%, 93.7%)	
12/22 08:09:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [53][390/390]	Step 21113	lr 0.01834	Loss 1.0887 (1.0188)	Arch Loss 4.2684 (4.1531)	Arch Hard Loss 1.8508 (1.7197)	Arch Beta Loss 2.4176 (2.4334)	Arch depth Loss -0.0056 (-0.0162)	Prec@(1,5) (69.9%, 93.6%)	
12/22 08:09:51午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 53/149] Final Prec@1 69.8880%
12/22 08:09:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][100/391]	Step 21114	Loss 1.7334	Prec@(1,5) (53.4%, 83.0%)
12/22 08:10:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][200/391]	Step 21114	Loss 1.7153	Prec@(1,5) (53.7%, 83.3%)
12/22 08:10:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][300/391]	Step 21114	Loss 1.7226	Prec@(1,5) (53.9%, 83.4%)
12/22 08:10:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [53][390/391]	Step 21114	Loss 1.7126	Prec@(1,5) (54.0%, 83.5%)
12/22 08:10:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 53/149] Final Prec@1 54.0400%
12/22 08:10:22午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('avg_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:10:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0400%
12/22 08:11:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][100/390]	Step 21214	lr 0.01811	Loss 0.6218 (0.9422)	Arch Loss 4.3942 (4.1361)	Arch Hard Loss 1.9836 (1.7222)	Arch Beta Loss 2.4106 (2.4139)	Arch depth Loss 0.0003 (-0.0027)	Prec@(1,5) (72.1%, 94.5%)	
12/22 08:12:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][200/390]	Step 21314	lr 0.01811	Loss 1.0911 (0.9690)	Arch Loss 4.2636 (4.1104)	Arch Hard Loss 1.8601 (1.7000)	Arch Beta Loss 2.4034 (2.4104)	Arch depth Loss 0.0051 (-0.0004)	Prec@(1,5) (71.4%, 94.3%)	
12/22 08:13:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][300/390]	Step 21414	lr 0.01811	Loss 0.9431 (0.9896)	Arch Loss 4.3775 (4.1112)	Arch Hard Loss 1.9817 (1.7044)	Arch Beta Loss 2.3958 (2.4068)	Arch depth Loss 0.0079 (0.0020)	Prec@(1,5) (70.7%, 94.0%)	
12/22 08:13:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [54][390/390]	Step 21504	lr 0.01811	Loss 1.0033 (1.0007)	Arch Loss 4.0088 (4.1160)	Arch Hard Loss 1.6188 (1.7124)	Arch Beta Loss 2.3900 (2.4036)	Arch depth Loss 0.0101 (0.0037)	Prec@(1,5) (70.4%, 93.8%)	
12/22 08:13:50午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 54/149] Final Prec@1 70.4080%
12/22 08:13:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][100/391]	Step 21505	Loss 1.7466	Prec@(1,5) (53.5%, 83.0%)
12/22 08:14:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][200/391]	Step 21505	Loss 1.7517	Prec@(1,5) (53.3%, 82.8%)
12/22 08:14:14午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][300/391]	Step 21505	Loss 1.7402	Prec@(1,5) (53.6%, 82.9%)
12/22 08:14:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [54][390/391]	Step 21505	Loss 1.7346	Prec@(1,5) (53.6%, 82.9%)
12/22 08:14:21午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 54/149] Final Prec@1 53.6360%
12/22 08:14:21午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('avg_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:14:21午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0400%
12/22 08:15:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][100/390]	Step 21605	lr 0.01788	Loss 0.9627 (0.9279)	Arch Loss 4.1261 (4.0885)	Arch Hard Loss 1.7435 (1.7023)	Arch Beta Loss 2.3827 (2.3862)	Arch depth Loss 0.0149 (0.0135)	Prec@(1,5) (72.5%, 94.9%)	
12/22 08:16:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][200/390]	Step 21705	lr 0.01788	Loss 0.9710 (0.9578)	Arch Loss 4.5902 (4.0601)	Arch Hard Loss 2.2133 (1.6771)	Arch Beta Loss 2.3768 (2.3830)	Arch depth Loss 0.0168 (0.0146)	Prec@(1,5) (71.5%, 94.4%)	
12/22 08:17:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][300/390]	Step 21805	lr 0.01788	Loss 1.2656 (0.9801)	Arch Loss 4.0044 (4.0872)	Arch Hard Loss 1.6336 (1.7073)	Arch Beta Loss 2.3708 (2.3799)	Arch depth Loss 0.0212 (0.0161)	Prec@(1,5) (70.7%, 94.0%)	
12/22 08:17:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [55][390/390]	Step 21895	lr 0.01788	Loss 1.1400 (1.0001)	Arch Loss 4.2153 (4.0847)	Arch Hard Loss 1.8503 (1.7076)	Arch Beta Loss 2.3651 (2.3771)	Arch depth Loss 0.0255 (0.0176)	Prec@(1,5) (70.1%, 93.8%)	
12/22 08:17:51午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 55/149] Final Prec@1 70.0760%
12/22 08:17:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][100/391]	Step 21896	Loss 1.7025	Prec@(1,5) (55.0%, 83.3%)
12/22 08:18:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][200/391]	Step 21896	Loss 1.7210	Prec@(1,5) (54.7%, 83.1%)
12/22 08:18:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][300/391]	Step 21896	Loss 1.7358	Prec@(1,5) (54.1%, 82.8%)
12/22 08:18:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [55][390/391]	Step 21896	Loss 1.7350	Prec@(1,5) (53.9%, 83.0%)
12/22 08:18:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 55/149] Final Prec@1 53.8800%
12/22 08:18:22午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:18:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.0400%
12/22 08:19:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][100/390]	Step 21996	lr 0.01765	Loss 1.0662 (0.9403)	Arch Loss 4.0801 (4.0698)	Arch Hard Loss 1.7204 (1.7074)	Arch Beta Loss 2.3597 (2.3624)	Arch depth Loss 0.0279 (0.0268)	Prec@(1,5) (71.8%, 94.9%)	
12/22 08:20:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][200/390]	Step 22096	lr 0.01765	Loss 0.8946 (0.9484)	Arch Loss 4.3600 (4.0484)	Arch Hard Loss 2.0060 (1.6888)	Arch Beta Loss 2.3541 (2.3596)	Arch depth Loss 0.0293 (0.0271)	Prec@(1,5) (71.8%, 94.7%)	
12/22 08:21:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][300/390]	Step 22196	lr 0.01765	Loss 1.0938 (0.9812)	Arch Loss 3.8865 (4.0621)	Arch Hard Loss 1.5381 (1.7052)	Arch Beta Loss 2.3484 (2.3569)	Arch depth Loss 0.0305 (0.0281)	Prec@(1,5) (70.8%, 94.2%)	
12/22 08:21:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [56][390/390]	Step 22286	lr 0.01765	Loss 1.1072 (0.9922)	Arch Loss 3.9224 (4.0544)	Arch Hard Loss 1.5784 (1.7000)	Arch Beta Loss 2.3440 (2.3544)	Arch depth Loss 0.0297 (0.0285)	Prec@(1,5) (70.3%, 94.0%)	
12/22 08:21:50午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 56/149] Final Prec@1 70.3080%
12/22 08:21:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][100/391]	Step 22287	Loss 1.6917	Prec@(1,5) (54.5%, 83.8%)
12/22 08:22:06午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][200/391]	Step 22287	Loss 1.6935	Prec@(1,5) (54.6%, 83.8%)
12/22 08:22:14午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][300/391]	Step 22287	Loss 1.6877	Prec@(1,5) (54.7%, 83.8%)
12/22 08:22:21午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [56][390/391]	Step 22287	Loss 1.6870	Prec@(1,5) (54.8%, 83.9%)
12/22 08:22:21午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 56/149] Final Prec@1 54.7840%
12/22 08:22:21午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:22:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:23:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][100/390]	Step 22387	lr 0.01742	Loss 0.7880 (0.9468)	Arch Loss 4.1263 (4.0648)	Arch Hard Loss 1.7872 (1.7234)	Arch Beta Loss 2.3390 (2.3414)	Arch depth Loss 0.0327 (0.0310)	Prec@(1,5) (71.7%, 94.6%)	
12/22 08:24:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][200/390]	Step 22487	lr 0.01742	Loss 0.7873 (0.9502)	Arch Loss 4.2894 (4.0413)	Arch Hard Loss 1.9553 (1.7024)	Arch Beta Loss 2.3341 (2.3389)	Arch depth Loss 0.0358 (0.0329)	Prec@(1,5) (71.6%, 94.5%)	
12/22 08:25:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][300/390]	Step 22587	lr 0.01742	Loss 1.0075 (0.9665)	Arch Loss 4.1128 (4.0456)	Arch Hard Loss 1.7829 (1.7090)	Arch Beta Loss 2.3299 (2.3366)	Arch depth Loss 0.0397 (0.0345)	Prec@(1,5) (71.2%, 94.1%)	
12/22 08:25:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [57][390/390]	Step 22677	lr 0.01742	Loss 1.0717 (0.9811)	Arch Loss 4.0786 (4.0391)	Arch Hard Loss 1.7533 (1.7046)	Arch Beta Loss 2.3253 (2.3345)	Arch depth Loss 0.0395 (0.0356)	Prec@(1,5) (70.6%, 94.0%)	
12/22 08:25:48午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 57/149] Final Prec@1 70.6320%
12/22 08:25:56午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][100/391]	Step 22678	Loss 1.7571	Prec@(1,5) (53.8%, 83.1%)
12/22 08:26:04午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][200/391]	Step 22678	Loss 1.7621	Prec@(1,5) (53.5%, 82.8%)
12/22 08:26:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][300/391]	Step 22678	Loss 1.7615	Prec@(1,5) (53.4%, 82.8%)
12/22 08:26:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [57][390/391]	Step 22678	Loss 1.7438	Prec@(1,5) (53.7%, 83.1%)
12/22 08:26:19午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 57/149] Final Prec@1 53.6840%
12/22 08:26:19午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('max_pool_3x3', 8)], [('max_pool_3x3', 8), ('skip_connect', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:26:19午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:27:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][100/390]	Step 22778	lr 0.01718	Loss 1.1700 (0.9477)	Arch Loss 3.7709 (4.0401)	Arch Hard Loss 1.4497 (1.7168)	Arch Beta Loss 2.3212 (2.3233)	Arch depth Loss 0.0420 (0.0404)	Prec@(1,5) (71.5%, 95.0%)	
12/22 08:28:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][200/390]	Step 22878	lr 0.01718	Loss 0.6407 (0.9433)	Arch Loss 3.8432 (4.0437)	Arch Hard Loss 1.5266 (1.7226)	Arch Beta Loss 2.3166 (2.3211)	Arch depth Loss 0.0436 (0.0413)	Prec@(1,5) (71.6%, 94.7%)	
12/22 08:29:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][300/390]	Step 22978	lr 0.01718	Loss 1.2732 (0.9586)	Arch Loss 4.2280 (4.0326)	Arch Hard Loss 1.9151 (1.7136)	Arch Beta Loss 2.3129 (2.3190)	Arch depth Loss 0.0426 (0.0420)	Prec@(1,5) (71.4%, 94.5%)	
12/22 08:29:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [58][390/390]	Step 23068	lr 0.01718	Loss 0.9356 (0.9648)	Arch Loss 4.1844 (4.0241)	Arch Hard Loss 1.8755 (1.7070)	Arch Beta Loss 2.3089 (2.3171)	Arch depth Loss 0.0458 (0.0425)	Prec@(1,5) (71.4%, 94.3%)	
12/22 08:29:49午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 58/149] Final Prec@1 71.3840%
12/22 08:29:57午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][100/391]	Step 23069	Loss 1.7333	Prec@(1,5) (53.9%, 83.3%)
12/22 08:30:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][200/391]	Step 23069	Loss 1.7516	Prec@(1,5) (53.9%, 83.0%)
12/22 08:30:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][300/391]	Step 23069	Loss 1.7497	Prec@(1,5) (54.0%, 82.9%)
12/22 08:30:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [58][390/391]	Step 23069	Loss 1.7500	Prec@(1,5) (54.0%, 83.0%)
12/22 08:30:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 58/149] Final Prec@1 54.0160%
12/22 08:30:20午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('max_pool_3x3', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:30:21午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:31:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][100/390]	Step 23169	lr 0.01695	Loss 1.0427 (0.9015)	Arch Loss 3.8965 (4.0166)	Arch Hard Loss 1.5915 (1.7095)	Arch Beta Loss 2.3050 (2.3071)	Arch depth Loss 0.0477 (0.0469)	Prec@(1,5) (72.9%, 95.0%)	
12/22 08:32:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][200/390]	Step 23269	lr 0.01695	Loss 0.9756 (0.9133)	Arch Loss 3.9580 (4.0246)	Arch Hard Loss 1.6569 (1.7196)	Arch Beta Loss 2.3011 (2.3050)	Arch depth Loss 0.0507 (0.0482)	Prec@(1,5) (72.4%, 94.7%)	
12/22 08:33:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][300/390]	Step 23369	lr 0.01695	Loss 1.2265 (0.9554)	Arch Loss 3.4830 (4.0031)	Arch Hard Loss 1.1855 (1.7000)	Arch Beta Loss 2.2975 (2.3031)	Arch depth Loss 0.0492 (0.0485)	Prec@(1,5) (71.3%, 94.3%)	
12/22 08:33:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [59][390/390]	Step 23459	lr 0.01695	Loss 0.9657 (0.9654)	Arch Loss 4.1227 (4.0101)	Arch Hard Loss 1.8286 (1.7087)	Arch Beta Loss 2.2940 (2.3014)	Arch depth Loss 0.0490 (0.0487)	Prec@(1,5) (71.2%, 94.2%)	
12/22 08:33:49午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 59/149] Final Prec@1 71.1840%
12/22 08:33:58午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][100/391]	Step 23460	Loss 1.7654	Prec@(1,5) (53.0%, 82.5%)
12/22 08:34:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][200/391]	Step 23460	Loss 1.7813	Prec@(1,5) (53.0%, 82.2%)
12/22 08:34:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][300/391]	Step 23460	Loss 1.7768	Prec@(1,5) (53.0%, 82.3%)
12/22 08:34:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [59][390/391]	Step 23460	Loss 1.7735	Prec@(1,5) (53.0%, 82.4%)
12/22 08:34:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 59/149] Final Prec@1 53.0080%
12/22 08:34:20午後 searchevaluateStage_main.py:66 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/22 08:34:21午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:34:22午後 searchEvalStage_curriculum_trainer.py:105 [INFO] --> Archtecture parameters are DISCRETED
12/22 08:34:22午後 searchEvalStage_curriculum_trainer.py:89 [INFO] --> Loaded alpha parameters are Freezed
####### ALPHA #######
# Alpha - DAG
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 0., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[1., 0., 0., 0.],
        [0., 1., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
Parameter containing:
tensor([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 0., 0.]], device='cuda:0')
# Beta
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')
#####################
12/22 08:34:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][100/703]	Step 23560	lr 0.025	Loss 2.4635 (2.3756)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (37.5%, 70.6%)	
12/22 08:35:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][200/703]	Step 23660	lr 0.025	Loss 2.3605 (2.2443)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (40.5%, 73.3%)	
12/22 08:35:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][300/703]	Step 23760	lr 0.025	Loss 2.0332 (2.1713)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (42.2%, 74.5%)	
12/22 08:35:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][400/703]	Step 23860	lr 0.025	Loss 1.8176 (2.1237)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.1%, 75.4%)	
12/22 08:36:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][500/703]	Step 23960	lr 0.025	Loss 1.8949 (2.0968)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (43.7%, 75.9%)	
12/22 08:36:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][600/703]	Step 24060	lr 0.025	Loss 1.7784 (2.0703)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (44.3%, 76.4%)	
12/22 08:36:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][700/703]	Step 24160	lr 0.025	Loss 2.1501 (2.0417)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.0%)	
12/22 08:36:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [60][703/703]	Step 24163	lr 0.025	Loss 2.1074 (2.0414)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (45.0%, 77.0%)	
12/22 08:36:49午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 60/149] Final Prec@1 44.9778%
12/22 08:36:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [60][78/79]	Step 24164	Loss 2.1251	Prec@(1,5) (44.2%, 76.1%)
12/22 08:36:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 60/149] Final Prec@1 44.1400%
12/22 08:36:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:37:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][100/703]	Step 24264	lr 0.02499	Loss 2.0058 (1.7914)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (49.8%, 82.2%)	
12/22 08:37:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][200/703]	Step 24364	lr 0.02499	Loss 1.3419 (1.7970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.3%, 81.6%)	
12/22 08:37:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][300/703]	Step 24464	lr 0.02499	Loss 1.9847 (1.8047)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.2%, 81.4%)	
12/22 08:38:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][400/703]	Step 24564	lr 0.02499	Loss 2.1027 (1.7990)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.4%, 81.5%)	
12/22 08:38:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][500/703]	Step 24664	lr 0.02499	Loss 1.4735 (1.7926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.6%, 81.6%)	
12/22 08:39:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][600/703]	Step 24764	lr 0.02499	Loss 1.5535 (1.7902)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.6%)	
12/22 08:39:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][700/703]	Step 24864	lr 0.02499	Loss 2.0144 (1.7876)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.7%)	
12/22 08:39:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [61][703/703]	Step 24867	lr 0.02499	Loss 1.5602 (1.7874)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (50.7%, 81.7%)	
12/22 08:39:21午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 61/149] Final Prec@1 50.7244%
12/22 08:39:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [61][78/79]	Step 24868	Loss 2.0983	Prec@(1,5) (44.6%, 76.7%)
12/22 08:39:28午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 61/149] Final Prec@1 44.6200%
12/22 08:39:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:39:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][100/703]	Step 24968	lr 0.02497	Loss 1.5966 (1.6937)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.4%)	
12/22 08:40:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][200/703]	Step 25068	lr 0.02497	Loss 1.6675 (1.6790)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.1%, 83.6%)	
12/22 08:40:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][300/703]	Step 25168	lr 0.02497	Loss 1.8352 (1.6910)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.7%, 83.4%)	
12/22 08:40:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][400/703]	Step 25268	lr 0.02497	Loss 2.3235 (1.6871)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (53.0%, 83.4%)	
12/22 08:41:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][500/703]	Step 25368	lr 0.02497	Loss 1.9773 (1.6980)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.8%, 83.2%)	
12/22 08:41:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][600/703]	Step 25468	lr 0.02497	Loss 1.7692 (1.6946)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.2%)	
12/22 08:41:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][700/703]	Step 25568	lr 0.02497	Loss 1.6648 (1.6921)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.3%)	
12/22 08:41:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [62][703/703]	Step 25571	lr 0.02497	Loss 1.6405 (1.6922)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (52.9%, 83.3%)	
12/22 08:41:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 62/149] Final Prec@1 52.9022%
12/22 08:42:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [62][78/79]	Step 25572	Loss 2.0294	Prec@(1,5) (45.8%, 78.3%)
12/22 08:42:01午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 62/149] Final Prec@1 45.7200%
12/22 08:42:01午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:42:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][100/703]	Step 25672	lr 0.02493	Loss 1.4903 (1.5940)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 85.2%)	
12/22 08:42:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][200/703]	Step 25772	lr 0.02493	Loss 1.5588 (1.5855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 85.1%)	
12/22 08:43:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][300/703]	Step 25872	lr 0.02493	Loss 1.4855 (1.5889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 85.1%)	
12/22 08:43:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][400/703]	Step 25972	lr 0.02493	Loss 1.5770 (1.5969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.7%, 84.8%)	
12/22 08:43:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][500/703]	Step 26072	lr 0.02493	Loss 1.5497 (1.6003)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.6%, 84.8%)	
12/22 08:44:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][600/703]	Step 26172	lr 0.02493	Loss 1.9487 (1.6077)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.4%, 84.6%)	
12/22 08:44:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][700/703]	Step 26272	lr 0.02493	Loss 1.7583 (1.6106)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.6%)	
12/22 08:44:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [63][703/703]	Step 26275	lr 0.02493	Loss 1.7834 (1.6109)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (55.3%, 84.6%)	
12/22 08:44:28午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 63/149] Final Prec@1 55.2911%
12/22 08:44:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [63][78/79]	Step 26276	Loss 2.0737	Prec@(1,5) (47.2%, 77.7%)
12/22 08:44:35午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 63/149] Final Prec@1 47.1800%
12/22 08:44:35午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:44:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][100/703]	Step 26376	lr 0.02488	Loss 1.3979 (1.5054)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.2%)	
12/22 08:45:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][200/703]	Step 26476	lr 0.02488	Loss 1.4868 (1.5199)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 85.9%)	
12/22 08:45:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][300/703]	Step 26576	lr 0.02488	Loss 1.8414 (1.5407)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.9%, 85.5%)	
12/22 08:45:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][400/703]	Step 26676	lr 0.02488	Loss 1.4167 (1.5481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.7%, 85.4%)	
12/22 08:46:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][500/703]	Step 26776	lr 0.02488	Loss 1.5216 (1.5554)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.4%)	
12/22 08:46:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][600/703]	Step 26876	lr 0.02488	Loss 1.4544 (1.5584)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.5%, 85.3%)	
12/22 08:47:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][700/703]	Step 26976	lr 0.02488	Loss 1.4769 (1.5636)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.2%)	
12/22 08:47:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [64][703/703]	Step 26979	lr 0.02488	Loss 1.6889 (1.5638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (56.3%, 85.2%)	
12/22 08:47:01午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 64/149] Final Prec@1 56.3022%
12/22 08:47:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [64][78/79]	Step 26980	Loss 1.8496	Prec@(1,5) (50.5%, 80.6%)
12/22 08:47:07午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 64/149] Final Prec@1 50.4400%
12/22 08:47:07午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:47:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][100/703]	Step 27080	lr 0.02482	Loss 1.4504 (1.5019)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.5%, 86.3%)	
12/22 08:47:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][200/703]	Step 27180	lr 0.02482	Loss 1.2216 (1.5182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.0%, 85.9%)	
12/22 08:48:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][300/703]	Step 27280	lr 0.02482	Loss 2.0065 (1.5152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.1%)	
12/22 08:48:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][400/703]	Step 27380	lr 0.02482	Loss 1.5790 (1.5158)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.7%, 86.1%)	
12/22 08:48:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][500/703]	Step 27480	lr 0.02482	Loss 1.4448 (1.5266)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.5%, 85.8%)	
12/22 08:49:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][600/703]	Step 27580	lr 0.02482	Loss 1.4629 (1.5212)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.4%, 85.9%)	
12/22 08:49:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][700/703]	Step 27680	lr 0.02482	Loss 1.4977 (1.5245)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 85.9%)	
12/22 08:49:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [65][703/703]	Step 27683	lr 0.02482	Loss 1.5963 (1.5251)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (57.3%, 85.9%)	
12/22 08:49:33午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 65/149] Final Prec@1 57.3289%
12/22 08:49:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [65][78/79]	Step 27684	Loss 1.8647	Prec@(1,5) (50.2%, 80.9%)
12/22 08:49:40午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 65/149] Final Prec@1 50.1600%
12/22 08:49:40午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:50:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][100/703]	Step 27784	lr 0.02474	Loss 1.4617 (1.4515)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.1%, 86.7%)	
12/22 08:50:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][200/703]	Step 27884	lr 0.02474	Loss 1.1924 (1.4542)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.0%, 86.9%)	
12/22 08:50:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][300/703]	Step 27984	lr 0.02474	Loss 1.3956 (1.4618)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 86.9%)	
12/22 08:51:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][400/703]	Step 28084	lr 0.02474	Loss 1.4966 (1.4705)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.4%, 86.9%)	
12/22 08:51:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][500/703]	Step 28184	lr 0.02474	Loss 1.5803 (1.4788)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.2%, 86.8%)	
12/22 08:51:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][600/703]	Step 28284	lr 0.02474	Loss 1.6019 (1.4833)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.7%)	
12/22 08:52:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][700/703]	Step 28384	lr 0.02474	Loss 1.3950 (1.4828)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.7%)	
12/22 08:52:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [66][703/703]	Step 28387	lr 0.02474	Loss 1.4694 (1.4831)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.1%, 86.7%)	
12/22 08:52:05午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 66/149] Final Prec@1 58.1289%
12/22 08:52:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [66][78/79]	Step 28388	Loss 1.8276	Prec@(1,5) (51.2%, 81.2%)
12/22 08:52:12午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 66/149] Final Prec@1 51.1800%
12/22 08:52:12午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:52:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][100/703]	Step 28488	lr 0.02464	Loss 1.5495 (1.3885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.3%)	
12/22 08:52:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][200/703]	Step 28588	lr 0.02464	Loss 1.3940 (1.4245)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.6%)	
12/22 08:53:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][300/703]	Step 28688	lr 0.02464	Loss 1.5164 (1.4250)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.6%)	
12/22 08:53:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][400/703]	Step 28788	lr 0.02464	Loss 1.4299 (1.4393)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.0%, 87.5%)	
12/22 08:53:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][500/703]	Step 28888	lr 0.02464	Loss 1.3427 (1.4488)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.3%)	
12/22 08:54:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][600/703]	Step 28988	lr 0.02464	Loss 1.4068 (1.4552)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.7%, 87.1%)	
12/22 08:54:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][700/703]	Step 29088	lr 0.02464	Loss 1.0742 (1.4488)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.2%)	
12/22 08:54:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [67][703/703]	Step 29091	lr 0.02464	Loss 1.5093 (1.4488)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (58.9%, 87.2%)	
12/22 08:54:38午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 67/149] Final Prec@1 58.9000%
12/22 08:54:44午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [67][78/79]	Step 29092	Loss 1.8612	Prec@(1,5) (50.5%, 80.9%)
12/22 08:54:44午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 67/149] Final Prec@1 50.5000%
12/22 08:54:44午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:55:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][100/703]	Step 29192	lr 0.02454	Loss 1.2839 (1.3966)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.8%, 88.3%)	
12/22 08:55:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][200/703]	Step 29292	lr 0.02454	Loss 1.4593 (1.3878)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.2%, 88.1%)	
12/22 08:55:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][300/703]	Step 29392	lr 0.02454	Loss 1.3469 (1.3910)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.1%, 88.0%)	
12/22 08:56:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][400/703]	Step 29492	lr 0.02454	Loss 1.4504 (1.3973)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.0%, 87.9%)	
12/22 08:56:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][500/703]	Step 29592	lr 0.02454	Loss 1.3563 (1.4091)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.7%, 87.7%)	
12/22 08:56:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][600/703]	Step 29692	lr 0.02454	Loss 1.1930 (1.4221)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.6%)	
12/22 08:57:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][700/703]	Step 29792	lr 0.02454	Loss 1.2276 (1.4230)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.4%, 87.6%)	
12/22 08:57:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [68][703/703]	Step 29795	lr 0.02454	Loss 1.9181 (1.4237)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (59.5%, 87.6%)	
12/22 08:57:11午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 68/149] Final Prec@1 59.4511%
12/22 08:57:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [68][78/79]	Step 29796	Loss 1.8150	Prec@(1,5) (50.4%, 81.3%)
12/22 08:57:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 68/149] Final Prec@1 50.4200%
12/22 08:57:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 08:57:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][100/703]	Step 29896	lr 0.02441	Loss 1.5660 (1.3519)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.3%)	
12/22 08:58:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][200/703]	Step 29996	lr 0.02441	Loss 1.3633 (1.3535)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.4%, 88.4%)	
12/22 08:58:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][300/703]	Step 30096	lr 0.02441	Loss 1.3068 (1.3763)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.1%, 88.0%)	
12/22 08:58:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][400/703]	Step 30196	lr 0.02441	Loss 1.4472 (1.3828)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.9%, 87.8%)	
12/22 08:59:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][500/703]	Step 30296	lr 0.02441	Loss 1.2723 (1.3834)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.8%, 88.0%)	
12/22 08:59:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][600/703]	Step 30396	lr 0.02441	Loss 1.5225 (1.3866)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 87.9%)	
12/22 08:59:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][700/703]	Step 30496	lr 0.02441	Loss 1.7258 (1.3941)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 87.8%)	
12/22 08:59:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [69][703/703]	Step 30499	lr 0.02441	Loss 1.3960 (1.3941)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 87.8%)	
12/22 08:59:44午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 69/149] Final Prec@1 60.5778%
12/22 08:59:50午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [69][78/79]	Step 30500	Loss 1.7727	Prec@(1,5) (51.9%, 82.7%)
12/22 08:59:51午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 69/149] Final Prec@1 51.8600%
12/22 08:59:51午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:00:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][100/703]	Step 30600	lr 0.02428	Loss 1.6083 (1.3609)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.4%, 88.4%)	
12/22 09:00:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][200/703]	Step 30700	lr 0.02428	Loss 1.4488 (1.3578)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.6%)	
12/22 09:00:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][300/703]	Step 30800	lr 0.02428	Loss 1.7159 (1.3598)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.5%)	
12/22 09:01:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][400/703]	Step 30900	lr 0.02428	Loss 1.6577 (1.3696)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.5%, 88.3%)	
12/22 09:01:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][500/703]	Step 31000	lr 0.02428	Loss 1.2260 (1.3706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.3%)	
12/22 09:01:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][600/703]	Step 31100	lr 0.02428	Loss 1.0205 (1.3677)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.7%, 88.3%)	
12/22 09:02:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][700/703]	Step 31200	lr 0.02428	Loss 1.4722 (1.3737)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.2%)	
12/22 09:02:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [70][703/703]	Step 31203	lr 0.02428	Loss 1.2061 (1.3730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (60.6%, 88.2%)	
12/22 09:02:16午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 70/149] Final Prec@1 60.6067%
12/22 09:02:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [70][78/79]	Step 31204	Loss 1.6764	Prec@(1,5) (54.5%, 83.2%)
12/22 09:02:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 70/149] Final Prec@1 54.4600%
12/22 09:02:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:02:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][100/703]	Step 31304	lr 0.02413	Loss 1.0556 (1.2650)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.6%)	
12/22 09:03:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][200/703]	Step 31404	lr 0.02413	Loss 0.8843 (1.2984)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.1%)	
12/22 09:03:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][300/703]	Step 31504	lr 0.02413	Loss 1.3945 (1.3185)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 88.7%)	
12/22 09:03:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][400/703]	Step 31604	lr 0.02413	Loss 1.6752 (1.3291)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 88.6%)	
12/22 09:04:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][500/703]	Step 31704	lr 0.02413	Loss 0.9782 (1.3293)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.9%, 88.7%)	
12/22 09:04:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][600/703]	Step 31804	lr 0.02413	Loss 1.6028 (1.3353)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.7%, 88.7%)	
12/22 09:04:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][700/703]	Step 31904	lr 0.02413	Loss 1.1736 (1.3448)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.6%)	
12/22 09:04:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [71][703/703]	Step 31907	lr 0.02413	Loss 1.1529 (1.3449)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.5%, 88.6%)	
12/22 09:04:49午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 71/149] Final Prec@1 61.4778%
12/22 09:04:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [71][78/79]	Step 31908	Loss 1.7045	Prec@(1,5) (53.7%, 83.3%)
12/22 09:04:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 71/149] Final Prec@1 53.7800%
12/22 09:04:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:05:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][100/703]	Step 32008	lr 0.02396	Loss 1.4644 (1.2739)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.7%, 89.7%)	
12/22 09:05:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][200/703]	Step 32108	lr 0.02396	Loss 1.1920 (1.2951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.1%)	
12/22 09:05:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][300/703]	Step 32208	lr 0.02396	Loss 1.4395 (1.3072)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.3%, 88.9%)	
12/22 09:06:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][400/703]	Step 32308	lr 0.02396	Loss 1.1866 (1.3053)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.2%, 89.1%)	
12/22 09:06:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][500/703]	Step 32408	lr 0.02396	Loss 1.2516 (1.3130)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.1%, 89.0%)	
12/22 09:07:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][600/703]	Step 32508	lr 0.02396	Loss 1.5283 (1.3173)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.0%, 89.0%)	
12/22 09:07:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][700/703]	Step 32608	lr 0.02396	Loss 1.4727 (1.3256)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 88.9%)	
12/22 09:07:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [72][703/703]	Step 32611	lr 0.02396	Loss 1.3598 (1.3268)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (61.8%, 88.9%)	
12/22 09:07:21午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 72/149] Final Prec@1 61.7956%
12/22 09:07:28午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [72][78/79]	Step 32612	Loss 1.7595	Prec@(1,5) (52.8%, 82.6%)
12/22 09:07:28午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 72/149] Final Prec@1 52.8200%
12/22 09:07:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:07:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][100/703]	Step 32712	lr 0.02379	Loss 1.1553 (1.2852)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.8%, 89.5%)	
12/22 09:08:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][200/703]	Step 32812	lr 0.02379	Loss 1.3386 (1.2556)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.4%, 89.8%)	
12/22 09:08:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][300/703]	Step 32912	lr 0.02379	Loss 1.1036 (1.2750)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.6%)	
12/22 09:08:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][400/703]	Step 33012	lr 0.02379	Loss 1.1018 (1.2819)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.9%, 89.5%)	
12/22 09:09:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][500/703]	Step 33112	lr 0.02379	Loss 0.9891 (1.2918)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.6%, 89.4%)	
12/22 09:09:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][600/703]	Step 33212	lr 0.02379	Loss 1.4854 (1.2971)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.3%)	
12/22 09:09:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][700/703]	Step 33312	lr 0.02379	Loss 1.2150 (1.3004)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.3%)	
12/22 09:09:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [73][703/703]	Step 33315	lr 0.02379	Loss 1.1436 (1.3006)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (62.5%, 89.3%)	
12/22 09:09:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 73/149] Final Prec@1 62.4578%
12/22 09:10:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [73][78/79]	Step 33316	Loss 1.6902	Prec@(1,5) (53.7%, 83.6%)
12/22 09:10:01午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 73/149] Final Prec@1 53.7200%
12/22 09:10:01午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:10:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][100/703]	Step 33416	lr 0.0236	Loss 1.2035 (1.2364)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.0%)	
12/22 09:10:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][200/703]	Step 33516	lr 0.0236	Loss 1.4395 (1.2556)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.8%, 89.8%)	
12/22 09:11:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][300/703]	Step 33616	lr 0.0236	Loss 1.1020 (1.2769)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.3%, 89.5%)	
12/22 09:11:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][400/703]	Step 33716	lr 0.0236	Loss 1.4866 (1.2826)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.1%, 89.5%)	
12/22 09:11:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][500/703]	Step 33816	lr 0.0236	Loss 1.3112 (1.2845)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.5%)	
12/22 09:12:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][600/703]	Step 33916	lr 0.0236	Loss 1.4633 (1.2825)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.2%, 89.6%)	
12/22 09:12:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][700/703]	Step 34016	lr 0.0236	Loss 1.2584 (1.2864)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.5%)	
12/22 09:12:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [74][703/703]	Step 34019	lr 0.0236	Loss 1.2820 (1.2870)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.0%, 89.5%)	
12/22 09:12:28午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 74/149] Final Prec@1 62.9800%
12/22 09:12:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [74][78/79]	Step 34020	Loss 1.7736	Prec@(1,5) (52.5%, 82.8%)
12/22 09:12:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 74/149] Final Prec@1 52.4600%
12/22 09:12:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:12:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][100/703]	Step 34120	lr 0.02339	Loss 0.7915 (1.1985)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 91.1%)	
12/22 09:13:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][200/703]	Step 34220	lr 0.02339	Loss 1.0268 (1.2317)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.4%, 90.5%)	
12/22 09:13:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][300/703]	Step 34320	lr 0.02339	Loss 1.6255 (1.2347)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.3%)	
12/22 09:13:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][400/703]	Step 34420	lr 0.02339	Loss 1.2270 (1.2357)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.4%)	
12/22 09:14:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][500/703]	Step 34520	lr 0.02339	Loss 1.0737 (1.2509)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.1%)	
12/22 09:14:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][600/703]	Step 34620	lr 0.02339	Loss 1.4608 (1.2621)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.9%, 89.9%)	
12/22 09:15:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][700/703]	Step 34720	lr 0.02339	Loss 1.5420 (1.2703)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.8%)	
12/22 09:15:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [75][703/703]	Step 34723	lr 0.02339	Loss 1.3345 (1.2706)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.7%, 89.8%)	
12/22 09:15:01午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 75/149] Final Prec@1 63.6933%
12/22 09:15:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [75][78/79]	Step 34724	Loss 1.7089	Prec@(1,5) (53.7%, 83.5%)
12/22 09:15:08午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 75/149] Final Prec@1 53.7000%
12/22 09:15:08午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:15:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][100/703]	Step 34824	lr 0.02318	Loss 0.9830 (1.1764)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.3%)	
12/22 09:15:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][200/703]	Step 34924	lr 0.02318	Loss 1.4470 (1.1928)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 91.0%)	
12/22 09:16:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][300/703]	Step 35024	lr 0.02318	Loss 1.1106 (1.2037)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.1%, 90.7%)	
12/22 09:16:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][400/703]	Step 35124	lr 0.02318	Loss 1.1964 (1.2204)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.6%)	
12/22 09:16:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][500/703]	Step 35224	lr 0.02318	Loss 1.4398 (1.2326)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.4%)	
12/22 09:17:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][600/703]	Step 35324	lr 0.02318	Loss 0.9415 (1.2411)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.0%, 90.3%)	
12/22 09:17:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][700/703]	Step 35424	lr 0.02318	Loss 1.4604 (1.2520)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.1%)	
12/22 09:17:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [76][703/703]	Step 35427	lr 0.02318	Loss 1.4588 (1.2522)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (63.8%, 90.1%)	
12/22 09:17:35午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 76/149] Final Prec@1 63.8222%
12/22 09:17:41午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [76][78/79]	Step 35428	Loss 1.6931	Prec@(1,5) (53.4%, 84.3%)
12/22 09:17:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 76/149] Final Prec@1 53.4400%
12/22 09:17:41午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:18:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][100/703]	Step 35528	lr 0.02295	Loss 1.1698 (1.1664)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.7%)	
12/22 09:18:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][200/703]	Step 35628	lr 0.02295	Loss 1.1986 (1.2152)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.5%, 90.7%)	
12/22 09:18:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][300/703]	Step 35728	lr 0.02295	Loss 1.1274 (1.2237)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.7%)	
12/22 09:19:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][400/703]	Step 35828	lr 0.02295	Loss 1.4175 (1.2347)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.5%)	
12/22 09:19:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][500/703]	Step 35928	lr 0.02295	Loss 1.1845 (1.2316)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.3%, 90.4%)	
12/22 09:19:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][600/703]	Step 36028	lr 0.02295	Loss 1.4172 (1.2365)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.3%)	
12/22 09:20:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][700/703]	Step 36128	lr 0.02295	Loss 0.9510 (1.2387)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.2%)	
12/22 09:20:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [77][703/703]	Step 36131	lr 0.02295	Loss 1.5471 (1.2393)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.2%, 90.2%)	
12/22 09:20:07午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 77/149] Final Prec@1 64.1578%
12/22 09:20:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [77][78/79]	Step 36132	Loss 1.7094	Prec@(1,5) (53.5%, 84.3%)
12/22 09:20:13午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 77/149] Final Prec@1 53.5600%
12/22 09:20:14午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 54.7840%
12/22 09:20:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][100/703]	Step 36232	lr 0.02271	Loss 1.2504 (1.1670)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.1%)	
12/22 09:20:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][200/703]	Step 36332	lr 0.02271	Loss 1.3068 (1.1898)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.7%, 90.8%)	
12/22 09:21:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][300/703]	Step 36432	lr 0.02271	Loss 1.0315 (1.1997)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 90.7%)	
12/22 09:21:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][400/703]	Step 36532	lr 0.02271	Loss 1.2925 (1.2088)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.9%, 90.6%)	
12/22 09:21:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][500/703]	Step 36632	lr 0.02271	Loss 1.2036 (1.2127)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.5%)	
12/22 09:22:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][600/703]	Step 36732	lr 0.02271	Loss 1.0355 (1.2137)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.8%, 90.5%)	
12/22 09:22:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][700/703]	Step 36832	lr 0.02271	Loss 1.4073 (1.2202)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.4%)	
12/22 09:22:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [78][703/703]	Step 36835	lr 0.02271	Loss 1.1233 (1.2199)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (64.6%, 90.4%)	
12/22 09:22:41午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 78/149] Final Prec@1 64.5733%
12/22 09:22:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [78][78/79]	Step 36836	Loss 1.5851	Prec@(1,5) (56.7%, 85.0%)
12/22 09:22:47午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 78/149] Final Prec@1 56.6400%
12/22 09:22:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.6400%
12/22 09:23:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][100/703]	Step 36936	lr 0.02246	Loss 1.0089 (1.1219)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.7%)	
12/22 09:23:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][200/703]	Step 37036	lr 0.02246	Loss 1.0547 (1.1415)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.5%)	
12/22 09:23:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][300/703]	Step 37136	lr 0.02246	Loss 0.7594 (1.1622)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.3%)	
12/22 09:24:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][400/703]	Step 37236	lr 0.02246	Loss 0.9508 (1.1727)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.6%, 91.1%)	
12/22 09:24:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][500/703]	Step 37336	lr 0.02246	Loss 1.0347 (1.1814)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.4%, 91.1%)	
12/22 09:24:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][600/703]	Step 37436	lr 0.02246	Loss 1.4014 (1.1866)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.3%, 91.0%)	
12/22 09:25:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][700/703]	Step 37536	lr 0.02246	Loss 1.5109 (1.1897)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.9%)	
12/22 09:25:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [79][703/703]	Step 37539	lr 0.02246	Loss 1.0287 (1.1900)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.2%, 90.9%)	
12/22 09:25:16午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 79/149] Final Prec@1 65.2267%
12/22 09:25:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [79][78/79]	Step 37540	Loss 1.6620	Prec@(1,5) (55.3%, 84.3%)
12/22 09:25:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 79/149] Final Prec@1 55.3200%
12/22 09:25:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 56.6400%
12/22 09:25:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][100/703]	Step 37640	lr 0.02219	Loss 1.0591 (1.1253)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 92.0%)	
12/22 09:26:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][200/703]	Step 37740	lr 0.02219	Loss 1.0929 (1.1309)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.8%, 92.2%)	
12/22 09:26:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][300/703]	Step 37840	lr 0.02219	Loss 1.0225 (1.1530)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.7%)	
12/22 09:26:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][400/703]	Step 37940	lr 0.02219	Loss 0.9999 (1.1652)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.5%)	
12/22 09:27:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][500/703]	Step 38040	lr 0.02219	Loss 1.0536 (1.1701)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.8%, 91.4%)	
12/22 09:27:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][600/703]	Step 38140	lr 0.02219	Loss 1.0277 (1.1795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.2%)	
12/22 09:27:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][700/703]	Step 38240	lr 0.02219	Loss 1.2508 (1.1799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.2%)	
12/22 09:27:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [80][703/703]	Step 38243	lr 0.02219	Loss 1.2351 (1.1805)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.5%, 91.2%)	
12/22 09:27:48午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 80/149] Final Prec@1 65.4578%
12/22 09:27:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [80][78/79]	Step 38244	Loss 1.5633	Prec@(1,5) (57.1%, 85.9%)
12/22 09:27:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 80/149] Final Prec@1 57.0600%
12/22 09:27:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0600%
12/22 09:28:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][100/703]	Step 38344	lr 0.02192	Loss 1.3878 (1.1406)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.4%)	
12/22 09:28:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][200/703]	Step 38444	lr 0.02192	Loss 1.1324 (1.1366)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.6%)	
12/22 09:28:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][300/703]	Step 38544	lr 0.02192	Loss 1.1693 (1.1465)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.3%, 91.6%)	
12/22 09:29:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][400/703]	Step 38644	lr 0.02192	Loss 0.8034 (1.1519)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.2%, 91.6%)	
12/22 09:29:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][500/703]	Step 38744	lr 0.02192	Loss 1.1343 (1.1609)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.1%, 91.4%)	
12/22 09:30:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][600/703]	Step 38844	lr 0.02192	Loss 1.0603 (1.1690)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.0%, 91.3%)	
12/22 09:30:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][700/703]	Step 38944	lr 0.02192	Loss 1.3186 (1.1725)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.2%)	
12/22 09:30:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [81][703/703]	Step 38947	lr 0.02192	Loss 1.3621 (1.1732)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (65.9%, 91.2%)	
12/22 09:30:21午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 81/149] Final Prec@1 65.9044%
12/22 09:30:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [81][78/79]	Step 38948	Loss 1.6744	Prec@(1,5) (55.3%, 83.9%)
12/22 09:30:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 81/149] Final Prec@1 55.3400%
12/22 09:30:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0600%
12/22 09:30:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][100/703]	Step 39048	lr 0.02163	Loss 1.2216 (1.1197)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.9%)	
12/22 09:31:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][200/703]	Step 39148	lr 0.02163	Loss 1.0350 (1.1191)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.8%)	
12/22 09:31:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][300/703]	Step 39248	lr 0.02163	Loss 0.9379 (1.1161)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.9%)	
12/22 09:31:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][400/703]	Step 39348	lr 0.02163	Loss 1.3457 (1.1232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.9%)	
12/22 09:32:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][500/703]	Step 39448	lr 0.02163	Loss 1.1641 (1.1364)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.7%)	
12/22 09:32:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][600/703]	Step 39548	lr 0.02163	Loss 1.0734 (1.1476)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.6%, 91.6%)	
12/22 09:32:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][700/703]	Step 39648	lr 0.02163	Loss 1.2176 (1.1529)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.5%)	
12/22 09:32:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [82][703/703]	Step 39651	lr 0.02163	Loss 1.2583 (1.1531)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.5%, 91.5%)	
12/22 09:32:55午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 82/149] Final Prec@1 66.4800%
12/22 09:33:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [82][78/79]	Step 39652	Loss 1.5669	Prec@(1,5) (56.7%, 85.7%)
12/22 09:33:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 82/149] Final Prec@1 56.7000%
12/22 09:33:02午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.0600%
12/22 09:33:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][100/703]	Step 39752	lr 0.02134	Loss 1.0252 (1.0855)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 92.1%)	
12/22 09:33:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][200/703]	Step 39852	lr 0.02134	Loss 0.9579 (1.1122)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.7%)	
12/22 09:34:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][300/703]	Step 39952	lr 0.02134	Loss 1.1710 (1.1098)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.8%)	
12/22 09:34:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][400/703]	Step 40052	lr 0.02134	Loss 1.2494 (1.1164)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.2%, 91.8%)	
12/22 09:34:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][500/703]	Step 40152	lr 0.02134	Loss 0.9793 (1.1260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.0%, 91.6%)	
12/22 09:35:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][600/703]	Step 40252	lr 0.02134	Loss 1.1451 (1.1322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.9%, 91.5%)	
12/22 09:35:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][700/703]	Step 40352	lr 0.02134	Loss 1.2810 (1.1409)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.5%)	
12/22 09:35:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [83][703/703]	Step 40355	lr 0.02134	Loss 1.4448 (1.1419)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (66.7%, 91.5%)	
12/22 09:35:27午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 83/149] Final Prec@1 66.6533%
12/22 09:35:34午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [83][78/79]	Step 40356	Loss 1.5897	Prec@(1,5) (57.2%, 84.8%)
12/22 09:35:34午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 83/149] Final Prec@1 57.1600%
12/22 09:35:34午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.1600%
12/22 09:35:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][100/703]	Step 40456	lr 0.02103	Loss 1.1773 (1.0635)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.3%)	
12/22 09:36:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][200/703]	Step 40556	lr 0.02103	Loss 0.9969 (1.0648)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.4%)	
12/22 09:36:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][300/703]	Step 40656	lr 0.02103	Loss 0.8275 (1.0828)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.0%)	
12/22 09:36:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][400/703]	Step 40756	lr 0.02103	Loss 1.2346 (1.1023)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.0%)	
12/22 09:37:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][500/703]	Step 40856	lr 0.02103	Loss 1.3061 (1.1118)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.6%, 91.8%)	
12/22 09:37:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][600/703]	Step 40956	lr 0.02103	Loss 0.8450 (1.1184)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.7%)	
12/22 09:38:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][700/703]	Step 41056	lr 0.02103	Loss 1.2495 (1.1228)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.7%)	
12/22 09:38:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [84][703/703]	Step 41059	lr 0.02103	Loss 1.1442 (1.1223)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.5%, 91.7%)	
12/22 09:38:00午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 84/149] Final Prec@1 67.4600%
12/22 09:38:07午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [84][78/79]	Step 41060	Loss 1.5429	Prec@(1,5) (57.3%, 86.6%)
12/22 09:38:07午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 84/149] Final Prec@1 57.3000%
12/22 09:38:07午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.3000%
12/22 09:38:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][100/703]	Step 41160	lr 0.02071	Loss 1.1843 (1.0528)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.5%)	
12/22 09:38:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][200/703]	Step 41260	lr 0.02071	Loss 1.4236 (1.0671)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.5%, 92.5%)	
12/22 09:39:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][300/703]	Step 41360	lr 0.02071	Loss 0.9539 (1.0742)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.4%)	
12/22 09:39:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][400/703]	Step 41460	lr 0.02071	Loss 1.2716 (1.0790)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.3%)	
12/22 09:39:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][500/703]	Step 41560	lr 0.02071	Loss 1.1018 (1.0863)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.2%)	
12/22 09:40:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][600/703]	Step 41660	lr 0.02071	Loss 1.1931 (1.0948)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.9%, 92.1%)	
12/22 09:40:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][700/703]	Step 41760	lr 0.02071	Loss 1.0651 (1.1014)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.0%)	
12/22 09:40:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [85][703/703]	Step 41763	lr 0.02071	Loss 1.3103 (1.1018)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (67.7%, 92.0%)	
12/22 09:40:34午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 85/149] Final Prec@1 67.7244%
12/22 09:40:40午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [85][78/79]	Step 41764	Loss 1.6747	Prec@(1,5) (55.2%, 84.1%)
12/22 09:40:41午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 85/149] Final Prec@1 55.2400%
12/22 09:40:41午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.3000%
12/22 09:41:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][100/703]	Step 41864	lr 0.02039	Loss 1.2056 (1.0044)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
12/22 09:41:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][200/703]	Step 41964	lr 0.02039	Loss 0.9078 (1.0280)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.1%)	
12/22 09:41:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][300/703]	Step 42064	lr 0.02039	Loss 1.2960 (1.0579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.0%, 92.7%)	
12/22 09:42:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][400/703]	Step 42164	lr 0.02039	Loss 1.2383 (1.0665)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.8%, 92.5%)	
12/22 09:42:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][500/703]	Step 42264	lr 0.02039	Loss 0.9447 (1.0775)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.3%)	
12/22 09:42:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][600/703]	Step 42364	lr 0.02039	Loss 0.8433 (1.0873)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.3%)	
12/22 09:43:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][700/703]	Step 42464	lr 0.02039	Loss 1.2179 (1.0902)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.2%)	
12/22 09:43:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [86][703/703]	Step 42467	lr 0.02039	Loss 0.9570 (1.0903)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.0%, 92.2%)	
12/22 09:43:06午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 86/149] Final Prec@1 68.0422%
12/22 09:43:13午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [86][78/79]	Step 42468	Loss 1.6702	Prec@(1,5) (55.5%, 84.3%)
12/22 09:43:13午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 86/149] Final Prec@1 55.5200%
12/22 09:43:13午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.3000%
12/22 09:43:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][100/703]	Step 42568	lr 0.02005	Loss 0.8972 (1.0296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 92.8%)	
12/22 09:43:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][200/703]	Step 42668	lr 0.02005	Loss 1.3981 (1.0420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.8%)	
12/22 09:44:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][300/703]	Step 42768	lr 0.02005	Loss 1.1488 (1.0517)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.7%)	
12/22 09:44:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][400/703]	Step 42868	lr 0.02005	Loss 1.1258 (1.0627)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.6%)	
12/22 09:44:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][500/703]	Step 42968	lr 0.02005	Loss 1.2371 (1.0693)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.2%, 92.5%)	
12/22 09:45:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][600/703]	Step 43068	lr 0.02005	Loss 1.2931 (1.0683)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.3%, 92.5%)	
12/22 09:45:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][700/703]	Step 43168	lr 0.02005	Loss 1.1704 (1.0747)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.4%)	
12/22 09:45:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [87][703/703]	Step 43171	lr 0.02005	Loss 1.4885 (1.0760)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.1%, 92.4%)	
12/22 09:45:40午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 87/149] Final Prec@1 68.0822%
12/22 09:45:46午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [87][78/79]	Step 43172	Loss 1.6377	Prec@(1,5) (55.8%, 85.3%)
12/22 09:45:46午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 87/149] Final Prec@1 55.7800%
12/22 09:45:46午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 57.3000%
12/22 09:46:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][100/703]	Step 43272	lr 0.01971	Loss 1.1770 (1.0068)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.3%)	
12/22 09:46:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][200/703]	Step 43372	lr 0.01971	Loss 1.0118 (1.0132)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.4%)	
12/22 09:46:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][300/703]	Step 43472	lr 0.01971	Loss 1.5916 (1.0351)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.2%, 93.2%)	
12/22 09:47:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][400/703]	Step 43572	lr 0.01971	Loss 1.1349 (1.0448)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.9%, 93.0%)	
12/22 09:47:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][500/703]	Step 43672	lr 0.01971	Loss 1.2493 (1.0514)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.7%, 92.8%)	
12/22 09:47:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][600/703]	Step 43772	lr 0.01971	Loss 1.2751 (1.0613)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.6%, 92.7%)	
12/22 09:48:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][700/703]	Step 43872	lr 0.01971	Loss 1.3103 (1.0663)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.6%)	
12/22 09:48:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [88][703/703]	Step 43875	lr 0.01971	Loss 1.0157 (1.0669)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (68.4%, 92.6%)	
12/22 09:48:13午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 88/149] Final Prec@1 68.3711%
12/22 09:48:19午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [88][78/79]	Step 43876	Loss 1.5856	Prec@(1,5) (58.4%, 85.5%)
12/22 09:48:19午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 88/149] Final Prec@1 58.4000%
12/22 09:48:19午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.4000%
12/22 09:48:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][100/703]	Step 43976	lr 0.01936	Loss 1.1632 (1.0062)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.2%)	
12/22 09:49:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][200/703]	Step 44076	lr 0.01936	Loss 0.6776 (1.0007)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.5%)	
12/22 09:49:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][300/703]	Step 44176	lr 0.01936	Loss 0.8158 (1.0077)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.4%)	
12/22 09:49:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][400/703]	Step 44276	lr 0.01936	Loss 1.0964 (1.0238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.8%, 93.2%)	
12/22 09:50:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][500/703]	Step 44376	lr 0.01936	Loss 1.1118 (1.0260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.1%)	
12/22 09:50:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][600/703]	Step 44476	lr 0.01936	Loss 1.1395 (1.0334)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.0%)	
12/22 09:50:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][700/703]	Step 44576	lr 0.01936	Loss 1.5409 (1.0428)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.9%)	
12/22 09:50:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [89][703/703]	Step 44579	lr 0.01936	Loss 0.9687 (1.0422)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.1%, 92.9%)	
12/22 09:50:45午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 89/149] Final Prec@1 69.0756%
12/22 09:50:51午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [89][78/79]	Step 44580	Loss 1.6450	Prec@(1,5) (56.4%, 85.0%)
12/22 09:50:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 89/149] Final Prec@1 56.3400%
12/22 09:50:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.4000%
12/22 09:51:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][100/703]	Step 44680	lr 0.019	Loss 0.9879 (0.9795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.6%)	
12/22 09:51:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][200/703]	Step 44780	lr 0.019	Loss 1.0486 (0.9951)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.5%)	
12/22 09:51:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][300/703]	Step 44880	lr 0.019	Loss 0.9018 (1.0039)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.3%)	
12/22 09:52:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][400/703]	Step 44980	lr 0.019	Loss 0.7580 (1.0093)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.0%, 93.3%)	
12/22 09:52:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][500/703]	Step 45080	lr 0.019	Loss 1.0736 (1.0186)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.9%, 93.2%)	
12/22 09:52:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][600/703]	Step 45180	lr 0.019	Loss 1.1139 (1.0221)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.7%, 93.1%)	
12/22 09:53:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][700/703]	Step 45280	lr 0.019	Loss 0.9236 (1.0323)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.0%)	
12/22 09:53:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [90][703/703]	Step 45283	lr 0.019	Loss 1.0354 (1.0325)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (69.4%, 93.0%)	
12/22 09:53:17午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 90/149] Final Prec@1 69.4133%
12/22 09:53:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [90][78/79]	Step 45284	Loss 1.5814	Prec@(1,5) (57.6%, 85.6%)
12/22 09:53:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 90/149] Final Prec@1 57.5400%
12/22 09:53:24午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.4000%
12/22 09:53:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][100/703]	Step 45384	lr 0.01863	Loss 1.0528 (0.9512)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.6%, 93.9%)	
12/22 09:54:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][200/703]	Step 45484	lr 0.01863	Loss 0.9779 (0.9695)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.2%, 93.7%)	
12/22 09:54:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][300/703]	Step 45584	lr 0.01863	Loss 1.3386 (0.9798)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.6%)	
12/22 09:54:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][400/703]	Step 45684	lr 0.01863	Loss 1.1314 (0.9887)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.6%)	
12/22 09:55:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][500/703]	Step 45784	lr 0.01863	Loss 1.1961 (0.9966)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.4%)	
12/22 09:55:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][600/703]	Step 45884	lr 0.01863	Loss 1.1449 (1.0018)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.3%, 93.4%)	
12/22 09:55:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][700/703]	Step 45984	lr 0.01863	Loss 0.8395 (1.0075)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.3%)	
12/22 09:55:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [91][703/703]	Step 45987	lr 0.01863	Loss 1.0286 (1.0079)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.2%, 93.3%)	
12/22 09:55:49午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 91/149] Final Prec@1 70.1622%
12/22 09:55:56午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [91][78/79]	Step 45988	Loss 1.5629	Prec@(1,5) (58.5%, 85.1%)
12/22 09:55:56午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 91/149] Final Prec@1 58.5200%
12/22 09:55:56午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.5200%
12/22 09:56:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][100/703]	Step 46088	lr 0.01826	Loss 0.9730 (0.9450)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.1%)	
12/22 09:56:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][200/703]	Step 46188	lr 0.01826	Loss 0.6677 (0.9630)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.8%)	
12/22 09:56:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][300/703]	Step 46288	lr 0.01826	Loss 1.0185 (0.9659)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.9%)	
12/22 09:57:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][400/703]	Step 46388	lr 0.01826	Loss 1.0654 (0.9707)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.9%, 93.7%)	
12/22 09:57:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][500/703]	Step 46488	lr 0.01826	Loss 1.0404 (0.9847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.7%, 93.5%)	
12/22 09:58:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][600/703]	Step 46588	lr 0.01826	Loss 1.1173 (0.9933)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.5%, 93.5%)	
12/22 09:58:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][700/703]	Step 46688	lr 0.01826	Loss 1.1714 (1.0009)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.4%)	
12/22 09:58:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [92][703/703]	Step 46691	lr 0.01826	Loss 0.8859 (1.0005)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.4%, 93.4%)	
12/22 09:58:22午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 92/149] Final Prec@1 70.3578%
12/22 09:58:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [92][78/79]	Step 46692	Loss 1.5526	Prec@(1,5) (57.7%, 86.2%)
12/22 09:58:29午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 92/149] Final Prec@1 57.7000%
12/22 09:58:29午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.5200%
12/22 09:58:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][100/703]	Step 46792	lr 0.01788	Loss 0.8903 (0.8897)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.4%)	
12/22 09:59:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][200/703]	Step 46892	lr 0.01788	Loss 1.1546 (0.9191)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.3%)	
12/22 09:59:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][300/703]	Step 46992	lr 0.01788	Loss 1.0368 (0.9367)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 94.1%)	
12/22 09:59:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][400/703]	Step 47092	lr 0.01788	Loss 1.2831 (0.9560)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.9%)	
12/22 10:00:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][500/703]	Step 47192	lr 0.01788	Loss 1.0112 (0.9644)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.8%)	
12/22 10:00:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][600/703]	Step 47292	lr 0.01788	Loss 1.3045 (0.9801)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.8%, 93.5%)	
12/22 10:00:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][700/703]	Step 47392	lr 0.01788	Loss 0.8708 (0.9885)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.4%)	
12/22 10:00:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [93][703/703]	Step 47395	lr 0.01788	Loss 0.9300 (0.9889)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (70.6%, 93.4%)	
12/22 10:00:54午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 93/149] Final Prec@1 70.6000%
12/22 10:01:01午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [93][78/79]	Step 47396	Loss 1.5607	Prec@(1,5) (57.6%, 86.2%)
12/22 10:01:01午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 93/149] Final Prec@1 57.6000%
12/22 10:01:01午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.5200%
12/22 10:01:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][100/703]	Step 47496	lr 0.0175	Loss 0.6429 (0.8704)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.8%)	
12/22 10:01:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][200/703]	Step 47596	lr 0.0175	Loss 0.9697 (0.9090)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.3%)	
12/22 10:02:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][300/703]	Step 47696	lr 0.0175	Loss 1.1065 (0.9198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.1%)	
12/22 10:02:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][400/703]	Step 47796	lr 0.0175	Loss 1.1154 (0.9318)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.9%, 94.0%)	
12/22 10:02:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][500/703]	Step 47896	lr 0.0175	Loss 1.0194 (0.9397)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.8%, 93.9%)	
12/22 10:03:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][600/703]	Step 47996	lr 0.0175	Loss 0.7888 (0.9512)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.3%, 93.8%)	
12/22 10:03:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][700/703]	Step 48096	lr 0.0175	Loss 0.9455 (0.9570)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.7%)	
12/22 10:03:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [94][703/703]	Step 48099	lr 0.0175	Loss 1.4515 (0.9580)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.0%, 93.7%)	
12/22 10:03:27午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 94/149] Final Prec@1 71.0111%
12/22 10:03:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [94][78/79]	Step 48100	Loss 1.5933	Prec@(1,5) (57.5%, 85.9%)
12/22 10:03:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 94/149] Final Prec@1 57.5000%
12/22 10:03:33午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 58.5200%
12/22 10:03:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][100/703]	Step 48200	lr 0.0171	Loss 1.0145 (0.8645)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.8%)	
12/22 10:04:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][200/703]	Step 48300	lr 0.0171	Loss 1.0898 (0.8926)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.5%)	
12/22 10:04:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][300/703]	Step 48400	lr 0.0171	Loss 0.9077 (0.9169)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.2%)	
12/22 10:04:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][400/703]	Step 48500	lr 0.0171	Loss 0.8861 (0.9268)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.1%)	
12/22 10:05:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][500/703]	Step 48600	lr 0.0171	Loss 1.0837 (0.9361)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.1%)	
12/22 10:05:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][600/703]	Step 48700	lr 0.0171	Loss 1.1232 (0.9455)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.7%, 94.0%)	
12/22 10:05:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][700/703]	Step 48800	lr 0.0171	Loss 1.0908 (0.9541)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.9%)	
12/22 10:05:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [95][703/703]	Step 48803	lr 0.0171	Loss 0.9860 (0.9543)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (71.5%, 93.9%)	
12/22 10:05:59午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 95/149] Final Prec@1 71.4533%
12/22 10:06:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [95][78/79]	Step 48804	Loss 1.5243	Prec@(1,5) (59.0%, 87.0%)
12/22 10:06:05午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 95/149] Final Prec@1 59.0800%
12/22 10:06:06午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.0800%
12/22 10:06:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][100/703]	Step 48904	lr 0.01671	Loss 0.9303 (0.8931)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.7%)	
12/22 10:06:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][200/703]	Step 49004	lr 0.01671	Loss 0.7826 (0.8845)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.7%, 94.7%)	
12/22 10:07:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][300/703]	Step 49104	lr 0.01671	Loss 0.8067 (0.8970)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.3%, 94.6%)	
12/22 10:07:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][400/703]	Step 49204	lr 0.01671	Loss 1.3090 (0.9041)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.0%, 94.4%)	
12/22 10:07:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][500/703]	Step 49304	lr 0.01671	Loss 1.0759 (0.9142)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.3%)	
12/22 10:08:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][600/703]	Step 49404	lr 0.01671	Loss 1.0595 (0.9286)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.3%, 94.1%)	
12/22 10:08:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][700/703]	Step 49504	lr 0.01671	Loss 1.0232 (0.9372)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.0%)	
12/22 10:08:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [96][703/703]	Step 49507	lr 0.01671	Loss 0.9512 (0.9367)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.0%)	
12/22 10:08:32午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 96/149] Final Prec@1 72.1222%
12/22 10:08:39午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [96][78/79]	Step 49508	Loss 1.5811	Prec@(1,5) (58.9%, 85.7%)
12/22 10:08:39午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 96/149] Final Prec@1 58.8000%
12/22 10:08:39午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.0800%
12/22 10:09:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][100/703]	Step 49608	lr 0.01631	Loss 0.8752 (0.8464)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.4%)	
12/22 10:09:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][200/703]	Step 49708	lr 0.01631	Loss 0.6294 (0.8655)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.8%, 95.2%)	
12/22 10:09:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][300/703]	Step 49808	lr 0.01631	Loss 0.7465 (0.8810)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.4%, 94.9%)	
12/22 10:10:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][400/703]	Step 49908	lr 0.01631	Loss 1.3078 (0.8888)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.7%)	
12/22 10:10:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][500/703]	Step 50008	lr 0.01631	Loss 1.1999 (0.8996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.7%)	
12/22 10:10:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][600/703]	Step 50108	lr 0.01631	Loss 0.8234 (0.9102)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.4%, 94.6%)	
12/22 10:11:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][700/703]	Step 50208	lr 0.01631	Loss 0.9391 (0.9213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.5%)	
12/22 10:11:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [97][703/703]	Step 50211	lr 0.01631	Loss 0.9138 (0.9215)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.1%, 94.5%)	
12/22 10:11:06午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 97/149] Final Prec@1 72.1267%
12/22 10:11:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [97][78/79]	Step 50212	Loss 1.5892	Prec@(1,5) (57.9%, 85.8%)
12/22 10:11:12午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 97/149] Final Prec@1 57.9200%
12/22 10:11:12午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.0800%
12/22 10:11:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][100/703]	Step 50312	lr 0.0159	Loss 0.8411 (0.8596)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 95.2%)	
12/22 10:11:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][200/703]	Step 50412	lr 0.0159	Loss 0.8118 (0.8659)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 95.0%)	
12/22 10:12:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][300/703]	Step 50512	lr 0.0159	Loss 0.7118 (0.8776)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.5%, 94.8%)	
12/22 10:12:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][400/703]	Step 50612	lr 0.0159	Loss 0.7943 (0.8860)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.7%)	
12/22 10:12:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][500/703]	Step 50712	lr 0.0159	Loss 0.7699 (0.8943)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.8%, 94.6%)	
12/22 10:13:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][600/703]	Step 50812	lr 0.0159	Loss 1.2101 (0.9011)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.7%, 94.5%)	
12/22 10:13:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][700/703]	Step 50912	lr 0.0159	Loss 0.5956 (0.9100)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.4%)	
12/22 10:13:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [98][703/703]	Step 50915	lr 0.0159	Loss 1.0612 (0.9108)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (72.6%, 94.4%)	
12/22 10:13:38午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 98/149] Final Prec@1 72.5711%
12/22 10:13:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [98][78/79]	Step 50916	Loss 1.6186	Prec@(1,5) (57.0%, 85.8%)
12/22 10:13:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 98/149] Final Prec@1 56.9800%
12/22 10:13:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 59.0800%
12/22 10:14:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][100/703]	Step 51016	lr 0.01549	Loss 0.8705 (0.7993)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.6%)	
12/22 10:14:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][200/703]	Step 51116	lr 0.01549	Loss 0.7595 (0.8238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.3%)	
12/22 10:14:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][300/703]	Step 51216	lr 0.01549	Loss 0.8561 (0.8494)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.4%, 95.1%)	
12/22 10:15:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][400/703]	Step 51316	lr 0.01549	Loss 0.8709 (0.8627)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
12/22 10:15:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][500/703]	Step 51416	lr 0.01549	Loss 1.0057 (0.8677)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.9%)	
12/22 10:15:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][600/703]	Step 51516	lr 0.01549	Loss 1.1940 (0.8771)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.7%)	
12/22 10:16:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][700/703]	Step 51616	lr 0.01549	Loss 1.0849 (0.8904)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.6%)	
12/22 10:16:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [99][703/703]	Step 51619	lr 0.01549	Loss 0.9461 (0.8909)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.2%, 94.6%)	
12/22 10:16:11午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [ 99/149] Final Prec@1 73.1933%
12/22 10:16:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [99][78/79]	Step 51620	Loss 1.4874	Prec@(1,5) (60.9%, 86.7%)
12/22 10:16:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [ 99/149] Final Prec@1 60.9000%
12/22 10:16:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.9000%
12/22 10:16:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][100/703]	Step 51720	lr 0.01508	Loss 1.0540 (0.7964)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.4%)	
12/22 10:16:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][200/703]	Step 51820	lr 0.01508	Loss 1.0010 (0.8076)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.4%)	
12/22 10:17:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][300/703]	Step 51920	lr 0.01508	Loss 0.9400 (0.8216)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.1%, 95.2%)	
12/22 10:17:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][400/703]	Step 52020	lr 0.01508	Loss 0.8742 (0.8381)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.5%, 95.1%)	
12/22 10:18:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][500/703]	Step 52120	lr 0.01508	Loss 0.7181 (0.8563)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.0%, 94.9%)	
12/22 10:18:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][600/703]	Step 52220	lr 0.01508	Loss 0.9868 (0.8598)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.9%, 94.9%)	
12/22 10:18:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][700/703]	Step 52320	lr 0.01508	Loss 0.7742 (0.8687)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.8%)	
12/22 10:18:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [100][703/703]	Step 52323	lr 0.01508	Loss 0.5958 (0.8679)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (73.6%, 94.8%)	
12/22 10:18:43午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [100/149] Final Prec@1 73.6444%
12/22 10:18:49午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [100][78/79]	Step 52324	Loss 1.5271	Prec@(1,5) (59.6%, 86.8%)
12/22 10:18:49午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [100/149] Final Prec@1 59.6400%
12/22 10:18:49午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.9000%
12/22 10:19:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][100/703]	Step 52424	lr 0.01467	Loss 0.7846 (0.8084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.2%)	
12/22 10:19:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][200/703]	Step 52524	lr 0.01467	Loss 0.8686 (0.8150)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.3%)	
12/22 10:19:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][300/703]	Step 52624	lr 0.01467	Loss 0.8785 (0.8162)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.3%)	
12/22 10:20:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][400/703]	Step 52724	lr 0.01467	Loss 0.9106 (0.8320)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
12/22 10:20:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][500/703]	Step 52824	lr 0.01467	Loss 0.9429 (0.8433)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.2%)	
12/22 10:20:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][600/703]	Step 52924	lr 0.01467	Loss 1.0116 (0.8513)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.3%, 95.0%)	
12/22 10:21:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][700/703]	Step 53024	lr 0.01467	Loss 0.8998 (0.8579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.2%, 94.9%)	
12/22 10:21:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [101][703/703]	Step 53027	lr 0.01467	Loss 1.2261 (0.8580)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.1%, 94.9%)	
12/22 10:21:16午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [101/149] Final Prec@1 74.1333%
12/22 10:21:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [101][78/79]	Step 53028	Loss 1.5158	Prec@(1,5) (60.6%, 86.8%)
12/22 10:21:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [101/149] Final Prec@1 60.6000%
12/22 10:21:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.9000%
12/22 10:21:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][100/703]	Step 53128	lr 0.01425	Loss 0.8499 (0.7667)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 95.5%)	
12/22 10:22:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][200/703]	Step 53228	lr 0.01425	Loss 0.9726 (0.7819)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.5%)	
12/22 10:22:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][300/703]	Step 53328	lr 0.01425	Loss 0.7105 (0.7976)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.9%, 95.4%)	
12/22 10:22:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][400/703]	Step 53428	lr 0.01425	Loss 0.7300 (0.8084)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.3%)	
12/22 10:23:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][500/703]	Step 53528	lr 0.01425	Loss 0.9928 (0.8252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.2%)	
12/22 10:23:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][600/703]	Step 53628	lr 0.01425	Loss 1.2039 (0.8292)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.2%)	
12/22 10:23:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][700/703]	Step 53728	lr 0.01425	Loss 0.8258 (0.8395)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.1%)	
12/22 10:23:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [102][703/703]	Step 53731	lr 0.01425	Loss 1.1122 (0.8400)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.6%, 95.1%)	
12/22 10:23:48午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [102/149] Final Prec@1 74.5689%
12/22 10:23:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [102][78/79]	Step 53732	Loss 1.4658	Prec@(1,5) (60.3%, 87.0%)
12/22 10:23:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [102/149] Final Prec@1 60.2600%
12/22 10:23:55午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.9000%
12/22 10:24:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][100/703]	Step 53832	lr 0.01384	Loss 0.6750 (0.7545)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.0%)	
12/22 10:24:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][200/703]	Step 53932	lr 0.01384	Loss 0.7320 (0.7741)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.8%)	
12/22 10:24:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][300/703]	Step 54032	lr 0.01384	Loss 1.0652 (0.7882)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.8%, 95.7%)	
12/22 10:25:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][400/703]	Step 54132	lr 0.01384	Loss 0.9742 (0.8010)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.5%, 95.6%)	
12/22 10:25:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][500/703]	Step 54232	lr 0.01384	Loss 0.7877 (0.8138)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.4%)	
12/22 10:26:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][600/703]	Step 54332	lr 0.01384	Loss 0.7672 (0.8204)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.2%, 95.3%)	
12/22 10:26:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][700/703]	Step 54432	lr 0.01384	Loss 0.6994 (0.8281)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (74.9%, 95.3%)	
12/22 10:26:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [103][703/703]	Step 54435	lr 0.01384	Loss 0.8300 (0.8282)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.0%, 95.2%)	
12/22 10:26:21午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [103/149] Final Prec@1 74.9511%
12/22 10:26:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [103][78/79]	Step 54436	Loss 1.5500	Prec@(1,5) (58.6%, 86.1%)
12/22 10:26:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [103/149] Final Prec@1 58.6200%
12/22 10:26:28午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 60.9000%
12/22 10:26:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][100/703]	Step 54536	lr 0.01342	Loss 0.8991 (0.7371)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.7%, 96.3%)	
12/22 10:27:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][200/703]	Step 54636	lr 0.01342	Loss 0.9125 (0.7638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.0%, 96.0%)	
12/22 10:27:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][300/703]	Step 54736	lr 0.01342	Loss 0.9426 (0.7725)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.9%)	
12/22 10:27:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][400/703]	Step 54836	lr 0.01342	Loss 1.1025 (0.7786)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.9%)	
12/22 10:28:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][500/703]	Step 54936	lr 0.01342	Loss 0.8966 (0.7923)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.7%)	
12/22 10:28:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][600/703]	Step 55036	lr 0.01342	Loss 0.7622 (0.8065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.6%, 95.6%)	
12/22 10:28:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][700/703]	Step 55136	lr 0.01342	Loss 0.7167 (0.8130)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.5%)	
12/22 10:28:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [104][703/703]	Step 55139	lr 0.01342	Loss 1.1527 (0.8134)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (75.3%, 95.5%)	
12/22 10:28:53午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [104/149] Final Prec@1 75.2867%
12/22 10:28:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [104][78/79]	Step 55140	Loss 1.4771	Prec@(1,5) (61.1%, 87.5%)
12/22 10:28:59午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [104/149] Final Prec@1 61.1200%
12/22 10:29:00午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.1200%
12/22 10:29:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][100/703]	Step 55240	lr 0.013	Loss 0.7473 (0.7245)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.3%)	
12/22 10:29:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][200/703]	Step 55340	lr 0.013	Loss 0.9260 (0.7582)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.9%, 96.0%)	
12/22 10:30:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][300/703]	Step 55440	lr 0.013	Loss 0.8990 (0.7635)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.6%, 95.9%)	
12/22 10:30:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][400/703]	Step 55540	lr 0.013	Loss 0.8188 (0.7699)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.4%, 95.9%)	
12/22 10:30:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][500/703]	Step 55640	lr 0.013	Loss 0.9468 (0.7720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.3%, 95.9%)	
12/22 10:31:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][600/703]	Step 55740	lr 0.013	Loss 0.9736 (0.7814)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.1%, 95.8%)	
12/22 10:31:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][700/703]	Step 55840	lr 0.013	Loss 0.6693 (0.7854)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.7%)	
12/22 10:31:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [105][703/703]	Step 55843	lr 0.013	Loss 0.6870 (0.7856)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.0%, 95.7%)	
12/22 10:31:29午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [105/149] Final Prec@1 75.9600%
12/22 10:31:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [105][78/79]	Step 55844	Loss 1.4409	Prec@(1,5) (61.5%, 87.4%)
12/22 10:31:35午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [105/149] Final Prec@1 61.5600%
12/22 10:31:35午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.5600%
12/22 10:31:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][100/703]	Step 55944	lr 0.01258	Loss 0.6830 (0.7255)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.2%)	
12/22 10:32:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][200/703]	Step 56044	lr 0.01258	Loss 0.8337 (0.7380)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.3%)	
12/22 10:32:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][300/703]	Step 56144	lr 0.01258	Loss 0.7756 (0.7543)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.8%, 96.1%)	
12/22 10:32:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][400/703]	Step 56244	lr 0.01258	Loss 0.9412 (0.7620)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.7%, 96.0%)	
12/22 10:33:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][500/703]	Step 56344	lr 0.01258	Loss 0.6830 (0.7676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 95.9%)	
12/22 10:33:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][600/703]	Step 56444	lr 0.01258	Loss 0.8259 (0.7710)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.5%, 96.0%)	
12/22 10:34:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][700/703]	Step 56544	lr 0.01258	Loss 0.8941 (0.7772)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.9%)	
12/22 10:34:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [106][703/703]	Step 56547	lr 0.01258	Loss 1.0941 (0.7784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (76.2%, 95.9%)	
12/22 10:34:01午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [106/149] Final Prec@1 76.1978%
12/22 10:34:08午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [106][78/79]	Step 56548	Loss 1.4777	Prec@(1,5) (61.5%, 87.2%)
12/22 10:34:08午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [106/149] Final Prec@1 61.4800%
12/22 10:34:08午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.5600%
12/22 10:34:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][100/703]	Step 56648	lr 0.01216	Loss 0.6923 (0.6857)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 97.0%)	
12/22 10:34:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][200/703]	Step 56748	lr 0.01216	Loss 0.6646 (0.7087)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.6%)	
12/22 10:35:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][300/703]	Step 56848	lr 0.01216	Loss 0.8200 (0.7126)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.6%)	
12/22 10:35:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][400/703]	Step 56948	lr 0.01216	Loss 0.5104 (0.7272)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.8%, 96.5%)	
12/22 10:35:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][500/703]	Step 57048	lr 0.01216	Loss 0.6649 (0.7344)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.5%, 96.4%)	
12/22 10:36:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][600/703]	Step 57148	lr 0.01216	Loss 0.7321 (0.7437)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.2%, 96.3%)	
12/22 10:36:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][700/703]	Step 57248	lr 0.01216	Loss 0.8934 (0.7509)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.2%)	
12/22 10:36:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [107][703/703]	Step 57251	lr 0.01216	Loss 0.5648 (0.7509)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.1%, 96.2%)	
12/22 10:36:33午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [107/149] Final Prec@1 77.0733%
12/22 10:36:40午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [107][78/79]	Step 57252	Loss 1.4992	Prec@(1,5) (60.9%, 87.7%)
12/22 10:36:40午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [107/149] Final Prec@1 60.8800%
12/22 10:36:40午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.5600%
12/22 10:37:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][100/703]	Step 57352	lr 0.01175	Loss 0.4263 (0.6564)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.2%)	
12/22 10:37:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][200/703]	Step 57452	lr 0.01175	Loss 0.7316 (0.6712)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 97.0%)	
12/22 10:37:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][300/703]	Step 57552	lr 0.01175	Loss 0.7349 (0.6978)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.6%, 96.7%)	
12/22 10:38:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][400/703]	Step 57652	lr 0.01175	Loss 0.7468 (0.7070)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.7%)	
12/22 10:38:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][500/703]	Step 57752	lr 0.01175	Loss 0.7999 (0.7213)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.5%)	
12/22 10:38:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][600/703]	Step 57852	lr 0.01175	Loss 0.6281 (0.7296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.6%, 96.4%)	
12/22 10:39:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][700/703]	Step 57952	lr 0.01175	Loss 0.6311 (0.7380)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.3%)	
12/22 10:39:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [108][703/703]	Step 57955	lr 0.01175	Loss 0.5837 (0.7383)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.4%, 96.3%)	
12/22 10:39:06午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [108/149] Final Prec@1 77.3600%
12/22 10:39:12午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [108][78/79]	Step 57956	Loss 1.5056	Prec@(1,5) (61.0%, 87.4%)
12/22 10:39:12午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [108/149] Final Prec@1 60.9400%
12/22 10:39:12午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.5600%
12/22 10:39:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][100/703]	Step 58056	lr 0.01133	Loss 0.6001 (0.6623)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
12/22 10:39:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][200/703]	Step 58156	lr 0.01133	Loss 0.6608 (0.6807)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.8%)	
12/22 10:40:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][300/703]	Step 58256	lr 0.01133	Loss 0.8359 (0.6929)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.5%, 96.6%)	
12/22 10:40:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][400/703]	Step 58356	lr 0.01133	Loss 0.6010 (0.6976)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.3%, 96.6%)	
12/22 10:40:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][500/703]	Step 58456	lr 0.01133	Loss 0.8933 (0.7002)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.6%)	
12/22 10:41:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][600/703]	Step 58556	lr 0.01133	Loss 0.6176 (0.7138)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.1%, 96.5%)	
12/22 10:41:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][700/703]	Step 58656	lr 0.01133	Loss 0.6890 (0.7197)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
12/22 10:41:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [109][703/703]	Step 58659	lr 0.01133	Loss 1.0269 (0.7200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (77.9%, 96.4%)	
12/22 10:41:38午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [109/149] Final Prec@1 77.8778%
12/22 10:41:45午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [109][78/79]	Step 58660	Loss 1.4781	Prec@(1,5) (61.4%, 87.9%)
12/22 10:41:45午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [109/149] Final Prec@1 61.4000%
12/22 10:41:45午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 61.5600%
12/22 10:42:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][100/703]	Step 58760	lr 0.01092	Loss 0.8299 (0.6605)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.0%)	
12/22 10:42:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][200/703]	Step 58860	lr 0.01092	Loss 0.6914 (0.6462)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.1%)	
12/22 10:42:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][300/703]	Step 58960	lr 0.01092	Loss 0.6468 (0.6674)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 96.9%)	
12/22 10:43:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][400/703]	Step 59060	lr 0.01092	Loss 0.8201 (0.6754)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.3%, 96.8%)	
12/22 10:43:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][500/703]	Step 59160	lr 0.01092	Loss 0.8152 (0.6840)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
12/22 10:43:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][600/703]	Step 59260	lr 0.01092	Loss 0.5642 (0.6887)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.8%, 96.7%)	
12/22 10:44:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][700/703]	Step 59360	lr 0.01092	Loss 0.4815 (0.6996)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.6%)	
12/22 10:44:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [110][703/703]	Step 59363	lr 0.01092	Loss 0.7693 (0.6995)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.4%, 96.6%)	
12/22 10:44:10午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [110/149] Final Prec@1 78.3733%
12/22 10:44:17午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [110][78/79]	Step 59364	Loss 1.4260	Prec@(1,5) (62.5%, 88.5%)
12/22 10:44:17午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [110/149] Final Prec@1 62.4000%
12/22 10:44:17午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.4000%
12/22 10:44:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][100/703]	Step 59464	lr 0.01051	Loss 0.7740 (0.6473)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 97.1%)	
12/22 10:44:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][200/703]	Step 59564	lr 0.01051	Loss 0.5229 (0.6543)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.8%, 97.0%)	
12/22 10:45:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][300/703]	Step 59664	lr 0.01051	Loss 0.7165 (0.6586)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
12/22 10:45:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][400/703]	Step 59764	lr 0.01051	Loss 0.6856 (0.6590)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.7%, 97.0%)	
12/22 10:46:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][500/703]	Step 59864	lr 0.01051	Loss 0.7479 (0.6662)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.4%, 96.9%)	
12/22 10:46:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][600/703]	Step 59964	lr 0.01051	Loss 0.7868 (0.6741)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.2%, 96.9%)	
12/22 10:46:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][700/703]	Step 60064	lr 0.01051	Loss 0.7802 (0.6853)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
12/22 10:46:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [111][703/703]	Step 60067	lr 0.01051	Loss 0.5813 (0.6850)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (78.9%, 96.7%)	
12/22 10:46:43午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [111/149] Final Prec@1 78.8622%
12/22 10:46:49午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [111][78/79]	Step 60068	Loss 1.5002	Prec@(1,5) (60.2%, 87.4%)
12/22 10:46:50午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [111/149] Final Prec@1 60.1400%
12/22 10:46:50午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.4000%
12/22 10:47:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][100/703]	Step 60168	lr 0.0101	Loss 0.9196 (0.6137)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.6%)	
12/22 10:47:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][200/703]	Step 60268	lr 0.0101	Loss 0.6895 (0.6198)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.4%)	
12/22 10:47:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][300/703]	Step 60368	lr 0.0101	Loss 0.6466 (0.6290)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.7%, 97.3%)	
12/22 10:48:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][400/703]	Step 60468	lr 0.0101	Loss 0.6511 (0.6361)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.1%)	
12/22 10:48:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][500/703]	Step 60568	lr 0.0101	Loss 0.8310 (0.6447)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.1%)	
12/22 10:48:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][600/703]	Step 60668	lr 0.0101	Loss 0.8436 (0.6490)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.2%, 97.1%)	
12/22 10:49:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][700/703]	Step 60768	lr 0.0101	Loss 0.7215 (0.6571)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
12/22 10:49:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [112][703/703]	Step 60771	lr 0.0101	Loss 0.3884 (0.6569)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (79.9%, 97.0%)	
12/22 10:49:16午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [112/149] Final Prec@1 79.8689%
12/22 10:49:23午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [112][78/79]	Step 60772	Loss 1.5418	Prec@(1,5) (60.4%, 86.7%)
12/22 10:49:23午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [112/149] Final Prec@1 60.3200%
12/22 10:49:23午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.4000%
12/22 10:49:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][100/703]	Step 60872	lr 0.00969	Loss 0.5377 (0.5859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.7%)	
12/22 10:50:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][200/703]	Step 60972	lr 0.00969	Loss 0.8298 (0.5912)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.3%, 97.8%)	
12/22 10:50:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][300/703]	Step 61072	lr 0.00969	Loss 0.8479 (0.6115)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.4%)	
12/22 10:50:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][400/703]	Step 61172	lr 0.00969	Loss 0.4385 (0.6205)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.6%, 97.3%)	
12/22 10:51:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][500/703]	Step 61272	lr 0.00969	Loss 0.6728 (0.6322)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.3%, 97.2%)	
12/22 10:51:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][600/703]	Step 61372	lr 0.00969	Loss 0.7932 (0.6404)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.1%)	
12/22 10:51:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][700/703]	Step 61472	lr 0.00969	Loss 0.7369 (0.6439)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.1%)	
12/22 10:51:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [113][703/703]	Step 61475	lr 0.00969	Loss 0.5283 (0.6436)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.2%)	
12/22 10:51:49午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [113/149] Final Prec@1 80.0089%
12/22 10:51:55午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [113][78/79]	Step 61476	Loss 1.4470	Prec@(1,5) (62.5%, 88.4%)
12/22 10:51:55午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [113/149] Final Prec@1 62.5600%
12/22 10:51:56午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.5600%
12/22 10:52:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][100/703]	Step 61576	lr 0.00929	Loss 0.6858 (0.5903)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.6%)	
12/22 10:52:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][200/703]	Step 61676	lr 0.00929	Loss 0.4890 (0.5927)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.5%)	
12/22 10:52:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][300/703]	Step 61776	lr 0.00929	Loss 0.4958 (0.6017)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.4%)	
12/22 10:53:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][400/703]	Step 61876	lr 0.00929	Loss 0.6341 (0.6098)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.0%, 97.4%)	
12/22 10:53:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][500/703]	Step 61976	lr 0.00929	Loss 0.6862 (0.6145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.8%, 97.4%)	
12/22 10:54:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][600/703]	Step 62076	lr 0.00929	Loss 0.4806 (0.6238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.4%, 97.3%)	
12/22 10:54:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][700/703]	Step 62176	lr 0.00929	Loss 0.6448 (0.6355)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.1%, 97.2%)	
12/22 10:54:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [114][703/703]	Step 62179	lr 0.00929	Loss 0.6290 (0.6363)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (80.0%, 97.2%)	
12/22 10:54:22午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [114/149] Final Prec@1 80.0244%
12/22 10:54:29午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [114][78/79]	Step 62180	Loss 1.4389	Prec@(1,5) (62.8%, 88.3%)
12/22 10:54:29午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [114/149] Final Prec@1 62.7800%
12/22 10:54:29午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.7800%
12/22 10:54:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][100/703]	Step 62280	lr 0.0089	Loss 0.5634 (0.5538)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.9%)	
12/22 10:55:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][200/703]	Step 62380	lr 0.0089	Loss 0.4727 (0.5558)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 98.0%)	
12/22 10:55:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][300/703]	Step 62480	lr 0.0089	Loss 0.5618 (0.5721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.9%)	
12/22 10:55:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][400/703]	Step 62580	lr 0.0089	Loss 0.4617 (0.5793)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.9%, 97.8%)	
12/22 10:56:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][500/703]	Step 62680	lr 0.0089	Loss 0.8168 (0.5943)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.4%, 97.6%)	
12/22 10:56:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][600/703]	Step 62780	lr 0.0089	Loss 0.6339 (0.5998)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.2%, 97.6%)	
12/22 10:56:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][700/703]	Step 62880	lr 0.0089	Loss 0.6910 (0.6059)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.5%)	
12/22 10:56:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [115][703/703]	Step 62883	lr 0.0089	Loss 0.6121 (0.6057)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (81.1%, 97.5%)	
12/22 10:56:56午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [115/149] Final Prec@1 81.1044%
12/22 10:57:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [115][78/79]	Step 62884	Loss 1.5170	Prec@(1,5) (61.3%, 88.0%)
12/22 10:57:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [115/149] Final Prec@1 61.2800%
12/22 10:57:02午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 62.7800%
12/22 10:57:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][100/703]	Step 62984	lr 0.0085	Loss 0.5261 (0.5236)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.0%)	
12/22 10:57:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][200/703]	Step 63084	lr 0.0085	Loss 0.5200 (0.5421)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 98.0%)	
12/22 10:58:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][300/703]	Step 63184	lr 0.0085	Loss 0.4848 (0.5488)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 97.8%)	
12/22 10:58:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][400/703]	Step 63284	lr 0.0085	Loss 0.4787 (0.5565)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 97.8%)	
12/22 10:58:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][500/703]	Step 63384	lr 0.0085	Loss 0.6405 (0.5638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.6%, 97.7%)	
12/22 10:59:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][600/703]	Step 63484	lr 0.0085	Loss 0.6332 (0.5738)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.3%, 97.7%)	
12/22 10:59:28午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][700/703]	Step 63584	lr 0.0085	Loss 0.6179 (0.5798)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.1%, 97.6%)	
12/22 10:59:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [116][703/703]	Step 63587	lr 0.0085	Loss 0.9174 (0.5807)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.0%, 97.6%)	
12/22 10:59:29午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [116/149] Final Prec@1 82.0333%
12/22 10:59:35午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [116][78/79]	Step 63588	Loss 1.4269	Prec@(1,5) (63.5%, 89.0%)
12/22 10:59:36午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [116/149] Final Prec@1 63.5200%
12/22 10:59:36午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5200%
12/22 10:59:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][100/703]	Step 63688	lr 0.00812	Loss 0.5067 (0.5180)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.0%)	
12/22 11:00:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][200/703]	Step 63788	lr 0.00812	Loss 0.6377 (0.5420)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 97.9%)	
12/22 11:00:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][300/703]	Step 63888	lr 0.00812	Loss 0.5595 (0.5457)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.2%, 97.9%)	
12/22 11:01:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][400/703]	Step 63988	lr 0.00812	Loss 0.5625 (0.5491)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.1%, 97.9%)	
12/22 11:01:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][500/703]	Step 64088	lr 0.00812	Loss 0.4351 (0.5550)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.9%, 97.8%)	
12/22 11:01:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][600/703]	Step 64188	lr 0.00812	Loss 0.8107 (0.5638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.5%, 97.8%)	
12/22 11:02:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][700/703]	Step 64288	lr 0.00812	Loss 0.9830 (0.5717)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
12/22 11:02:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [117][703/703]	Step 64291	lr 0.00812	Loss 0.6982 (0.5720)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.2%, 97.7%)	
12/22 11:02:03午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [117/149] Final Prec@1 82.2200%
12/22 11:02:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [117][78/79]	Step 64292	Loss 1.4335	Prec@(1,5) (62.7%, 88.5%)
12/22 11:02:10午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [117/149] Final Prec@1 62.7400%
12/22 11:02:10午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5200%
12/22 11:02:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][100/703]	Step 64392	lr 0.00774	Loss 0.6985 (0.5222)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.7%, 98.3%)	
12/22 11:02:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][200/703]	Step 64492	lr 0.00774	Loss 0.5923 (0.5182)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.3%)	
12/22 11:03:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][300/703]	Step 64592	lr 0.00774	Loss 0.5537 (0.5209)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.8%, 98.2%)	
12/22 11:03:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][400/703]	Step 64692	lr 0.00774	Loss 0.7507 (0.5296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.2%)	
12/22 11:03:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][500/703]	Step 64792	lr 0.00774	Loss 0.4674 (0.5348)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.3%, 98.1%)	
12/22 11:04:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][600/703]	Step 64892	lr 0.00774	Loss 0.5652 (0.5429)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.0%, 98.0%)	
12/22 11:04:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][700/703]	Step 64992	lr 0.00774	Loss 0.4761 (0.5476)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 98.0%)	
12/22 11:04:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [118][703/703]	Step 64995	lr 0.00774	Loss 0.4015 (0.5472)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (82.8%, 98.0%)	
12/22 11:04:35午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [118/149] Final Prec@1 82.7822%
12/22 11:04:42午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [118][78/79]	Step 64996	Loss 1.4668	Prec@(1,5) (63.4%, 89.1%)
12/22 11:04:42午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [118/149] Final Prec@1 63.4600%
12/22 11:04:42午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5200%
12/22 11:05:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][100/703]	Step 65096	lr 0.00737	Loss 0.4672 (0.4907)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.6%)	
12/22 11:05:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][200/703]	Step 65196	lr 0.00737	Loss 0.3687 (0.4920)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.8%, 98.5%)	
12/22 11:05:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][300/703]	Step 65296	lr 0.00737	Loss 0.6740 (0.5003)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.4%)	
12/22 11:06:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][400/703]	Step 65396	lr 0.00737	Loss 0.3436 (0.5045)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.3%, 98.4%)	
12/22 11:06:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][500/703]	Step 65496	lr 0.00737	Loss 0.4923 (0.5116)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.3%)	
12/22 11:06:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][600/703]	Step 65596	lr 0.00737	Loss 0.5621 (0.5219)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.6%, 98.2%)	
12/22 11:07:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][700/703]	Step 65696	lr 0.00737	Loss 0.3407 (0.5296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.1%)	
12/22 11:07:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [119][703/703]	Step 65699	lr 0.00737	Loss 0.4128 (0.5295)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (83.5%, 98.1%)	
12/22 11:07:09午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [119/149] Final Prec@1 83.4867%
12/22 11:07:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [119][78/79]	Step 65700	Loss 1.4273	Prec@(1,5) (62.9%, 89.0%)
12/22 11:07:15午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [119/149] Final Prec@1 62.8600%
12/22 11:07:15午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.5200%
12/22 11:07:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][100/703]	Step 65800	lr 0.007	Loss 0.2814 (0.4636)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.5%)	
12/22 11:07:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][200/703]	Step 65900	lr 0.007	Loss 0.5134 (0.4752)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.5%)	
12/22 11:08:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][300/703]	Step 66000	lr 0.007	Loss 0.7405 (0.4859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.5%, 98.4%)	
12/22 11:08:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][400/703]	Step 66100	lr 0.007	Loss 0.3292 (0.4915)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
12/22 11:09:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][500/703]	Step 66200	lr 0.007	Loss 0.5000 (0.4943)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.4%, 98.3%)	
12/22 11:09:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][600/703]	Step 66300	lr 0.007	Loss 0.6107 (0.5031)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.1%, 98.2%)	
12/22 11:09:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][700/703]	Step 66400	lr 0.007	Loss 0.6896 (0.5078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.2%)	
12/22 11:09:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [120][703/703]	Step 66403	lr 0.007	Loss 0.5489 (0.5078)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.0%, 98.2%)	
12/22 11:09:43午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [120/149] Final Prec@1 84.0156%
12/22 11:09:49午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [120][78/79]	Step 66404	Loss 1.4574	Prec@(1,5) (63.7%, 88.8%)
12/22 11:09:49午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [120/149] Final Prec@1 63.7200%
12/22 11:09:49午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.7200%
12/22 11:10:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][100/703]	Step 66504	lr 0.00664	Loss 0.5236 (0.4811)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.6%)	
12/22 11:10:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][200/703]	Step 66604	lr 0.00664	Loss 0.3364 (0.4679)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.5%)	
12/22 11:10:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][300/703]	Step 66704	lr 0.00664	Loss 0.3487 (0.4676)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.4%)	
12/22 11:11:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][400/703]	Step 66804	lr 0.00664	Loss 0.3946 (0.4735)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.5%, 98.4%)	
12/22 11:11:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][500/703]	Step 66904	lr 0.00664	Loss 0.6829 (0.4784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.3%, 98.4%)	
12/22 11:11:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][600/703]	Step 67004	lr 0.00664	Loss 0.5344 (0.4861)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.0%, 98.3%)	
12/22 11:12:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][700/703]	Step 67104	lr 0.00664	Loss 0.4386 (0.4937)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.3%)	
12/22 11:12:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [121][703/703]	Step 67107	lr 0.00664	Loss 0.4840 (0.4940)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (84.7%, 98.3%)	
12/22 11:12:15午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [121/149] Final Prec@1 84.6489%
12/22 11:12:22午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [121][78/79]	Step 67108	Loss 1.4017	Prec@(1,5) (63.9%, 89.1%)
12/22 11:12:22午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [121/149] Final Prec@1 63.9000%
12/22 11:12:22午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.9000%
12/22 11:12:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][100/703]	Step 67208	lr 0.00629	Loss 0.4457 (0.4132)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 99.0%)	
12/22 11:13:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][200/703]	Step 67308	lr 0.00629	Loss 0.6289 (0.4216)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
12/22 11:13:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][300/703]	Step 67408	lr 0.00629	Loss 0.5851 (0.4451)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.7%)	
12/22 11:13:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][400/703]	Step 67508	lr 0.00629	Loss 0.4182 (0.4523)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.6%)	
12/22 11:14:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][500/703]	Step 67608	lr 0.00629	Loss 0.2822 (0.4553)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.0%, 98.6%)	
12/22 11:14:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][600/703]	Step 67708	lr 0.00629	Loss 0.5904 (0.4624)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.8%, 98.5%)	
12/22 11:14:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][700/703]	Step 67808	lr 0.00629	Loss 0.4823 (0.4664)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.5%)	
12/22 11:14:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [122][703/703]	Step 67811	lr 0.00629	Loss 0.7473 (0.4666)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.5%)	
12/22 11:14:48午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [122/149] Final Prec@1 85.6244%
12/22 11:14:54午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [122][78/79]	Step 67812	Loss 1.4374	Prec@(1,5) (63.6%, 88.9%)
12/22 11:14:54午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [122/149] Final Prec@1 63.6600%
12/22 11:14:54午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 63.9000%
12/22 11:15:16午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][100/703]	Step 67912	lr 0.00595	Loss 0.4257 (0.4180)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.7%, 99.0%)	
12/22 11:15:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][200/703]	Step 68012	lr 0.00595	Loss 0.2695 (0.4296)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.4%, 98.9%)	
12/22 11:15:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][300/703]	Step 68112	lr 0.00595	Loss 0.4082 (0.4367)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.2%, 98.7%)	
12/22 11:16:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][400/703]	Step 68212	lr 0.00595	Loss 0.3618 (0.4414)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.1%, 98.7%)	
12/22 11:16:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][500/703]	Step 68312	lr 0.00595	Loss 0.5588 (0.4478)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.7%)	
12/22 11:16:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][600/703]	Step 68412	lr 0.00595	Loss 0.5245 (0.4505)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.9%, 98.7%)	
12/22 11:17:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][700/703]	Step 68512	lr 0.00595	Loss 0.3081 (0.4558)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.7%, 98.7%)	
12/22 11:17:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [123][703/703]	Step 68515	lr 0.00595	Loss 0.5627 (0.4561)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (85.6%, 98.7%)	
12/22 11:17:20午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [123/149] Final Prec@1 85.6333%
12/22 11:17:27午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [123][78/79]	Step 68516	Loss 1.4446	Prec@(1,5) (64.1%, 89.2%)
12/22 11:17:27午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [123/149] Final Prec@1 64.0800%
12/22 11:17:27午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.0800%
12/22 11:17:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][100/703]	Step 68616	lr 0.00561	Loss 0.3548 (0.4089)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.0%, 98.8%)	
12/22 11:18:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][200/703]	Step 68716	lr 0.00561	Loss 0.3661 (0.4065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.9%)	
12/22 11:18:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][300/703]	Step 68816	lr 0.00561	Loss 0.5580 (0.4033)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 98.9%)	
12/22 11:18:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][400/703]	Step 68916	lr 0.00561	Loss 0.4836 (0.4135)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.9%)	
12/22 11:19:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][500/703]	Step 69016	lr 0.00561	Loss 0.6198 (0.4197)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.9%, 98.8%)	
12/22 11:19:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][600/703]	Step 69116	lr 0.00561	Loss 0.3749 (0.4254)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.8%, 98.8%)	
12/22 11:19:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][700/703]	Step 69216	lr 0.00561	Loss 0.5038 (0.4286)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.8%)	
12/22 11:19:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [124][703/703]	Step 69219	lr 0.00561	Loss 0.3789 (0.4285)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (86.6%, 98.8%)	
12/22 11:19:53午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [124/149] Final Prec@1 86.6156%
12/22 11:19:59午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [124][78/79]	Step 69220	Loss 1.4392	Prec@(1,5) (64.4%, 88.8%)
12/22 11:20:00午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [124/149] Final Prec@1 64.4200%
12/22 11:20:00午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4200%
12/22 11:20:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][100/703]	Step 69320	lr 0.00529	Loss 0.3058 (0.3868)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 99.0%)	
12/22 11:20:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][200/703]	Step 69420	lr 0.00529	Loss 0.3465 (0.3865)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.8%, 99.1%)	
12/22 11:21:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][300/703]	Step 69520	lr 0.00529	Loss 0.3604 (0.3925)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 99.0%)	
12/22 11:21:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][400/703]	Step 69620	lr 0.00529	Loss 0.4613 (0.3967)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.7%, 99.0%)	
12/22 11:21:44午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][500/703]	Step 69720	lr 0.00529	Loss 0.5544 (0.4025)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.5%, 99.0%)	
12/22 11:22:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][600/703]	Step 69820	lr 0.00529	Loss 0.3245 (0.4065)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.4%, 98.9%)	
12/22 11:22:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][700/703]	Step 69920	lr 0.00529	Loss 0.2943 (0.4111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.9%)	
12/22 11:22:26午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [125][703/703]	Step 69923	lr 0.00529	Loss 0.2706 (0.4111)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.2%, 98.9%)	
12/22 11:22:26午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [125/149] Final Prec@1 87.1533%
12/22 11:22:33午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [125][78/79]	Step 69924	Loss 1.4501	Prec@(1,5) (64.4%, 89.0%)
12/22 11:22:33午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [125/149] Final Prec@1 64.3800%
12/22 11:22:33午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 64.4200%
12/22 11:22:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][100/703]	Step 70024	lr 0.00497	Loss 0.3157 (0.3704)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.8%, 99.2%)	
12/22 11:23:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][200/703]	Step 70124	lr 0.00497	Loss 0.4504 (0.3704)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.5%, 99.2%)	
12/22 11:23:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][300/703]	Step 70224	lr 0.00497	Loss 0.4944 (0.3744)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.2%)	
12/22 11:23:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][400/703]	Step 70324	lr 0.00497	Loss 0.3161 (0.3764)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.2%, 99.1%)	
12/22 11:24:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][500/703]	Step 70424	lr 0.00497	Loss 0.4957 (0.3834)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.0%, 99.1%)	
12/22 11:24:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][600/703]	Step 70524	lr 0.00497	Loss 0.3554 (0.3867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.9%, 99.1%)	
12/22 11:24:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][700/703]	Step 70624	lr 0.00497	Loss 0.5140 (0.3917)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.7%, 99.1%)	
12/22 11:24:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [126][703/703]	Step 70627	lr 0.00497	Loss 0.5717 (0.3921)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (87.7%, 99.0%)	
12/22 11:24:58午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [126/149] Final Prec@1 87.7156%
12/22 11:25:05午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [126][78/79]	Step 70628	Loss 1.3938	Prec@(1,5) (65.2%, 89.6%)
12/22 11:25:05午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [126/149] Final Prec@1 65.1800%
12/22 11:25:05午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.1800%
12/22 11:25:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][100/703]	Step 70728	lr 0.00466	Loss 0.3173 (0.3401)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.5%)	
12/22 11:25:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][200/703]	Step 70828	lr 0.00466	Loss 0.3008 (0.3469)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.4%)	
12/22 11:26:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][300/703]	Step 70928	lr 0.00466	Loss 0.3325 (0.3508)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.3%, 99.3%)	
12/22 11:26:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][400/703]	Step 71028	lr 0.00466	Loss 0.4481 (0.3582)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.0%, 99.2%)	
12/22 11:26:49午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][500/703]	Step 71128	lr 0.00466	Loss 0.3944 (0.3637)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.8%, 99.2%)	
12/22 11:27:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][600/703]	Step 71228	lr 0.00466	Loss 0.3456 (0.3685)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.6%, 99.2%)	
12/22 11:27:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][700/703]	Step 71328	lr 0.00466	Loss 0.5721 (0.3730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/22 11:27:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [127][703/703]	Step 71331	lr 0.00466	Loss 0.4237 (0.3730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (88.4%, 99.1%)	
12/22 11:27:31午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [127/149] Final Prec@1 88.3600%
12/22 11:27:38午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [127][78/79]	Step 71332	Loss 1.4022	Prec@(1,5) (65.6%, 89.2%)
12/22 11:27:38午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [127/149] Final Prec@1 65.6000%
12/22 11:27:38午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6000%
12/22 11:28:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][100/703]	Step 71432	lr 0.00437	Loss 0.4618 (0.3381)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.2%)	
12/22 11:28:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][200/703]	Step 71532	lr 0.00437	Loss 0.4652 (0.3407)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.8%, 99.2%)	
12/22 11:28:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][300/703]	Step 71632	lr 0.00437	Loss 0.4633 (0.3417)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.3%)	
12/22 11:29:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][400/703]	Step 71732	lr 0.00437	Loss 0.3640 (0.3423)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.3%)	
12/22 11:29:22午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][500/703]	Step 71832	lr 0.00437	Loss 0.2005 (0.3465)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.2%)	
12/22 11:29:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][600/703]	Step 71932	lr 0.00437	Loss 0.2808 (0.3500)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.4%, 99.3%)	
12/22 11:30:03午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][700/703]	Step 72032	lr 0.00437	Loss 0.3326 (0.3542)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
12/22 11:30:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [128][703/703]	Step 72035	lr 0.00437	Loss 0.2268 (0.3541)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.2%, 99.2%)	
12/22 11:30:04午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [128/149] Final Prec@1 89.2200%
12/22 11:30:10午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [128][78/79]	Step 72036	Loss 1.4012	Prec@(1,5) (65.3%, 89.6%)
12/22 11:30:10午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [128/149] Final Prec@1 65.2800%
12/22 11:30:10午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6000%
12/22 11:30:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][100/703]	Step 72136	lr 0.00408	Loss 0.5113 (0.3071)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.4%, 99.5%)	
12/22 11:30:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][200/703]	Step 72236	lr 0.00408	Loss 0.4696 (0.3145)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.5%)	
12/22 11:31:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][300/703]	Step 72336	lr 0.00408	Loss 0.6249 (0.3217)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.4%)	
12/22 11:31:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][400/703]	Step 72436	lr 0.00408	Loss 0.4014 (0.3260)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.0%, 99.4%)	
12/22 11:31:54午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][500/703]	Step 72536	lr 0.00408	Loss 0.3338 (0.3342)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.6%, 99.4%)	
12/22 11:32:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][600/703]	Step 72636	lr 0.00408	Loss 0.1421 (0.3362)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.3%)	
12/22 11:32:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][700/703]	Step 72736	lr 0.00408	Loss 0.2045 (0.3387)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.3%)	
12/22 11:32:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [129][703/703]	Step 72739	lr 0.00408	Loss 0.5326 (0.3391)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.5%, 99.3%)	
12/22 11:32:36午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [129/149] Final Prec@1 89.4667%
12/22 11:32:43午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [129][78/79]	Step 72740	Loss 1.4242	Prec@(1,5) (64.6%, 89.5%)
12/22 11:32:43午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [129/149] Final Prec@1 64.6600%
12/22 11:32:43午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6000%
12/22 11:33:05午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][100/703]	Step 72840	lr 0.00381	Loss 0.2426 (0.3077)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.4%)	
12/22 11:33:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][200/703]	Step 72940	lr 0.00381	Loss 0.2715 (0.3006)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.5%)	
12/22 11:33:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][300/703]	Step 73040	lr 0.00381	Loss 0.2938 (0.3113)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.5%, 99.5%)	
12/22 11:34:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][400/703]	Step 73140	lr 0.00381	Loss 0.5889 (0.3185)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.3%, 99.4%)	
12/22 11:34:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][500/703]	Step 73240	lr 0.00381	Loss 0.4603 (0.3200)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.4%)	
12/22 11:34:47午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][600/703]	Step 73340	lr 0.00381	Loss 0.3003 (0.3232)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.2%, 99.4%)	
12/22 11:35:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][700/703]	Step 73440	lr 0.00381	Loss 0.4083 (0.3284)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
12/22 11:35:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [130][703/703]	Step 73443	lr 0.00381	Loss 0.3864 (0.3286)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (89.9%, 99.3%)	
12/22 11:35:09午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [130/149] Final Prec@1 89.9356%
12/22 11:35:15午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [130][78/79]	Step 73444	Loss 1.3954	Prec@(1,5) (65.4%, 89.7%)
12/22 11:35:15午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [130/149] Final Prec@1 65.3400%
12/22 11:35:15午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.6000%
12/22 11:35:37午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][100/703]	Step 73544	lr 0.00354	Loss 0.2988 (0.2745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.6%)	
12/22 11:35:57午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][200/703]	Step 73644	lr 0.00354	Loss 0.1954 (0.2805)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.5%, 99.6%)	
12/22 11:36:18午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][300/703]	Step 73744	lr 0.00354	Loss 0.2151 (0.2808)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.6%)	
12/22 11:36:38午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][400/703]	Step 73844	lr 0.00354	Loss 0.2927 (0.2920)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
12/22 11:36:59午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][500/703]	Step 73944	lr 0.00354	Loss 0.4035 (0.2963)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.0%, 99.5%)	
12/22 11:37:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][600/703]	Step 74044	lr 0.00354	Loss 0.6761 (0.2999)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
12/22 11:37:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][700/703]	Step 74144	lr 0.00354	Loss 0.3949 (0.3016)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
12/22 11:37:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [131][703/703]	Step 74147	lr 0.00354	Loss 0.2137 (0.3017)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (90.9%, 99.4%)	
12/22 11:37:41午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [131/149] Final Prec@1 90.8511%
12/22 11:37:47午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [131][78/79]	Step 74148	Loss 1.4060	Prec@(1,5) (65.7%, 90.0%)
12/22 11:37:47午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [131/149] Final Prec@1 65.7400%
12/22 11:37:48午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.7400%
12/22 11:38:10午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][100/703]	Step 74248	lr 0.00329	Loss 0.2458 (0.2721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.5%)	
12/22 11:38:30午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][200/703]	Step 74348	lr 0.00329	Loss 0.4064 (0.2784)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.5%)	
12/22 11:38:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][300/703]	Step 74448	lr 0.00329	Loss 0.2671 (0.2824)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.5%)	
12/22 11:39:11午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][400/703]	Step 74548	lr 0.00329	Loss 0.2259 (0.2859)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.4%, 99.5%)	
12/22 11:39:32午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][500/703]	Step 74648	lr 0.00329	Loss 0.3138 (0.2921)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.3%, 99.5%)	
12/22 11:39:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][600/703]	Step 74748	lr 0.00329	Loss 0.2873 (0.2928)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.2%, 99.5%)	
12/22 11:40:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][700/703]	Step 74848	lr 0.00329	Loss 0.4900 (0.2964)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
12/22 11:40:13午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [132][703/703]	Step 74851	lr 0.00329	Loss 0.3793 (0.2968)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.1%, 99.4%)	
12/22 11:40:13午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [132/149] Final Prec@1 91.0600%
12/22 11:40:20午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [132][78/79]	Step 74852	Loss 1.4199	Prec@(1,5) (65.7%, 89.4%)
12/22 11:40:20午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [132/149] Final Prec@1 65.7200%
12/22 11:40:20午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.7400%
12/22 11:40:42午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][100/703]	Step 74952	lr 0.00305	Loss 0.5103 (0.2625)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.7%)	
12/22 11:41:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][200/703]	Step 75052	lr 0.00305	Loss 0.3516 (0.2707)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.6%)	
12/22 11:41:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][300/703]	Step 75152	lr 0.00305	Loss 0.3535 (0.2694)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.0%, 99.6%)	
12/22 11:41:43午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][400/703]	Step 75252	lr 0.00305	Loss 0.2793 (0.2708)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.9%, 99.6%)	
12/22 11:42:04午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][500/703]	Step 75352	lr 0.00305	Loss 0.3187 (0.2745)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.8%, 99.6%)	
12/22 11:42:24午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][600/703]	Step 75452	lr 0.00305	Loss 0.2478 (0.2771)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.7%, 99.6%)	
12/22 11:42:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][700/703]	Step 75552	lr 0.00305	Loss 0.2549 (0.2797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.6%)	
12/22 11:42:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [133][703/703]	Step 75555	lr 0.00305	Loss 0.4082 (0.2799)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (91.6%, 99.6%)	
12/22 11:42:45午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [133/149] Final Prec@1 91.6111%
12/22 11:42:52午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [133][78/79]	Step 75556	Loss 1.4315	Prec@(1,5) (65.3%, 89.2%)
12/22 11:42:52午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [133/149] Final Prec@1 65.3800%
12/22 11:42:52午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.7400%
12/22 11:43:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][100/703]	Step 75656	lr 0.00282	Loss 0.2315 (0.2466)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.6%)	
12/22 11:43:34午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][200/703]	Step 75756	lr 0.00282	Loss 0.3156 (0.2481)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.6%, 99.7%)	
12/22 11:43:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][300/703]	Step 75856	lr 0.00282	Loss 0.2401 (0.2504)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.7%)	
12/22 11:44:15午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][400/703]	Step 75956	lr 0.00282	Loss 0.2591 (0.2563)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.7%)	
12/22 11:44:36午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][500/703]	Step 76056	lr 0.00282	Loss 0.1835 (0.2583)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.4%, 99.7%)	
12/22 11:44:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][600/703]	Step 76156	lr 0.00282	Loss 0.2225 (0.2598)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.3%, 99.6%)	
12/22 11:45:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][700/703]	Step 76256	lr 0.00282	Loss 0.2660 (0.2638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.6%)	
12/22 11:45:17午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [134][703/703]	Step 76259	lr 0.00282	Loss 0.2542 (0.2638)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.1%, 99.6%)	
12/22 11:45:18午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [134/149] Final Prec@1 92.1289%
12/22 11:45:24午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [134][78/79]	Step 76260	Loss 1.4222	Prec@(1,5) (65.6%, 89.7%)
12/22 11:45:24午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [134/149] Final Prec@1 65.6200%
12/22 11:45:24午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.7400%
12/22 11:45:46午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][100/703]	Step 76360	lr 0.00261	Loss 0.1817 (0.2372)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
12/22 11:46:07午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][200/703]	Step 76460	lr 0.00261	Loss 0.2241 (0.2395)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
12/22 11:46:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][300/703]	Step 76560	lr 0.00261	Loss 0.2543 (0.2467)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.8%, 99.7%)	
12/22 11:46:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][400/703]	Step 76660	lr 0.00261	Loss 0.3220 (0.2499)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
12/22 11:47:09午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][500/703]	Step 76760	lr 0.00261	Loss 0.1960 (0.2504)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.7%, 99.6%)	
12/22 11:47:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][600/703]	Step 76860	lr 0.00261	Loss 0.2736 (0.2533)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.7%)	
12/22 11:47:50午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][700/703]	Step 76960	lr 0.00261	Loss 0.2858 (0.2545)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
12/22 11:47:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [135][703/703]	Step 76963	lr 0.00261	Loss 0.3129 (0.2545)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (92.5%, 99.6%)	
12/22 11:47:51午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [135/149] Final Prec@1 92.4800%
12/22 11:47:57午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [135][78/79]	Step 76964	Loss 1.4059	Prec@(1,5) (65.2%, 89.8%)
12/22 11:47:57午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [135/149] Final Prec@1 65.2200%
12/22 11:47:57午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.7400%
12/22 11:48:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][100/703]	Step 77064	lr 0.0024	Loss 0.2648 (0.2202)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 11:48:40午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][200/703]	Step 77164	lr 0.0024	Loss 0.2423 (0.2237)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.7%)	
12/22 11:49:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][300/703]	Step 77264	lr 0.0024	Loss 0.2396 (0.2252)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 11:49:21午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][400/703]	Step 77364	lr 0.0024	Loss 0.3576 (0.2313)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
12/22 11:49:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][500/703]	Step 77464	lr 0.0024	Loss 0.3227 (0.2344)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.3%, 99.7%)	
12/22 11:50:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][600/703]	Step 77564	lr 0.0024	Loss 0.2440 (0.2376)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.1%, 99.7%)	
12/22 11:50:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][700/703]	Step 77664	lr 0.0024	Loss 0.2662 (0.2398)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
12/22 11:50:23午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [136][703/703]	Step 77667	lr 0.0024	Loss 0.2903 (0.2400)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.0%, 99.7%)	
12/22 11:50:23午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [136/149] Final Prec@1 93.0089%
12/22 11:50:30午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [136][78/79]	Step 77668	Loss 1.4147	Prec@(1,5) (65.7%, 89.7%)
12/22 11:50:30午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [136/149] Final Prec@1 65.7200%
12/22 11:50:30午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.7400%
12/22 11:50:52午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][100/703]	Step 77768	lr 0.00221	Loss 0.2690 (0.2148)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.7%)	
12/22 11:51:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][200/703]	Step 77868	lr 0.00221	Loss 0.1687 (0.2219)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 11:51:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][300/703]	Step 77968	lr 0.00221	Loss 0.2051 (0.2212)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.7%)	
12/22 11:51:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][400/703]	Step 78068	lr 0.00221	Loss 0.2676 (0.2238)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.7%, 99.7%)	
12/22 11:52:14午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][500/703]	Step 78168	lr 0.00221	Loss 0.2313 (0.2264)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.6%, 99.8%)	
12/22 11:52:35午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][600/703]	Step 78268	lr 0.00221	Loss 0.2141 (0.2287)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.5%, 99.7%)	
12/22 11:52:55午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][700/703]	Step 78368	lr 0.00221	Loss 0.1587 (0.2301)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 11:52:56午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [137][703/703]	Step 78371	lr 0.00221	Loss 0.2352 (0.2302)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.4%, 99.7%)	
12/22 11:52:56午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [137/149] Final Prec@1 93.4133%
12/22 11:53:02午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [137][78/79]	Step 78372	Loss 1.4473	Prec@(1,5) (65.6%, 89.6%)
12/22 11:53:02午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [137/149] Final Prec@1 65.5800%
12/22 11:53:02午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 65.7400%
12/22 11:53:25午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][100/703]	Step 78472	lr 0.00204	Loss 0.1827 (0.2109)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.3%, 99.8%)	
12/22 11:53:45午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][200/703]	Step 78572	lr 0.00204	Loss 0.1842 (0.2137)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.8%)	
12/22 11:54:06午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][300/703]	Step 78672	lr 0.00204	Loss 0.1902 (0.2127)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.8%)	
12/22 11:54:27午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][400/703]	Step 78772	lr 0.00204	Loss 0.2387 (0.2147)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.1%, 99.8%)	
12/22 11:54:48午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][500/703]	Step 78872	lr 0.00204	Loss 0.2645 (0.2157)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.0%, 99.8%)	
12/22 11:55:08午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][600/703]	Step 78972	lr 0.00204	Loss 0.2227 (0.2169)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.9%, 99.8%)	
12/22 11:55:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][700/703]	Step 79072	lr 0.00204	Loss 0.2387 (0.2193)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.8%)	
12/22 11:55:29午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [138][703/703]	Step 79075	lr 0.00204	Loss 0.2427 (0.2192)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (93.8%, 99.8%)	
12/22 11:55:30午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [138/149] Final Prec@1 93.8022%
12/22 11:55:36午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [138][78/79]	Step 79076	Loss 1.4131	Prec@(1,5) (66.3%, 90.3%)
12/22 11:55:36午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [138/149] Final Prec@1 66.3000%
12/22 11:55:36午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 66.3000%
12/22 11:55:58午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][100/703]	Step 79176	lr 0.00187	Loss 0.1147 (0.1938)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/22 11:56:19午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][200/703]	Step 79276	lr 0.00187	Loss 0.1476 (0.1979)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/22 11:56:39午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][300/703]	Step 79376	lr 0.00187	Loss 0.1878 (0.1989)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/22 11:57:00午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][400/703]	Step 79476	lr 0.00187	Loss 0.2794 (0.2040)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/22 11:57:20午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][500/703]	Step 79576	lr 0.00187	Loss 0.1452 (0.2051)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/22 11:57:41午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][600/703]	Step 79676	lr 0.00187	Loss 0.1792 (0.2071)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.4%, 99.8%)	
12/22 11:58:01午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][700/703]	Step 79776	lr 0.00187	Loss 0.3390 (0.2103)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 11:58:02午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [139][703/703]	Step 79779	lr 0.00187	Loss 0.1842 (0.2105)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.2%, 99.8%)	
12/22 11:58:02午後 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [139/149] Final Prec@1 94.2311%
12/22 11:58:09午後 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [139][78/79]	Step 79780	Loss 1.3953	Prec@(1,5) (66.7%, 90.2%)
12/22 11:58:09午後 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [139/149] Final Prec@1 66.6800%
12/22 11:58:09午後 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 66.6800%
12/22 11:58:31午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][100/703]	Step 79880	lr 0.00172	Loss 0.2824 (0.1942)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.8%)	
12/22 11:58:51午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][200/703]	Step 79980	lr 0.00172	Loss 0.1998 (0.1932)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.9%, 99.8%)	
12/22 11:59:12午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][300/703]	Step 80080	lr 0.00172	Loss 0.0966 (0.1953)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/22 11:59:33午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][400/703]	Step 80180	lr 0.00172	Loss 0.1629 (0.1992)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/22 11:59:53午後 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][500/703]	Step 80280	lr 0.00172	Loss 0.1319 (0.1969)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/23 12:00:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][600/703]	Step 80380	lr 0.00172	Loss 0.1995 (0.1982)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.6%, 99.8%)	
12/23 12:00:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][700/703]	Step 80480	lr 0.00172	Loss 0.1373 (0.2006)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/23 12:00:35午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [140][703/703]	Step 80483	lr 0.00172	Loss 0.2015 (0.2008)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.5%, 99.8%)	
12/23 12:00:35午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [140/149] Final Prec@1 94.5333%
12/23 12:00:42午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [140][78/79]	Step 80484	Loss 1.4019	Prec@(1,5) (66.5%, 89.8%)
12/23 12:00:42午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [140/149] Final Prec@1 66.4600%
12/23 12:00:42午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 66.6800%
12/23 12:01:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][100/703]	Step 80584	lr 0.00159	Loss 0.1554 (0.1783)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.5%, 99.9%)	
12/23 12:01:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][200/703]	Step 80684	lr 0.00159	Loss 0.3186 (0.1867)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.9%, 99.9%)	
12/23 12:01:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][300/703]	Step 80784	lr 0.00159	Loss 0.1492 (0.1903)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.9%)	
12/23 12:02:05午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][400/703]	Step 80884	lr 0.00159	Loss 0.1349 (0.1895)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.9%)	
12/23 12:02:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][500/703]	Step 80984	lr 0.00159	Loss 0.1625 (0.1905)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.9%)	
12/23 12:02:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][600/703]	Step 81084	lr 0.00159	Loss 0.1708 (0.1903)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.8%, 99.9%)	
12/23 12:03:07午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][700/703]	Step 81184	lr 0.00159	Loss 0.2001 (0.1931)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/23 12:03:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [141][703/703]	Step 81187	lr 0.00159	Loss 0.1974 (0.1934)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (94.7%, 99.8%)	
12/23 12:03:08午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [141/149] Final Prec@1 94.7244%
12/23 12:03:14午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [141][78/79]	Step 81188	Loss 1.3902	Prec@(1,5) (66.5%, 90.1%)
12/23 12:03:14午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [141/149] Final Prec@1 66.5400%
12/23 12:03:14午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 66.6800%
12/23 12:03:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][100/703]	Step 81288	lr 0.00146	Loss 0.0868 (0.1786)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/23 12:03:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][200/703]	Step 81388	lr 0.00146	Loss 0.1117 (0.1795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.9%)	
12/23 12:04:18午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][300/703]	Step 81488	lr 0.00146	Loss 0.1619 (0.1793)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/23 12:04:39午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][400/703]	Step 81588	lr 0.00146	Loss 0.1540 (0.1806)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.9%)	
12/23 12:04:59午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][500/703]	Step 81688	lr 0.00146	Loss 0.1858 (0.1811)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.9%)	
12/23 12:05:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][600/703]	Step 81788	lr 0.00146	Loss 0.3757 (0.1830)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.9%)	
12/23 12:05:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][700/703]	Step 81888	lr 0.00146	Loss 0.1409 (0.1846)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.9%)	
12/23 12:05:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [142][703/703]	Step 81891	lr 0.00146	Loss 0.2069 (0.1847)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.9%)	
12/23 12:05:42午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [142/149] Final Prec@1 95.0556%
12/23 12:05:48午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [142][78/79]	Step 81892	Loss 1.4251	Prec@(1,5) (67.2%, 89.9%)
12/23 12:05:48午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [142/149] Final Prec@1 67.1800%
12/23 12:05:49午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:06:11午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][100/703]	Step 81992	lr 0.00136	Loss 0.2013 (0.1795)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.7%)	
12/23 12:06:31午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][200/703]	Step 82092	lr 0.00136	Loss 0.1445 (0.1777)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.8%)	
12/23 12:06:52午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][300/703]	Step 82192	lr 0.00136	Loss 0.1361 (0.1779)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.3%, 99.8%)	
12/23 12:07:12午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][400/703]	Step 82292	lr 0.00136	Loss 0.1580 (0.1787)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.8%)	
12/23 12:07:33午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][500/703]	Step 82392	lr 0.00136	Loss 0.2352 (0.1797)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.8%)	
12/23 12:07:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][600/703]	Step 82492	lr 0.00136	Loss 0.3339 (0.1806)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.2%, 99.8%)	
12/23 12:08:14午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][700/703]	Step 82592	lr 0.00136	Loss 0.1971 (0.1815)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/23 12:08:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [143][703/703]	Step 82595	lr 0.00136	Loss 0.2007 (0.1815)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.1%, 99.8%)	
12/23 12:08:15午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [143/149] Final Prec@1 95.1422%
12/23 12:08:22午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [143][78/79]	Step 82596	Loss 1.4011	Prec@(1,5) (66.7%, 90.2%)
12/23 12:08:22午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [143/149] Final Prec@1 66.7600%
12/23 12:08:22午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:08:44午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][100/703]	Step 82696	lr 0.00126	Loss 0.1263 (0.1663)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 100.0%)	
12/23 12:09:04午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][200/703]	Step 82796	lr 0.00126	Loss 0.1236 (0.1707)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 100.0%)	
12/23 12:09:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][300/703]	Step 82896	lr 0.00126	Loss 0.1933 (0.1719)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:09:45午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][400/703]	Step 82996	lr 0.00126	Loss 0.2182 (0.1726)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:10:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][500/703]	Step 83096	lr 0.00126	Loss 0.1825 (0.1733)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.5%, 99.9%)	
12/23 12:10:26午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][600/703]	Step 83196	lr 0.00126	Loss 0.1420 (0.1759)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.5%, 99.9%)	
12/23 12:10:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][700/703]	Step 83296	lr 0.00126	Loss 0.1364 (0.1769)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/23 12:10:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [144][703/703]	Step 83299	lr 0.00126	Loss 0.1811 (0.1772)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.4%, 99.9%)	
12/23 12:10:47午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [144/149] Final Prec@1 95.3867%
12/23 12:10:54午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [144][78/79]	Step 83300	Loss 1.3934	Prec@(1,5) (67.0%, 89.9%)
12/23 12:10:54午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [144/149] Final Prec@1 67.0200%
12/23 12:10:54午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:11:16午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][100/703]	Step 83400	lr 0.00118	Loss 0.2578 (0.1731)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.8%)	
12/23 12:11:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][200/703]	Step 83500	lr 0.00118	Loss 0.1871 (0.1656)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.9%, 99.9%)	
12/23 12:11:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][300/703]	Step 83600	lr 0.00118	Loss 0.2029 (0.1672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
12/23 12:12:17午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][400/703]	Step 83700	lr 0.00118	Loss 0.1225 (0.1698)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 99.9%)	
12/23 12:12:38午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][500/703]	Step 83800	lr 0.00118	Loss 0.1520 (0.1709)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 99.9%)	
12/23 12:12:58午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][600/703]	Step 83900	lr 0.00118	Loss 0.1294 (0.1721)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:13:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][700/703]	Step 84000	lr 0.00118	Loss 0.1685 (0.1730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.5%, 99.9%)	
12/23 12:13:19午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [145][703/703]	Step 84003	lr 0.00118	Loss 0.1845 (0.1730)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.5%, 99.9%)	
12/23 12:13:20午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [145/149] Final Prec@1 95.5333%
12/23 12:13:26午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [145][78/79]	Step 84004	Loss 1.4037	Prec@(1,5) (67.0%, 90.1%)
12/23 12:13:26午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [145/149] Final Prec@1 66.9200%
12/23 12:13:26午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:13:48午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][100/703]	Step 84104	lr 0.00112	Loss 0.1393 (0.1659)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 99.9%)	
12/23 12:14:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][200/703]	Step 84204	lr 0.00112	Loss 0.0906 (0.1672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:14:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][300/703]	Step 84304	lr 0.00112	Loss 0.1908 (0.1672)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.7%, 99.9%)	
12/23 12:14:49午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][400/703]	Step 84404	lr 0.00112	Loss 0.0831 (0.1688)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:15:10午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][500/703]	Step 84504	lr 0.00112	Loss 0.2918 (0.1701)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:15:30午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][600/703]	Step 84604	lr 0.00112	Loss 0.2288 (0.1694)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:15:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][700/703]	Step 84704	lr 0.00112	Loss 0.2362 (0.1700)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:15:51午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [146][703/703]	Step 84707	lr 0.00112	Loss 0.1174 (0.1700)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.6%, 99.9%)	
12/23 12:15:52午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [146/149] Final Prec@1 95.5689%
12/23 12:15:58午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [146][78/79]	Step 84708	Loss 1.4157	Prec@(1,5) (66.4%, 90.1%)
12/23 12:15:58午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [146/149] Final Prec@1 66.4600%
12/23 12:15:58午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:16:20午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][100/703]	Step 84808	lr 0.00107	Loss 0.1325 (0.1562)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 100.0%)	
12/23 12:16:41午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][200/703]	Step 84908	lr 0.00107	Loss 0.1185 (0.1579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:17:01午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][300/703]	Step 85008	lr 0.00107	Loss 0.3266 (0.1584)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:17:22午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][400/703]	Step 85108	lr 0.00107	Loss 0.0873 (0.1621)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.9%, 99.9%)	
12/23 12:17:42午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][500/703]	Step 85208	lr 0.00107	Loss 0.2663 (0.1629)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
12/23 12:18:03午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][600/703]	Step 85308	lr 0.00107	Loss 0.1311 (0.1629)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
12/23 12:18:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][700/703]	Step 85408	lr 0.00107	Loss 0.2531 (0.1641)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
12/23 12:18:24午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [147][703/703]	Step 85411	lr 0.00107	Loss 0.1671 (0.1641)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (95.8%, 99.9%)	
12/23 12:18:24午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [147/149] Final Prec@1 95.8044%
12/23 12:18:31午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [147][78/79]	Step 85412	Loss 1.4033	Prec@(1,5) (66.9%, 90.1%)
12/23 12:18:31午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [147/149] Final Prec@1 66.9600%
12/23 12:18:31午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:18:53午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][100/703]	Step 85512	lr 0.00103	Loss 0.2323 (0.1555)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.2%, 99.9%)	
12/23 12:19:13午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][200/703]	Step 85612	lr 0.00103	Loss 0.1380 (0.1539)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.2%, 99.9%)	
12/23 12:19:34午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][300/703]	Step 85712	lr 0.00103	Loss 0.0913 (0.1542)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.3%, 99.9%)	
12/23 12:19:54午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][400/703]	Step 85812	lr 0.00103	Loss 0.1866 (0.1544)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.3%, 99.9%)	
12/23 12:20:15午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][500/703]	Step 85912	lr 0.00103	Loss 0.1091 (0.1571)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:20:36午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][600/703]	Step 86012	lr 0.00103	Loss 0.1534 (0.1579)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:20:56午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][700/703]	Step 86112	lr 0.00103	Loss 0.1720 (0.1590)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.0%, 99.9%)	
12/23 12:20:57午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [148][703/703]	Step 86115	lr 0.00103	Loss 0.1285 (0.1591)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.0%, 99.9%)	
12/23 12:20:57午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [148/149] Final Prec@1 96.0267%
12/23 12:21:03午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [148][78/79]	Step 86116	Loss 1.4359	Prec@(1,5) (67.0%, 89.7%)
12/23 12:21:03午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [148/149] Final Prec@1 67.0600%
12/23 12:21:03午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:21:25午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][100/703]	Step 86216	lr 0.00101	Loss 0.1358 (0.1495)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:21:46午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][200/703]	Step 86316	lr 0.00101	Loss 0.1103 (0.1492)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.4%, 99.9%)	
12/23 12:22:06午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][300/703]	Step 86416	lr 0.00101	Loss 0.1640 (0.1517)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.3%, 99.9%)	
12/23 12:22:27午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][400/703]	Step 86516	lr 0.00101	Loss 0.1346 (0.1561)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:22:47午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][500/703]	Step 86616	lr 0.00101	Loss 0.1435 (0.1566)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:23:08午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][600/703]	Step 86716	lr 0.00101	Loss 0.1885 (0.1561)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:23:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][700/703]	Step 86816	lr 0.00101	Loss 0.2232 (0.1566)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:23:29午前 searchEvalStage_curriculum_trainer.py:213 [INFO] Train: Epoch: [149][703/703]	Step 86819	lr 0.00101	Loss 0.2410 (0.1567)	Arch Loss 0.0000 (0.0000)	Arch Hard Loss 0.0000 (0.0000)	Arch Beta Loss 0.0000 (0.0000)	Arch depth Loss 0.0000 (0.0000)	Prec@(1,5) (96.1%, 99.9%)	
12/23 12:23:29午前 searchEvalStage_curriculum_trainer.py:227 [INFO] Train: [149/149] Final Prec@1 96.0844%
12/23 12:23:36午前 SearchEvalStage_ArchKD_trainer.py:330 [INFO] Valid: Epoch: [149][78/79]	Step 86820	Loss 1.4258	Prec@(1,5) (66.4%, 90.2%)
12/23 12:23:36午前 SearchEvalStage_ArchKD_trainer.py:341 [INFO] Valid: [149/149] Final Prec@1 66.4400%
12/23 12:23:36午前 searchevaluateStage_main.py:99 [INFO] Until now, best Prec@1 = 67.1800%
12/23 12:23:36午前 searchevaluateStage_main.py:104 [INFO] Final best Prec@1 = 67.1800%
12/23 12:23:36午前 searchevaluateStage_main.py:105 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('max_pool_3x3', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('skip_connect', 7)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=[3, 4], DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('avg_pool_3x3', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('skip_connect', 9)]], DAG2_concat=[2, 4], DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=[3, 4])
12/26 08:07:59PM parser.py:28 [INFO] 
12/26 08:07:59PM parser.py:29 [INFO] Parameters:
12/26 08:07:59PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30/DAG
12/26 08:07:59PM parser.py:31 [INFO] T=10.0
12/26 08:07:59PM parser.py:31 [INFO] ADVANCED=1
12/26 08:07:59PM parser.py:31 [INFO] ALPHA_LR=0.0003
12/26 08:07:59PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/26 08:07:59PM parser.py:31 [INFO] ARCH_CRITERION=expected
12/26 08:07:59PM parser.py:31 [INFO] BATCH_SIZE=64
12/26 08:07:59PM parser.py:31 [INFO] CASCADE=0
12/26 08:07:59PM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/26 08:07:59PM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 30]
12/26 08:07:59PM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/26 08:07:59PM parser.py:31 [INFO] DATA_PATH=../data/
12/26 08:07:59PM parser.py:31 [INFO] DATASET=cifar100
12/26 08:07:59PM parser.py:31 [INFO] DEPTH_COEF=0.0
12/26 08:07:59PM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/26 08:07:59PM parser.py:31 [INFO] DISCRETE=1
12/26 08:07:59PM parser.py:31 [INFO] EPOCHS=50
12/26 08:07:59PM parser.py:31 [INFO] EVAL_EPOCHS=90
12/26 08:07:59PM parser.py:31 [INFO] EXP_NAME=s0-expected2-sw3-g1_30-30
12/26 08:07:59PM parser.py:31 [INFO] FINAL_L=0.0
12/26 08:07:59PM parser.py:31 [INFO] G=1.0
12/26 08:07:59PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/26 08:07:59PM parser.py:31 [INFO] GPUS=[0]
12/26 08:07:59PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/26 08:07:59PM parser.py:31 [INFO] INIT_CHANNELS=16
12/26 08:07:59PM parser.py:31 [INFO] L=0.0
12/26 08:07:59PM parser.py:31 [INFO] LAYERS=32
12/26 08:07:59PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/26 08:07:59PM parser.py:31 [INFO] NAME=Curriculum
12/26 08:07:59PM parser.py:31 [INFO] NONKD=1
12/26 08:07:59PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30
12/26 08:07:59PM parser.py:31 [INFO] PCDARTS=0
12/26 08:07:59PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Curriculum/s0-expected2-sw3-g1_30-30/plots
12/26 08:07:59PM parser.py:31 [INFO] PRINT_FREQ=100
12/26 08:07:59PM parser.py:31 [INFO] RESET=0
12/26 08:07:59PM parser.py:31 [INFO] RESUME_PATH=None
12/26 08:07:59PM parser.py:31 [INFO] SAVE=s0-expected2-sw3-g1_30-30
12/26 08:07:59PM parser.py:31 [INFO] SEED=0
12/26 08:07:59PM parser.py:31 [INFO] SHARE_STAGE=0
12/26 08:07:59PM parser.py:31 [INFO] SLIDE_WINDOW=3
12/26 08:07:59PM parser.py:31 [INFO] SPEC_CELL=1
12/26 08:07:59PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/26 08:07:59PM parser.py:31 [INFO] TEACHER_NAME=none
12/26 08:07:59PM parser.py:31 [INFO] TEACHER_PATH=none
12/26 08:07:59PM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/26 08:07:59PM parser.py:31 [INFO] TYPE=SearchEvalCurriculum
12/26 08:07:59PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/26 08:07:59PM parser.py:31 [INFO] W_LR=0.025
12/26 08:07:59PM parser.py:31 [INFO] W_LR_MIN=0.001
12/26 08:07:59PM parser.py:31 [INFO] W_MOMENTUM=0.9
12/26 08:07:59PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/26 08:07:59PM parser.py:31 [INFO] WORKERS=4
12/26 08:07:59PM parser.py:32 [INFO] 
12/26 08:08:00PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
