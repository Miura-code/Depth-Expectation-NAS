12/26 08:34:19PM parser.py:28 [INFO] 
12/26 08:34:19PM parser.py:29 [INFO] Parameters:
12/26 08:34:19PM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.001/DAG
12/26 08:34:19PM parser.py:31 [INFO] T=10.0
12/26 08:34:19PM parser.py:31 [INFO] ADVANCED=1
12/26 08:34:19PM parser.py:31 [INFO] ALPHA_LR=0.0003
12/26 08:34:19PM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/26 08:34:19PM parser.py:31 [INFO] ARCH_CRITERION=expected
12/26 08:34:19PM parser.py:31 [INFO] BATCH_SIZE=64
12/26 08:34:19PM parser.py:31 [INFO] CASCADE=0
12/26 08:34:19PM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/26 08:34:19PM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 30]
12/26 08:34:19PM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/26 08:34:19PM parser.py:31 [INFO] DATA_PATH=../data/
12/26 08:34:19PM parser.py:31 [INFO] DATASET=cifar100
12/26 08:34:19PM parser.py:31 [INFO] DEPTH_COEF=-0.001
12/26 08:34:19PM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/26 08:34:19PM parser.py:31 [INFO] DISCRETE=1
12/26 08:34:19PM parser.py:31 [INFO] EPOCHS=50
12/26 08:34:19PM parser.py:31 [INFO] EVAL_EPOCHS=100
12/26 08:34:19PM parser.py:31 [INFO] EXP_NAME=s0-depth-sw3-g-0.001
12/26 08:34:19PM parser.py:31 [INFO] FINAL_L=0.0
12/26 08:34:19PM parser.py:31 [INFO] G=0.0
12/26 08:34:19PM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/26 08:34:19PM parser.py:31 [INFO] GPUS=[0]
12/26 08:34:19PM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/26 08:34:19PM parser.py:31 [INFO] INIT_CHANNELS=16
12/26 08:34:19PM parser.py:31 [INFO] L=0.0
12/26 08:34:19PM parser.py:31 [INFO] LAYERS=32
12/26 08:34:19PM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/26 08:34:19PM parser.py:31 [INFO] NAME=Pruning
12/26 08:34:19PM parser.py:31 [INFO] NONKD=1
12/26 08:34:19PM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.001
12/26 08:34:19PM parser.py:31 [INFO] PCDARTS=0
12/26 08:34:19PM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.001/plots
12/26 08:34:19PM parser.py:31 [INFO] PRINT_FREQ=100
12/26 08:34:19PM parser.py:31 [INFO] RESET=0
12/26 08:34:19PM parser.py:31 [INFO] RESUME_PATH=None
12/26 08:34:19PM parser.py:31 [INFO] SAVE=s0-depth-sw3-g-0.001
12/26 08:34:19PM parser.py:31 [INFO] SEED=0
12/26 08:34:19PM parser.py:31 [INFO] SHARE_STAGE=0
12/26 08:34:19PM parser.py:31 [INFO] SLIDE_WINDOW=3
12/26 08:34:19PM parser.py:31 [INFO] SPEC_CELL=1
12/26 08:34:19PM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/26 08:34:19PM parser.py:31 [INFO] TEACHER_NAME=none
12/26 08:34:19PM parser.py:31 [INFO] TEACHER_PATH=none
12/26 08:34:19PM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/26 08:34:19PM parser.py:31 [INFO] TYPE=Distribution
12/26 08:34:19PM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/26 08:34:19PM parser.py:31 [INFO] W_LR=0.025
12/26 08:34:19PM parser.py:31 [INFO] W_LR_MIN=0.001
12/26 08:34:19PM parser.py:31 [INFO] W_MOMENTUM=0.9
12/26 08:34:19PM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/26 08:34:19PM parser.py:31 [INFO] WORKERS=4
12/26 08:34:19PM parser.py:32 [INFO] 
12/26 08:34:21PM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/26 08:35:06PM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.3308 (4.5089)	Arch Loss 4.2706 (4.4932)	Arch Hard Loss 4.2706 (4.4932)	Arch Beta Loss 2.8230 (2.8232)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (2.5%, 10.3%)	
12/26 08:35:53PM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1579 (4.4291)	Arch Loss 4.3603 (4.4210)	Arch Hard Loss 4.3603 (4.4210)	Arch Beta Loss 2.8239 (2.8233)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (3.0%, 12.9%)	
12/26 08:36:40PM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][300/390]	Step 300	lr 0.025	Loss 4.2596 (4.3573)	Arch Loss 4.2451 (4.3405)	Arch Hard Loss 4.2451 (4.3405)	Arch Beta Loss 2.8262 (2.8237)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (3.6%, 14.9%)	
12/26 08:37:23PM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][390/390]	Step 390	lr 0.025	Loss 3.9634 (4.2947)	Arch Loss 4.0962 (4.2821)	Arch Hard Loss 4.0962 (4.2821)	Arch Beta Loss 2.8302 (2.8247)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (4.2%, 16.7%)	
12/26 08:37:24PM searchDistribution_trainer.py:166 [INFO] Train: [  0/49] Final Prec@1 4.1600%
12/26 08:37:33PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][100/391]	Step 391	Loss 4.0422	Prec@(1,5) (6.8%, 24.5%)
12/26 08:37:40PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][200/391]	Step 391	Loss 4.0458	Prec@(1,5) (6.7%, 24.0%)
12/26 08:37:48PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][300/391]	Step 391	Loss 4.0495	Prec@(1,5) (6.7%, 23.8%)
12/26 08:37:55PM searchStage_trainer.py:312 [INFO] Valid: Epoch: [0][390/391]	Step 391	Loss 4.0553	Prec@(1,5) (6.6%, 23.4%)
12/26 08:37:55PM searchStage_trainer.py:323 [INFO] Valid: [  0/49] Final Prec@1 6.6000%
12/26 08:37:55PM trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('skip_connect', 2), ('max_pool_3x3', 4)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 5), ('max_pool_3x3', 7)], [('max_pool_3x3', 7), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 10), ('avg_pool_3x3', 9)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('avg_pool_3x3', 2)], [('max_pool_3x3', 2), ('skip_connect', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 4), ('avg_pool_3x3', 6)], [('avg_pool_3x3', 7), ('avg_pool_3x3', 6)], [('max_pool_3x3', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 10)]], DAG3_concat=range(10, 12))
12/26 08:37:56PM trainer_runner.py:108 [INFO] Until now, best Prec@1 = 6.6000%
12/26 08:38:45午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][100/390]	Step 491	lr 0.02498	Loss 4.0936 (4.0059)	Arch Loss 4.0047 (4.0172)	Arch Hard Loss 4.0047 (4.0172)	Arch Beta Loss 2.8373 (2.8335)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (7.5%, 25.2%)	
12/26 08:39:33午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][200/390]	Step 591	lr 0.02498	Loss 4.0950 (3.9822)	Arch Loss 3.8178 (3.9727)	Arch Hard Loss 3.8178 (3.9727)	Arch Beta Loss 2.8458 (2.8377)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (7.8%, 26.1%)	
12/26 08:40:17午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][300/390]	Step 691	lr 0.02498	Loss 3.8985 (3.9438)	Arch Loss 3.8365 (3.9370)	Arch Hard Loss 3.8365 (3.9370)	Arch Beta Loss 2.8554 (2.8420)	Arch depth Loss 0.0029 (0.0028)	Prec@(1,5) (8.2%, 27.2%)	
12/26 08:40:56午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [1][390/390]	Step 781	lr 0.02498	Loss 3.8055 (3.9160)	Arch Loss 3.9462 (3.8938)	Arch Hard Loss 3.9462 (3.8938)	Arch Beta Loss 2.8630 (2.8460)	Arch depth Loss 0.0029 (0.0028)	Prec@(1,5) (8.6%, 28.1%)	
12/26 08:40:56午後 searchDistribution_trainer.py:166 [INFO] Train: [  1/49] Final Prec@1 8.6400%
12/26 08:41:03午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][100/391]	Step 782	Loss 3.7878	Prec@(1,5) (9.6%, 31.5%)
12/26 08:41:10午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][200/391]	Step 782	Loss 3.7614	Prec@(1,5) (9.8%, 32.7%)
12/26 08:41:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][300/391]	Step 782	Loss 3.7614	Prec@(1,5) (9.9%, 32.7%)
12/26 08:41:22午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [1][390/391]	Step 782	Loss 3.7696	Prec@(1,5) (9.9%, 32.7%)
12/26 08:41:22午後 searchStage_trainer.py:323 [INFO] Valid: [  1/49] Final Prec@1 9.8720%
12/26 08:41:22午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('max_pool_3x3', 1)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 4)], [('max_pool_3x3', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 6), ('max_pool_3x3', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 10)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('max_pool_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('max_pool_3x3', 6)], [('skip_connect', 9), ('avg_pool_3x3', 8)], [('avg_pool_3x3', 9), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('avg_pool_3x3', 7), ('max_pool_3x3', 6)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
12/26 08:41:23午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 9.8720%
12/26 08:42:06午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][100/390]	Step 882	lr 0.02491	Loss 3.8748 (3.7284)	Arch Loss 3.9435 (3.7419)	Arch Hard Loss 3.9435 (3.7419)	Arch Beta Loss 2.8717 (2.8673)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (11.4%, 34.4%)	
12/26 08:42:50午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][200/390]	Step 982	lr 0.02491	Loss 3.5807 (3.7182)	Arch Loss 3.7265 (3.7192)	Arch Hard Loss 3.7265 (3.7192)	Arch Beta Loss 2.8809 (2.8718)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (11.5%, 34.7%)	
12/26 08:43:33午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][300/390]	Step 1082	lr 0.02491	Loss 3.5868 (3.7015)	Arch Loss 3.6628 (3.6878)	Arch Hard Loss 3.6628 (3.6878)	Arch Beta Loss 2.8896 (2.8763)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (11.8%, 34.8%)	
12/26 08:44:12午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [2][390/390]	Step 1172	lr 0.02491	Loss 3.5523 (3.6778)	Arch Loss 3.4419 (3.6638)	Arch Hard Loss 3.4419 (3.6638)	Arch Beta Loss 2.8971 (2.8803)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (12.2%, 35.4%)	
12/26 08:44:13午後 searchDistribution_trainer.py:166 [INFO] Train: [  2/49] Final Prec@1 12.1840%
12/26 08:44:20午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][100/391]	Step 1173	Loss 3.5368	Prec@(1,5) (14.5%, 38.7%)
12/26 08:44:27午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][200/391]	Step 1173	Loss 3.5362	Prec@(1,5) (14.4%, 39.3%)
12/26 08:44:33午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][300/391]	Step 1173	Loss 3.5395	Prec@(1,5) (14.5%, 39.3%)
12/26 08:44:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [2][390/391]	Step 1173	Loss 3.5353	Prec@(1,5) (14.7%, 39.6%)
12/26 08:44:39午後 searchStage_trainer.py:323 [INFO] Valid: [  2/49] Final Prec@1 14.6520%
12/26 08:44:39午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('max_pool_3x3', 0)], [('max_pool_3x3', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 5), ('max_pool_3x3', 4)], [('skip_connect', 5), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 6)], [('skip_connect', 7), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 3)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 3), ('max_pool_3x3', 5)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 7), ('max_pool_3x3', 6)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(10, 12))
12/26 08:44:39午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 14.6520%
12/26 08:45:23午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][100/390]	Step 1273	lr 0.02479	Loss 3.3505 (3.5409)	Arch Loss 3.4326 (3.5695)	Arch Hard Loss 3.4326 (3.5695)	Arch Beta Loss 2.9050 (2.9013)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (14.2%, 39.9%)	
12/26 08:46:06午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][200/390]	Step 1373	lr 0.02479	Loss 3.1645 (3.5259)	Arch Loss 3.6132 (3.5429)	Arch Hard Loss 3.6132 (3.5429)	Arch Beta Loss 2.9129 (2.9051)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (14.4%, 40.2%)	
12/26 08:46:49午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][300/390]	Step 1473	lr 0.02479	Loss 3.6440 (3.5281)	Arch Loss 3.6880 (3.5264)	Arch Hard Loss 3.6880 (3.5264)	Arch Beta Loss 2.9200 (2.9088)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (14.6%, 40.2%)	
12/26 08:47:29午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [3][390/390]	Step 1563	lr 0.02479	Loss 3.1314 (3.5097)	Arch Loss 3.4081 (3.5141)	Arch Hard Loss 3.4081 (3.5141)	Arch Beta Loss 2.9259 (2.9121)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (14.9%, 40.8%)	
12/26 08:47:29午後 searchDistribution_trainer.py:166 [INFO] Train: [  3/49] Final Prec@1 14.9400%
12/26 08:47:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][100/391]	Step 1564	Loss 3.5243	Prec@(1,5) (15.0%, 40.6%)
12/26 08:47:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][200/391]	Step 1564	Loss 3.5255	Prec@(1,5) (14.9%, 40.5%)
12/26 08:47:50午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][300/391]	Step 1564	Loss 3.5232	Prec@(1,5) (14.7%, 40.5%)
12/26 08:47:56午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [3][390/391]	Step 1564	Loss 3.5264	Prec@(1,5) (14.7%, 40.3%)
12/26 08:47:56午後 searchStage_trainer.py:323 [INFO] Valid: [  3/49] Final Prec@1 14.7320%
12/26 08:47:56午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('max_pool_3x3', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('skip_connect', 9)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 08:47:56午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 14.7320%
12/26 08:48:40午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][100/390]	Step 1664	lr 0.02462	Loss 3.4171 (3.4185)	Arch Loss 3.0821 (3.4213)	Arch Hard Loss 3.0821 (3.4213)	Arch Beta Loss 2.9321 (2.9292)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (16.3%, 43.4%)	
12/26 08:49:24午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][200/390]	Step 1764	lr 0.02462	Loss 2.9942 (3.4022)	Arch Loss 3.4251 (3.4009)	Arch Hard Loss 3.4251 (3.4009)	Arch Beta Loss 2.9378 (2.9321)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (16.8%, 44.0%)	
12/26 08:50:07午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][300/390]	Step 1864	lr 0.02462	Loss 3.5063 (3.3878)	Arch Loss 3.2304 (3.3887)	Arch Hard Loss 3.2304 (3.3887)	Arch Beta Loss 2.9444 (2.9352)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (17.2%, 44.3%)	
12/26 08:50:47午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [4][390/390]	Step 1954	lr 0.02462	Loss 3.2507 (3.3723)	Arch Loss 3.0770 (3.3764)	Arch Hard Loss 3.0770 (3.3764)	Arch Beta Loss 2.9491 (2.9379)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (17.5%, 44.8%)	
12/26 08:50:47午後 searchDistribution_trainer.py:166 [INFO] Train: [  4/49] Final Prec@1 17.5480%
12/26 08:50:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][100/391]	Step 1955	Loss 3.5207	Prec@(1,5) (16.8%, 45.2%)
12/26 08:51:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][200/391]	Step 1955	Loss 3.4794	Prec@(1,5) (17.1%, 45.7%)
12/26 08:51:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][300/391]	Step 1955	Loss 3.4806	Prec@(1,5) (16.7%, 45.4%)
12/26 08:51:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [4][390/391]	Step 1955	Loss 3.4720	Prec@(1,5) (16.7%, 45.8%)
12/26 08:51:13午後 searchStage_trainer.py:323 [INFO] Valid: [  4/49] Final Prec@1 16.7240%
12/26 08:51:13午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('max_pool_3x3', 5), ('max_pool_3x3', 3)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 5)], [('max_pool_3x3', 6), ('max_pool_3x3', 7)], [('skip_connect', 8), ('max_pool_3x3', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 08:51:14午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 16.7240%
12/26 08:51:59午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][100/390]	Step 2055	lr 0.02441	Loss 3.1631 (3.2590)	Arch Loss 3.3002 (3.3002)	Arch Hard Loss 3.3002 (3.3002)	Arch Beta Loss 2.9546 (2.9521)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (19.1%, 48.4%)	
12/26 08:52:42午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][200/390]	Step 2155	lr 0.02441	Loss 3.1557 (3.2557)	Arch Loss 3.3006 (3.2896)	Arch Hard Loss 3.3006 (3.2896)	Arch Beta Loss 2.9588 (2.9545)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (19.1%, 48.4%)	
12/26 08:53:27午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][300/390]	Step 2255	lr 0.02441	Loss 3.6688 (3.2485)	Arch Loss 3.2227 (3.2789)	Arch Hard Loss 3.2227 (3.2789)	Arch Beta Loss 2.9627 (2.9565)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (19.4%, 48.4%)	
12/26 08:54:05午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [5][390/390]	Step 2345	lr 0.02441	Loss 3.1685 (3.2367)	Arch Loss 3.2335 (3.2744)	Arch Hard Loss 3.2335 (3.2744)	Arch Beta Loss 2.9661 (2.9583)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (19.6%, 48.8%)	
12/26 08:54:05午後 searchDistribution_trainer.py:166 [INFO] Train: [  5/49] Final Prec@1 19.5800%
12/26 08:54:12午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][100/391]	Step 2346	Loss 3.2017	Prec@(1,5) (21.7%, 49.3%)
12/26 08:54:18午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][200/391]	Step 2346	Loss 3.2141	Prec@(1,5) (20.9%, 49.1%)
12/26 08:54:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][300/391]	Step 2346	Loss 3.2156	Prec@(1,5) (20.9%, 49.3%)
12/26 08:54:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [5][390/391]	Step 2346	Loss 3.2193	Prec@(1,5) (20.7%, 49.3%)
12/26 08:54:30午後 searchStage_trainer.py:323 [INFO] Valid: [  5/49] Final Prec@1 20.7440%
12/26 08:54:30午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('max_pool_3x3', 1), ('max_pool_3x3', 2)], [('max_pool_3x3', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 08:54:31午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 20.7440%
12/26 08:55:15午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][100/390]	Step 2446	lr 0.02416	Loss 3.0053 (3.1198)	Arch Loss 3.0014 (3.2083)	Arch Hard Loss 3.0014 (3.2083)	Arch Beta Loss 2.9686 (2.9677)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (21.5%, 51.8%)	
12/26 08:55:58午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][200/390]	Step 2546	lr 0.02416	Loss 2.8882 (3.1222)	Arch Loss 2.9465 (3.1658)	Arch Hard Loss 2.9465 (3.1658)	Arch Beta Loss 2.9716 (2.9689)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (22.0%, 52.1%)	
12/26 08:56:40午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][300/390]	Step 2646	lr 0.02416	Loss 3.2099 (3.1031)	Arch Loss 2.9485 (3.1495)	Arch Hard Loss 2.9485 (3.1495)	Arch Beta Loss 2.9751 (2.9705)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (22.2%, 52.5%)	
12/26 08:57:18午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [6][390/390]	Step 2736	lr 0.02416	Loss 2.9671 (3.1012)	Arch Loss 3.4904 (3.1442)	Arch Hard Loss 3.4904 (3.1442)	Arch Beta Loss 2.9775 (2.9718)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (22.3%, 52.6%)	
12/26 08:57:18午後 searchDistribution_trainer.py:166 [INFO] Train: [  6/49] Final Prec@1 22.2600%
12/26 08:57:24午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][100/391]	Step 2737	Loss 3.0189	Prec@(1,5) (23.8%, 54.9%)
12/26 08:57:31午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][200/391]	Step 2737	Loss 3.0189	Prec@(1,5) (23.7%, 55.0%)
12/26 08:57:37午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][300/391]	Step 2737	Loss 3.0292	Prec@(1,5) (23.6%, 54.8%)
12/26 08:57:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [6][390/391]	Step 2737	Loss 3.0277	Prec@(1,5) (23.7%, 54.7%)
12/26 08:57:42午後 searchStage_trainer.py:323 [INFO] Valid: [  6/49] Final Prec@1 23.7240%
12/26 08:57:42午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('max_pool_3x3', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 08:57:43午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 23.7240%
12/26 08:58:26午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][100/390]	Step 2837	lr 0.02386	Loss 3.0553 (2.9889)	Arch Loss 2.9424 (3.0534)	Arch Hard Loss 2.9424 (3.0534)	Arch Beta Loss 2.9800 (2.9788)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (24.5%, 56.0%)	
12/26 08:59:08午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][200/390]	Step 2937	lr 0.02386	Loss 2.8648 (2.9780)	Arch Loss 2.8816 (3.0571)	Arch Hard Loss 2.8816 (3.0571)	Arch Beta Loss 2.9816 (2.9797)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (25.0%, 56.3%)	
12/26 08:59:51午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][300/390]	Step 3037	lr 0.02386	Loss 3.1394 (2.9711)	Arch Loss 3.0953 (3.0396)	Arch Hard Loss 3.0953 (3.0396)	Arch Beta Loss 2.9834 (2.9806)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (25.1%, 56.3%)	
12/26 09:00:29午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [7][390/390]	Step 3127	lr 0.02386	Loss 2.7865 (2.9690)	Arch Loss 2.6601 (3.0371)	Arch Hard Loss 2.6601 (3.0371)	Arch Beta Loss 2.9843 (2.9814)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (25.0%, 56.4%)	
12/26 09:00:30午後 searchDistribution_trainer.py:166 [INFO] Train: [  7/49] Final Prec@1 25.0560%
12/26 09:00:37午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][100/391]	Step 3128	Loss 2.9519	Prec@(1,5) (25.4%, 56.8%)
12/26 09:00:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][200/391]	Step 3128	Loss 2.9549	Prec@(1,5) (25.4%, 56.5%)
12/26 09:00:50午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][300/391]	Step 3128	Loss 2.9544	Prec@(1,5) (25.5%, 56.6%)
12/26 09:00:56午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [7][390/391]	Step 3128	Loss 2.9598	Prec@(1,5) (25.3%, 56.5%)
12/26 09:00:56午後 searchStage_trainer.py:323 [INFO] Valid: [  7/49] Final Prec@1 25.3320%
12/26 09:00:56午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('max_pool_3x3', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('max_pool_3x3', 5)], [('skip_connect', 5), ('max_pool_3x3', 6)], [('max_pool_3x3', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:00:57午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 25.3320%
12/26 09:01:42午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][100/390]	Step 3228	lr 0.02352	Loss 2.6050 (2.8728)	Arch Loss 2.8102 (2.9929)	Arch Hard Loss 2.8102 (2.9929)	Arch Beta Loss 2.9858 (2.9848)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (26.8%, 57.6%)	
12/26 09:02:26午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][200/390]	Step 3328	lr 0.02352	Loss 2.9274 (2.8653)	Arch Loss 2.7592 (2.9678)	Arch Hard Loss 2.7592 (2.9678)	Arch Beta Loss 2.9884 (2.9859)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (27.5%, 58.3%)	
12/26 09:03:09午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][300/390]	Step 3428	lr 0.02352	Loss 3.0362 (2.8638)	Arch Loss 3.1382 (2.9465)	Arch Hard Loss 3.1382 (2.9465)	Arch Beta Loss 2.9898 (2.9869)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (27.1%, 58.6%)	
12/26 09:03:48午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [8][390/390]	Step 3518	lr 0.02352	Loss 2.8251 (2.8675)	Arch Loss 3.0617 (2.9344)	Arch Hard Loss 3.0617 (2.9344)	Arch Beta Loss 2.9911 (2.9877)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (27.2%, 58.5%)	
12/26 09:03:48午後 searchDistribution_trainer.py:166 [INFO] Train: [  8/49] Final Prec@1 27.2120%
12/26 09:03:55午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][100/391]	Step 3519	Loss 2.8763	Prec@(1,5) (26.9%, 59.0%)
12/26 09:04:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][200/391]	Step 3519	Loss 2.8916	Prec@(1,5) (26.6%, 58.4%)
12/26 09:04:07午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][300/391]	Step 3519	Loss 2.8850	Prec@(1,5) (26.8%, 58.8%)
12/26 09:04:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [8][390/391]	Step 3519	Loss 2.8819	Prec@(1,5) (27.0%, 58.8%)
12/26 09:04:13午後 searchStage_trainer.py:323 [INFO] Valid: [  8/49] Final Prec@1 27.0360%
12/26 09:04:13午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('max_pool_3x3', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:04:14午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 27.0360%
12/26 09:04:57午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][100/390]	Step 3619	lr 0.02313	Loss 2.8877 (2.7785)	Arch Loss 2.8023 (2.8727)	Arch Hard Loss 2.8023 (2.8727)	Arch Beta Loss 2.9939 (2.9925)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (28.9%, 61.1%)	
12/26 09:05:42午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][200/390]	Step 3719	lr 0.02313	Loss 2.5873 (2.7824)	Arch Loss 3.1401 (2.8699)	Arch Hard Loss 3.1401 (2.8699)	Arch Beta Loss 2.9942 (2.9931)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (28.6%, 60.8%)	
12/26 09:06:26午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][300/390]	Step 3819	lr 0.02313	Loss 2.6869 (2.7651)	Arch Loss 2.6895 (2.8618)	Arch Hard Loss 2.6895 (2.8618)	Arch Beta Loss 2.9956 (2.9936)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (28.8%, 61.0%)	
12/26 09:07:06午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [9][390/390]	Step 3909	lr 0.02313	Loss 2.4626 (2.7565)	Arch Loss 2.9573 (2.8535)	Arch Hard Loss 2.9573 (2.8535)	Arch Beta Loss 2.9970 (2.9943)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (29.0%, 61.2%)	
12/26 09:07:06午後 searchDistribution_trainer.py:166 [INFO] Train: [  9/49] Final Prec@1 28.9920%
12/26 09:07:14午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][100/391]	Step 3910	Loss 2.7956	Prec@(1,5) (28.4%, 60.8%)
12/26 09:07:20午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][200/391]	Step 3910	Loss 2.7780	Prec@(1,5) (28.7%, 60.9%)
12/26 09:07:28午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][300/391]	Step 3910	Loss 2.7762	Prec@(1,5) (29.0%, 61.1%)
12/26 09:07:34午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [9][390/391]	Step 3910	Loss 2.7716	Prec@(1,5) (29.0%, 61.1%)
12/26 09:07:34午後 searchStage_trainer.py:323 [INFO] Valid: [  9/49] Final Prec@1 29.0040%
12/26 09:07:34午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(10, 12), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('max_pool_3x3', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:07:35午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 29.0040%
12/26 09:08:22午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][100/390]	Step 4010	lr 0.02271	Loss 2.9515 (2.6653)	Arch Loss 2.9021 (2.8051)	Arch Hard Loss 2.9021 (2.8051)	Arch Beta Loss 2.9974 (2.9970)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (30.5%, 62.8%)	
12/26 09:09:10午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][200/390]	Step 4110	lr 0.02271	Loss 2.6000 (2.6535)	Arch Loss 2.8650 (2.7738)	Arch Hard Loss 2.8650 (2.7738)	Arch Beta Loss 2.9974 (2.9970)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (31.0%, 63.4%)	
12/26 09:09:57午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][300/390]	Step 4210	lr 0.02271	Loss 2.4987 (2.6643)	Arch Loss 3.2791 (2.7707)	Arch Hard Loss 3.2791 (2.7707)	Arch Beta Loss 2.9981 (2.9972)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (30.9%, 63.2%)	
12/26 09:10:39午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [10][390/390]	Step 4300	lr 0.02271	Loss 2.5828 (2.6575)	Arch Loss 3.0916 (2.7549)	Arch Hard Loss 3.0916 (2.7549)	Arch Beta Loss 2.9997 (2.9976)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (31.1%, 63.4%)	
12/26 09:10:39午後 searchDistribution_trainer.py:166 [INFO] Train: [ 10/49] Final Prec@1 31.0600%
12/26 09:10:47午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][100/391]	Step 4301	Loss 2.7400	Prec@(1,5) (30.1%, 62.1%)
12/26 09:10:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][200/391]	Step 4301	Loss 2.7515	Prec@(1,5) (29.6%, 61.7%)
12/26 09:11:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][300/391]	Step 4301	Loss 2.7570	Prec@(1,5) (29.7%, 61.5%)
12/26 09:11:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [10][390/391]	Step 4301	Loss 2.7526	Prec@(1,5) (29.9%, 61.4%)
12/26 09:11:08午後 searchStage_trainer.py:323 [INFO] Valid: [ 10/49] Final Prec@1 29.8800%
12/26 09:11:08午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('max_pool_3x3', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:11:08午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 29.8800%
12/26 09:11:55午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][100/390]	Step 4401	lr 0.02225	Loss 2.7913 (2.5732)	Arch Loss 2.5044 (2.7294)	Arch Hard Loss 2.5044 (2.7294)	Arch Beta Loss 3.0005 (3.0004)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (32.5%, 66.3%)	
12/26 09:12:40午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][200/390]	Step 4501	lr 0.02225	Loss 2.1794 (2.5637)	Arch Loss 2.7354 (2.7102)	Arch Hard Loss 2.7354 (2.7102)	Arch Beta Loss 3.0008 (3.0007)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (32.7%, 66.1%)	
12/26 09:13:25午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][300/390]	Step 4601	lr 0.02225	Loss 2.6065 (2.5590)	Arch Loss 2.5804 (2.6910)	Arch Hard Loss 2.5804 (2.6910)	Arch Beta Loss 3.0014 (3.0009)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (33.2%, 66.3%)	
12/26 09:14:06午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [11][390/390]	Step 4691	lr 0.02225	Loss 2.2646 (2.5601)	Arch Loss 2.4952 (2.6878)	Arch Hard Loss 2.4952 (2.6878)	Arch Beta Loss 3.0015 (3.0010)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (33.1%, 66.0%)	
12/26 09:14:06午後 searchDistribution_trainer.py:166 [INFO] Train: [ 11/49] Final Prec@1 33.1560%
12/26 09:14:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][100/391]	Step 4692	Loss 2.6710	Prec@(1,5) (31.5%, 63.2%)
12/26 09:14:19午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][200/391]	Step 4692	Loss 2.6569	Prec@(1,5) (31.6%, 63.5%)
12/26 09:14:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][300/391]	Step 4692	Loss 2.6690	Prec@(1,5) (31.3%, 63.4%)
12/26 09:14:31午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [11][390/391]	Step 4692	Loss 2.6691	Prec@(1,5) (31.5%, 63.3%)
12/26 09:14:31午後 searchStage_trainer.py:323 [INFO] Valid: [ 11/49] Final Prec@1 31.4320%
12/26 09:14:31午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:14:31午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 31.4320%
12/26 09:15:16午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][100/390]	Step 4792	lr 0.02175	Loss 2.4460 (2.4560)	Arch Loss 2.6669 (2.6473)	Arch Hard Loss 2.6669 (2.6473)	Arch Beta Loss 3.0025 (3.0019)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (35.0%, 68.8%)	
12/26 09:16:00午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][200/390]	Step 4892	lr 0.02175	Loss 2.4166 (2.4557)	Arch Loss 2.8076 (2.6365)	Arch Hard Loss 2.8076 (2.6365)	Arch Beta Loss 3.0032 (3.0025)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (35.4%, 68.4%)	
12/26 09:16:44午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][300/390]	Step 4992	lr 0.02175	Loss 2.8227 (2.4765)	Arch Loss 2.6597 (2.6350)	Arch Hard Loss 2.6597 (2.6350)	Arch Beta Loss 3.0031 (3.0027)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (34.8%, 67.8%)	
12/26 09:17:23午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [12][390/390]	Step 5082	lr 0.02175	Loss 2.8454 (2.4702)	Arch Loss 2.6973 (2.6163)	Arch Hard Loss 2.6973 (2.6163)	Arch Beta Loss 3.0046 (3.0030)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (34.9%, 68.0%)	
12/26 09:17:23午後 searchDistribution_trainer.py:166 [INFO] Train: [ 12/49] Final Prec@1 34.9200%
12/26 09:17:31午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][100/391]	Step 5083	Loss 2.5785	Prec@(1,5) (34.2%, 66.0%)
12/26 09:17:38午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][200/391]	Step 5083	Loss 2.5990	Prec@(1,5) (33.5%, 65.5%)
12/26 09:17:44午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][300/391]	Step 5083	Loss 2.6010	Prec@(1,5) (33.5%, 65.3%)
12/26 09:17:49午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [12][390/391]	Step 5083	Loss 2.6011	Prec@(1,5) (33.5%, 65.4%)
12/26 09:17:50午後 searchStage_trainer.py:323 [INFO] Valid: [ 12/49] Final Prec@1 33.4480%
12/26 09:17:50午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 9), ('skip_connect', 8)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('max_pool_3x3', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:17:50午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 33.4480%
12/26 09:18:34午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][100/390]	Step 5183	lr 0.02121	Loss 2.2767 (2.3650)	Arch Loss 2.0660 (2.5656)	Arch Hard Loss 2.0660 (2.5656)	Arch Beta Loss 3.0041 (3.0043)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (37.5%, 70.1%)	
12/26 09:19:17午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][200/390]	Step 5283	lr 0.02121	Loss 2.5337 (2.3772)	Arch Loss 2.2908 (2.5649)	Arch Hard Loss 2.2908 (2.5649)	Arch Beta Loss 3.0037 (3.0041)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (36.9%, 70.0%)	
12/26 09:20:00午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][300/390]	Step 5383	lr 0.02121	Loss 2.2786 (2.3864)	Arch Loss 2.9366 (2.5677)	Arch Hard Loss 2.9366 (2.5677)	Arch Beta Loss 3.0021 (3.0037)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (36.6%, 70.0%)	
12/26 09:20:39午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [13][390/390]	Step 5473	lr 0.02121	Loss 2.0759 (2.3808)	Arch Loss 2.5842 (2.5567)	Arch Hard Loss 2.5842 (2.5567)	Arch Beta Loss 3.0024 (3.0034)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (36.7%, 70.1%)	
12/26 09:20:40午後 searchDistribution_trainer.py:166 [INFO] Train: [ 13/49] Final Prec@1 36.7520%
12/26 09:20:46午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][100/391]	Step 5474	Loss 2.6059	Prec@(1,5) (33.4%, 65.7%)
12/26 09:20:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][200/391]	Step 5474	Loss 2.5948	Prec@(1,5) (33.8%, 65.9%)
12/26 09:21:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][300/391]	Step 5474	Loss 2.6002	Prec@(1,5) (33.8%, 65.5%)
12/26 09:21:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [13][390/391]	Step 5474	Loss 2.5942	Prec@(1,5) (33.8%, 65.7%)
12/26 09:21:05午後 searchStage_trainer.py:323 [INFO] Valid: [ 13/49] Final Prec@1 33.8000%
12/26 09:21:05午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:21:06午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 33.8000%
12/26 09:21:50午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][100/390]	Step 5574	lr 0.02065	Loss 2.2019 (2.2954)	Arch Loss 2.4059 (2.5153)	Arch Hard Loss 2.4059 (2.5153)	Arch Beta Loss 3.0017 (3.0024)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (38.6%, 71.6%)	
12/26 09:22:33午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][200/390]	Step 5674	lr 0.02065	Loss 2.0821 (2.3111)	Arch Loss 2.5533 (2.5009)	Arch Hard Loss 2.5533 (2.5009)	Arch Beta Loss 3.0008 (3.0018)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (38.0%, 71.5%)	
12/26 09:23:18午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][300/390]	Step 5774	lr 0.02065	Loss 2.1102 (2.3080)	Arch Loss 2.7565 (2.4979)	Arch Hard Loss 2.7565 (2.4979)	Arch Beta Loss 2.9995 (3.0012)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (38.3%, 71.3%)	
12/26 09:23:58午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [14][390/390]	Step 5864	lr 0.02065	Loss 2.4179 (2.3100)	Arch Loss 2.5185 (2.4937)	Arch Hard Loss 2.5185 (2.4937)	Arch Beta Loss 2.9980 (3.0007)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (38.3%, 71.3%)	
12/26 09:23:58午後 searchDistribution_trainer.py:166 [INFO] Train: [ 14/49] Final Prec@1 38.3280%
12/26 09:24:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][100/391]	Step 5865	Loss 2.5500	Prec@(1,5) (33.8%, 66.1%)
12/26 09:24:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][200/391]	Step 5865	Loss 2.5415	Prec@(1,5) (34.3%, 66.4%)
12/26 09:24:19午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][300/391]	Step 5865	Loss 2.5415	Prec@(1,5) (34.0%, 66.6%)
12/26 09:24:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [14][390/391]	Step 5865	Loss 2.5366	Prec@(1,5) (34.0%, 66.9%)
12/26 09:24:26午後 searchStage_trainer.py:323 [INFO] Valid: [ 14/49] Final Prec@1 34.0560%
12/26 09:24:26午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:24:26午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 34.0560%
12/26 09:25:11午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][100/390]	Step 5965	lr 0.02005	Loss 2.2545 (2.2086)	Arch Loss 2.3931 (2.4525)	Arch Hard Loss 2.3931 (2.4525)	Arch Beta Loss 2.9985 (2.9977)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (40.9%, 73.6%)	
12/26 09:25:55午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][200/390]	Step 6065	lr 0.02005	Loss 1.9337 (2.2412)	Arch Loss 2.5309 (2.4506)	Arch Hard Loss 2.5309 (2.4506)	Arch Beta Loss 2.9983 (2.9980)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (39.9%, 72.8%)	
12/26 09:26:38午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][300/390]	Step 6165	lr 0.02005	Loss 2.0928 (2.2371)	Arch Loss 2.6115 (2.4421)	Arch Hard Loss 2.6115 (2.4421)	Arch Beta Loss 2.9973 (2.9978)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (40.0%, 73.1%)	
12/26 09:27:18午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [15][390/390]	Step 6255	lr 0.02005	Loss 2.5046 (2.2419)	Arch Loss 2.3518 (2.4436)	Arch Hard Loss 2.3518 (2.4436)	Arch Beta Loss 2.9966 (2.9977)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (39.9%, 72.9%)	
12/26 09:27:18午後 searchDistribution_trainer.py:166 [INFO] Train: [ 15/49] Final Prec@1 39.9080%
12/26 09:27:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][100/391]	Step 6256	Loss 2.4607	Prec@(1,5) (36.2%, 67.9%)
12/26 09:27:31午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][200/391]	Step 6256	Loss 2.4674	Prec@(1,5) (36.1%, 68.3%)
12/26 09:27:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][300/391]	Step 6256	Loss 2.4637	Prec@(1,5) (36.0%, 68.4%)
12/26 09:27:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [15][390/391]	Step 6256	Loss 2.4691	Prec@(1,5) (35.9%, 68.3%)
12/26 09:27:45午後 searchStage_trainer.py:323 [INFO] Valid: [ 15/49] Final Prec@1 35.8600%
12/26 09:27:45午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:27:46午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 35.8600%
12/26 09:28:34午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][100/390]	Step 6356	lr 0.01943	Loss 2.1284 (2.1295)	Arch Loss 2.2674 (2.4397)	Arch Hard Loss 2.2674 (2.4397)	Arch Beta Loss 2.9960 (2.9964)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (42.2%, 74.9%)	
12/26 09:29:20午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][200/390]	Step 6456	lr 0.01943	Loss 2.1879 (2.1533)	Arch Loss 2.4792 (2.4258)	Arch Hard Loss 2.4792 (2.4258)	Arch Beta Loss 2.9940 (2.9956)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (41.7%, 74.5%)	
12/26 09:30:06午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][300/390]	Step 6556	lr 0.01943	Loss 2.2881 (2.1677)	Arch Loss 2.2265 (2.4081)	Arch Hard Loss 2.2265 (2.4081)	Arch Beta Loss 2.9939 (2.9950)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (41.4%, 74.4%)	
12/26 09:30:48午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [16][390/390]	Step 6646	lr 0.01943	Loss 1.9165 (2.1685)	Arch Loss 2.8637 (2.4048)	Arch Hard Loss 2.8637 (2.4048)	Arch Beta Loss 2.9939 (2.9948)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (41.3%, 74.4%)	
12/26 09:30:49午後 searchDistribution_trainer.py:166 [INFO] Train: [ 16/49] Final Prec@1 41.2880%
12/26 09:30:56午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][100/391]	Step 6647	Loss 2.3563	Prec@(1,5) (38.4%, 71.2%)
12/26 09:31:03午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][200/391]	Step 6647	Loss 2.3710	Prec@(1,5) (37.8%, 70.4%)
12/26 09:31:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][300/391]	Step 6647	Loss 2.3622	Prec@(1,5) (38.1%, 70.6%)
12/26 09:31:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [16][390/391]	Step 6647	Loss 2.3595	Prec@(1,5) (38.1%, 70.7%)
12/26 09:31:17午後 searchStage_trainer.py:323 [INFO] Valid: [ 16/49] Final Prec@1 38.1040%
12/26 09:31:17午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:31:18午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 38.1040%
12/26 09:32:04午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][100/390]	Step 6747	lr 0.01878	Loss 2.2648 (2.0596)	Arch Loss 2.3829 (2.3662)	Arch Hard Loss 2.3829 (2.3662)	Arch Beta Loss 2.9925 (2.9933)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (43.9%, 76.7%)	
12/26 09:32:51午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][200/390]	Step 6847	lr 0.01878	Loss 2.2694 (2.0791)	Arch Loss 2.4414 (2.3796)	Arch Hard Loss 2.4414 (2.3796)	Arch Beta Loss 2.9918 (2.9926)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (43.1%, 76.4%)	
12/26 09:33:39午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][300/390]	Step 6947	lr 0.01878	Loss 2.0925 (2.0934)	Arch Loss 2.0394 (2.3528)	Arch Hard Loss 2.0394 (2.3528)	Arch Beta Loss 2.9897 (2.9920)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (42.9%, 76.1%)	
12/26 09:34:18午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [17][390/390]	Step 7037	lr 0.01878	Loss 2.1577 (2.0951)	Arch Loss 2.2717 (2.3512)	Arch Hard Loss 2.2717 (2.3512)	Arch Beta Loss 2.9894 (2.9914)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (43.0%, 76.1%)	
12/26 09:34:18午後 searchDistribution_trainer.py:166 [INFO] Train: [ 17/49] Final Prec@1 42.9680%
12/26 09:34:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][100/391]	Step 7038	Loss 2.3102	Prec@(1,5) (38.9%, 72.2%)
12/26 09:34:32午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][200/391]	Step 7038	Loss 2.2859	Prec@(1,5) (39.7%, 72.4%)
12/26 09:34:38午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][300/391]	Step 7038	Loss 2.2910	Prec@(1,5) (39.5%, 72.4%)
12/26 09:34:43午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [17][390/391]	Step 7038	Loss 2.2924	Prec@(1,5) (39.6%, 72.3%)
12/26 09:34:43午後 searchStage_trainer.py:323 [INFO] Valid: [ 17/49] Final Prec@1 39.5680%
12/26 09:34:43午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG3_concat=range(9, 11))
12/26 09:34:44午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 39.5680%
12/26 09:35:28午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][100/390]	Step 7138	lr 0.01811	Loss 1.9543 (2.0380)	Arch Loss 2.4594 (2.3042)	Arch Hard Loss 2.4594 (2.3042)	Arch Beta Loss 2.9889 (2.9890)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (43.6%, 76.9%)	
12/26 09:36:12午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][200/390]	Step 7238	lr 0.01811	Loss 2.2481 (2.0130)	Arch Loss 1.8876 (2.3206)	Arch Hard Loss 1.8876 (2.3206)	Arch Beta Loss 2.9870 (2.9886)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (44.3%, 77.6%)	
12/26 09:36:56午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][300/390]	Step 7338	lr 0.01811	Loss 1.6798 (2.0117)	Arch Loss 2.3711 (2.3175)	Arch Hard Loss 2.3711 (2.3175)	Arch Beta Loss 2.9861 (2.9879)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (44.6%, 77.6%)	
12/26 09:37:35午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [18][390/390]	Step 7428	lr 0.01811	Loss 2.0728 (2.0195)	Arch Loss 2.0299 (2.3110)	Arch Hard Loss 2.0299 (2.3110)	Arch Beta Loss 2.9847 (2.9873)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (44.4%, 77.3%)	
12/26 09:37:35午後 searchDistribution_trainer.py:166 [INFO] Train: [ 18/49] Final Prec@1 44.4240%
12/26 09:37:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][100/391]	Step 7429	Loss 2.2858	Prec@(1,5) (40.5%, 71.8%)
12/26 09:37:48午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][200/391]	Step 7429	Loss 2.2898	Prec@(1,5) (40.4%, 71.8%)
12/26 09:37:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][300/391]	Step 7429	Loss 2.2757	Prec@(1,5) (40.5%, 72.2%)
12/26 09:38:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [18][390/391]	Step 7429	Loss 2.2789	Prec@(1,5) (40.4%, 72.3%)
12/26 09:38:00午後 searchStage_trainer.py:323 [INFO] Valid: [ 18/49] Final Prec@1 40.3720%
12/26 09:38:00午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 09:38:00午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 40.3720%
12/26 09:38:44午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][100/390]	Step 7529	lr 0.01742	Loss 1.7855 (1.9033)	Arch Loss 2.1738 (2.2897)	Arch Hard Loss 2.1738 (2.2897)	Arch Beta Loss 2.9830 (2.9838)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (47.5%, 79.4%)	
12/26 09:39:30午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][200/390]	Step 7629	lr 0.01742	Loss 1.6734 (1.9244)	Arch Loss 2.3721 (2.2725)	Arch Hard Loss 2.3721 (2.2725)	Arch Beta Loss 2.9820 (2.9832)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (47.0%, 79.0%)	
12/26 09:40:14午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][300/390]	Step 7729	lr 0.01742	Loss 2.2248 (1.9418)	Arch Loss 1.9516 (2.2734)	Arch Hard Loss 1.9516 (2.2734)	Arch Beta Loss 2.9813 (2.9826)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (46.6%, 78.6%)	
12/26 09:40:52午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [19][390/390]	Step 7819	lr 0.01742	Loss 1.8526 (1.9507)	Arch Loss 2.8457 (2.2749)	Arch Hard Loss 2.8457 (2.2749)	Arch Beta Loss 2.9795 (2.9821)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (46.3%, 78.4%)	
12/26 09:40:52午後 searchDistribution_trainer.py:166 [INFO] Train: [ 19/49] Final Prec@1 46.2480%
12/26 09:40:58午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][100/391]	Step 7820	Loss 2.3148	Prec@(1,5) (38.9%, 71.8%)
12/26 09:41:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][200/391]	Step 7820	Loss 2.3236	Prec@(1,5) (39.1%, 71.5%)
12/26 09:41:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][300/391]	Step 7820	Loss 2.3235	Prec@(1,5) (39.1%, 71.3%)
12/26 09:41:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [19][390/391]	Step 7820	Loss 2.3219	Prec@(1,5) (39.4%, 71.3%)
12/26 09:41:16午後 searchStage_trainer.py:323 [INFO] Valid: [ 19/49] Final Prec@1 39.3560%
12/26 09:41:16午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 09:41:16午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 40.3720%
12/26 09:41:59午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][100/390]	Step 7920	lr 0.01671	Loss 1.6903 (1.8269)	Arch Loss 2.2641 (2.2601)	Arch Hard Loss 2.2641 (2.2601)	Arch Beta Loss 2.9771 (2.9780)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (48.8%, 80.8%)	
12/26 09:42:42午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][200/390]	Step 8020	lr 0.01671	Loss 2.2385 (1.8644)	Arch Loss 1.9018 (2.2382)	Arch Hard Loss 1.9018 (2.2382)	Arch Beta Loss 2.9756 (2.9772)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (48.2%, 79.9%)	
12/26 09:43:25午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][300/390]	Step 8120	lr 0.01671	Loss 2.1246 (1.8825)	Arch Loss 1.9267 (2.2363)	Arch Hard Loss 1.9267 (2.2363)	Arch Beta Loss 2.9744 (2.9763)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (47.8%, 79.8%)	
12/26 09:44:02午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [20][390/390]	Step 8210	lr 0.01671	Loss 1.8102 (1.8938)	Arch Loss 2.1304 (2.2332)	Arch Hard Loss 2.1304 (2.2332)	Arch Beta Loss 2.9727 (2.9758)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (47.7%, 79.5%)	
12/26 09:44:02午後 searchDistribution_trainer.py:166 [INFO] Train: [ 20/49] Final Prec@1 47.6680%
12/26 09:44:09午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][100/391]	Step 8211	Loss 2.5123	Prec@(1,5) (36.1%, 68.4%)
12/26 09:44:15午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][200/391]	Step 8211	Loss 2.5555	Prec@(1,5) (34.9%, 67.7%)
12/26 09:44:21午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][300/391]	Step 8211	Loss 2.5584	Prec@(1,5) (34.7%, 67.8%)
12/26 09:44:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [20][390/391]	Step 8211	Loss 2.5605	Prec@(1,5) (34.7%, 67.7%)
12/26 09:44:27午後 searchStage_trainer.py:323 [INFO] Valid: [ 20/49] Final Prec@1 34.6960%
12/26 09:44:27午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 09:44:27午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 40.3720%
12/26 09:45:10午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][100/390]	Step 8311	lr 0.01598	Loss 1.8771 (1.8186)	Arch Loss 2.4124 (2.2195)	Arch Hard Loss 2.4124 (2.2195)	Arch Beta Loss 2.9715 (2.9719)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (49.2%, 81.1%)	
12/26 09:45:52午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][200/390]	Step 8411	lr 0.01598	Loss 2.4604 (1.8057)	Arch Loss 2.2518 (2.1890)	Arch Hard Loss 2.2518 (2.1890)	Arch Beta Loss 2.9717 (2.9721)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (49.4%, 81.3%)	
12/26 09:46:35午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][300/390]	Step 8511	lr 0.01598	Loss 2.0352 (1.8242)	Arch Loss 2.1793 (2.2013)	Arch Hard Loss 2.1793 (2.2013)	Arch Beta Loss 2.9701 (2.9717)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (49.0%, 81.1%)	
12/26 09:47:13午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [21][390/390]	Step 8601	lr 0.01598	Loss 1.7417 (1.8354)	Arch Loss 2.1642 (2.2001)	Arch Hard Loss 2.1642 (2.2001)	Arch Beta Loss 2.9690 (2.9712)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (48.7%, 80.8%)	
12/26 09:47:13午後 searchDistribution_trainer.py:166 [INFO] Train: [ 21/49] Final Prec@1 48.7440%
12/26 09:47:20午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][100/391]	Step 8602	Loss 2.5395	Prec@(1,5) (35.9%, 68.9%)
12/26 09:47:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][200/391]	Step 8602	Loss 2.5117	Prec@(1,5) (36.2%, 68.8%)
12/26 09:47:32午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][300/391]	Step 8602	Loss 2.5031	Prec@(1,5) (36.5%, 68.8%)
12/26 09:47:38午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [21][390/391]	Step 8602	Loss 2.5053	Prec@(1,5) (36.4%, 68.7%)
12/26 09:47:38午後 searchStage_trainer.py:323 [INFO] Valid: [ 21/49] Final Prec@1 36.3920%
12/26 09:47:38午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 09:47:38午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 40.3720%
12/26 09:48:21午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][100/390]	Step 8702	lr 0.01525	Loss 2.0588 (1.7070)	Arch Loss 2.1169 (2.1822)	Arch Hard Loss 2.1169 (2.1822)	Arch Beta Loss 2.9691 (2.9693)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (52.3%, 83.1%)	
12/26 09:49:03午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][200/390]	Step 8802	lr 0.01525	Loss 1.5455 (1.7470)	Arch Loss 2.0660 (2.1867)	Arch Hard Loss 2.0660 (2.1867)	Arch Beta Loss 2.9672 (2.9686)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (51.0%, 82.6%)	
12/26 09:49:45午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][300/390]	Step 8902	lr 0.01525	Loss 1.9999 (1.7623)	Arch Loss 2.2279 (2.1769)	Arch Hard Loss 2.2279 (2.1769)	Arch Beta Loss 2.9663 (2.9681)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (50.6%, 82.4%)	
12/26 09:50:22午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [22][390/390]	Step 8992	lr 0.01525	Loss 1.7083 (1.7763)	Arch Loss 1.9668 (2.1707)	Arch Hard Loss 1.9668 (2.1707)	Arch Beta Loss 2.9656 (2.9676)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (50.3%, 82.0%)	
12/26 09:50:23午後 searchDistribution_trainer.py:166 [INFO] Train: [ 22/49] Final Prec@1 50.3200%
12/26 09:50:29午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][100/391]	Step 8993	Loss 2.1748	Prec@(1,5) (43.0%, 74.6%)
12/26 09:50:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][200/391]	Step 8993	Loss 2.1858	Prec@(1,5) (42.8%, 74.0%)
12/26 09:50:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][300/391]	Step 8993	Loss 2.1910	Prec@(1,5) (42.6%, 73.9%)
12/26 09:50:47午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [22][390/391]	Step 8993	Loss 2.1911	Prec@(1,5) (42.5%, 73.9%)
12/26 09:50:47午後 searchStage_trainer.py:323 [INFO] Valid: [ 22/49] Final Prec@1 42.4960%
12/26 09:50:47午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 09:50:48午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 42.4960%
12/26 09:51:31午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][100/390]	Step 9093	lr 0.0145	Loss 1.4723 (1.6493)	Arch Loss 1.8175 (2.1411)	Arch Hard Loss 1.8175 (2.1411)	Arch Beta Loss 2.9637 (2.9649)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (53.3%, 84.4%)	
12/26 09:52:14午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][200/390]	Step 9193	lr 0.0145	Loss 1.8463 (1.6837)	Arch Loss 2.5551 (2.1442)	Arch Hard Loss 2.5551 (2.1442)	Arch Beta Loss 2.9639 (2.9642)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (52.2%, 83.4%)	
12/26 09:52:57午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][300/390]	Step 9293	lr 0.0145	Loss 2.2836 (1.7044)	Arch Loss 2.0988 (2.1420)	Arch Hard Loss 2.0988 (2.1420)	Arch Beta Loss 2.9634 (2.9641)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (51.7%, 83.1%)	
12/26 09:53:35午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [23][390/390]	Step 9383	lr 0.0145	Loss 1.6839 (1.7241)	Arch Loss 2.2021 (2.1339)	Arch Hard Loss 2.2021 (2.1339)	Arch Beta Loss 2.9624 (2.9638)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (51.2%, 82.8%)	
12/26 09:53:36午後 searchDistribution_trainer.py:166 [INFO] Train: [ 23/49] Final Prec@1 51.1720%
12/26 09:53:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][100/391]	Step 9384	Loss 2.1760	Prec@(1,5) (43.5%, 74.6%)
12/26 09:53:48午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][200/391]	Step 9384	Loss 2.1768	Prec@(1,5) (43.4%, 74.7%)
12/26 09:53:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][300/391]	Step 9384	Loss 2.1729	Prec@(1,5) (43.5%, 74.7%)
12/26 09:54:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [23][390/391]	Step 9384	Loss 2.1661	Prec@(1,5) (43.6%, 74.9%)
12/26 09:54:00午後 searchStage_trainer.py:323 [INFO] Valid: [ 23/49] Final Prec@1 43.6440%
12/26 09:54:00午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 9)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 09:54:00午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 43.6440%
12/26 09:54:44午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][100/390]	Step 9484	lr 0.01375	Loss 1.5345 (1.6022)	Arch Loss 2.0226 (2.1111)	Arch Hard Loss 2.0226 (2.1111)	Arch Beta Loss 2.9615 (2.9621)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (54.7%, 84.7%)	
12/26 09:55:26午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][200/390]	Step 9584	lr 0.01375	Loss 1.4328 (1.6099)	Arch Loss 1.9894 (2.1210)	Arch Hard Loss 1.9894 (2.1210)	Arch Beta Loss 2.9596 (2.9612)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (54.2%, 84.6%)	
12/26 09:56:10午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][300/390]	Step 9684	lr 0.01375	Loss 1.8783 (1.6400)	Arch Loss 2.0562 (2.1222)	Arch Hard Loss 2.0562 (2.1222)	Arch Beta Loss 2.9592 (2.9605)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (53.7%, 84.1%)	
12/26 09:56:50午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [24][390/390]	Step 9774	lr 0.01375	Loss 1.8522 (1.6489)	Arch Loss 2.0525 (2.1218)	Arch Hard Loss 2.0525 (2.1218)	Arch Beta Loss 2.9574 (2.9600)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (53.4%, 83.8%)	
12/26 09:56:50午後 searchDistribution_trainer.py:166 [INFO] Train: [ 24/49] Final Prec@1 53.4120%
12/26 09:56:57午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][100/391]	Step 9775	Loss 2.3275	Prec@(1,5) (40.5%, 71.7%)
12/26 09:57:03午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][200/391]	Step 9775	Loss 2.3397	Prec@(1,5) (39.7%, 71.9%)
12/26 09:57:10午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][300/391]	Step 9775	Loss 2.3516	Prec@(1,5) (39.6%, 71.8%)
12/26 09:57:16午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [24][390/391]	Step 9775	Loss 2.3548	Prec@(1,5) (39.6%, 71.7%)
12/26 09:57:16午後 searchStage_trainer.py:323 [INFO] Valid: [ 24/49] Final Prec@1 39.6240%
12/26 09:57:16午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 09:57:16午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 43.6440%
12/26 09:58:01午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][100/390]	Step 9875	lr 0.013	Loss 1.4621 (1.5512)	Arch Loss 1.9063 (2.1271)	Arch Hard Loss 1.9063 (2.1271)	Arch Beta Loss 2.9573 (2.9571)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (55.0%, 86.3%)	
12/26 09:58:46午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][200/390]	Step 9975	lr 0.013	Loss 1.6308 (1.5701)	Arch Loss 1.7640 (2.0956)	Arch Hard Loss 1.7640 (2.0956)	Arch Beta Loss 2.9551 (2.9566)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (55.1%, 85.6%)	
12/26 09:59:30午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][300/390]	Step 10075	lr 0.013	Loss 1.5736 (1.5880)	Arch Loss 1.9571 (2.0896)	Arch Hard Loss 1.9571 (2.0896)	Arch Beta Loss 2.9530 (2.9558)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (54.6%, 85.2%)	
12/26 10:00:09午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [25][390/390]	Step 10165	lr 0.013	Loss 1.7107 (1.5991)	Arch Loss 2.2213 (2.1016)	Arch Hard Loss 2.2213 (2.1016)	Arch Beta Loss 2.9525 (2.9551)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (54.3%, 85.0%)	
12/26 10:00:10午後 searchDistribution_trainer.py:166 [INFO] Train: [ 25/49] Final Prec@1 54.2960%
12/26 10:00:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][100/391]	Step 10166	Loss 2.2205	Prec@(1,5) (42.5%, 74.3%)
12/26 10:00:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][200/391]	Step 10166	Loss 2.2031	Prec@(1,5) (43.0%, 74.5%)
12/26 10:00:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][300/391]	Step 10166	Loss 2.1984	Prec@(1,5) (43.0%, 74.4%)
12/26 10:00:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [25][390/391]	Step 10166	Loss 2.1893	Prec@(1,5) (43.2%, 74.7%)
12/26 10:00:36午後 searchStage_trainer.py:323 [INFO] Valid: [ 25/49] Final Prec@1 43.2400%
12/26 10:00:36午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('avg_pool_3x3', 9), ('skip_connect', 8)]], DAG1_concat=range(10, 12), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:00:36午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 43.6440%
12/26 10:01:20午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][100/390]	Step 10266	lr 0.01225	Loss 1.6799 (1.5147)	Arch Loss 2.0803 (2.0876)	Arch Hard Loss 2.0803 (2.0876)	Arch Beta Loss 2.9514 (2.9519)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (56.7%, 86.5%)	
12/26 10:02:04午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][200/390]	Step 10366	lr 0.01225	Loss 1.3511 (1.5204)	Arch Loss 2.0395 (2.1081)	Arch Hard Loss 2.0395 (2.1081)	Arch Beta Loss 2.9501 (2.9514)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (56.5%, 86.5%)	
12/26 10:02:48午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][300/390]	Step 10466	lr 0.01225	Loss 1.2798 (1.5255)	Arch Loss 1.9388 (2.0798)	Arch Hard Loss 1.9388 (2.0798)	Arch Beta Loss 2.9490 (2.9509)	Arch depth Loss 0.0029 (0.0030)	Prec@(1,5) (56.3%, 86.3%)	
12/26 10:03:27午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [26][390/390]	Step 10556	lr 0.01225	Loss 1.8921 (1.5431)	Arch Loss 2.1397 (2.0844)	Arch Hard Loss 2.1397 (2.0844)	Arch Beta Loss 2.9476 (2.9503)	Arch depth Loss 0.0029 (0.0030)	Prec@(1,5) (56.0%, 85.9%)	
12/26 10:03:27午後 searchDistribution_trainer.py:166 [INFO] Train: [ 26/49] Final Prec@1 56.0320%
12/26 10:03:34午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][100/391]	Step 10557	Loss 2.1956	Prec@(1,5) (42.5%, 74.0%)
12/26 10:03:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][200/391]	Step 10557	Loss 2.1662	Prec@(1,5) (43.3%, 74.4%)
12/26 10:03:47午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][300/391]	Step 10557	Loss 2.1641	Prec@(1,5) (43.4%, 74.5%)
12/26 10:03:53午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [26][390/391]	Step 10557	Loss 2.1604	Prec@(1,5) (43.6%, 74.6%)
12/26 10:03:53午後 searchStage_trainer.py:323 [INFO] Valid: [ 26/49] Final Prec@1 43.5880%
12/26 10:03:53午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:03:53午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 43.6440%
12/26 10:04:38午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][100/390]	Step 10657	lr 0.0115	Loss 1.6467 (1.4029)	Arch Loss 2.0445 (2.0491)	Arch Hard Loss 2.0445 (2.0491)	Arch Beta Loss 2.9478 (2.9474)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (59.2%, 88.2%)	
12/26 10:05:21午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][200/390]	Step 10757	lr 0.0115	Loss 1.5926 (1.4475)	Arch Loss 2.1029 (2.0622)	Arch Hard Loss 2.1029 (2.0622)	Arch Beta Loss 2.9482 (2.9479)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (58.4%, 87.4%)	
12/26 10:06:07午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][300/390]	Step 10857	lr 0.0115	Loss 1.9376 (1.4748)	Arch Loss 1.3332 (2.0488)	Arch Hard Loss 1.3332 (2.0488)	Arch Beta Loss 2.9469 (2.9477)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (57.6%, 86.8%)	
12/26 10:06:47午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [27][390/390]	Step 10947	lr 0.0115	Loss 1.3459 (1.4948)	Arch Loss 2.3093 (2.0462)	Arch Hard Loss 2.3093 (2.0462)	Arch Beta Loss 2.9456 (2.9473)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (57.3%, 86.5%)	
12/26 10:06:47午後 searchDistribution_trainer.py:166 [INFO] Train: [ 27/49] Final Prec@1 57.2840%
12/26 10:06:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][100/391]	Step 10948	Loss 3.1069	Prec@(1,5) (28.0%, 60.1%)
12/26 10:07:01午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][200/391]	Step 10948	Loss 3.1314	Prec@(1,5) (28.2%, 59.7%)
12/26 10:07:07午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][300/391]	Step 10948	Loss 3.1445	Prec@(1,5) (28.2%, 59.5%)
12/26 10:07:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [27][390/391]	Step 10948	Loss 3.1348	Prec@(1,5) (28.4%, 59.5%)
12/26 10:07:13午後 searchStage_trainer.py:323 [INFO] Valid: [ 27/49] Final Prec@1 28.3800%
12/26 10:07:13午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:07:14午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 43.6440%
12/26 10:07:58午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][100/390]	Step 11048	lr 0.01075	Loss 1.5612 (1.4042)	Arch Loss 2.0275 (2.0342)	Arch Hard Loss 2.0275 (2.0342)	Arch Beta Loss 2.9452 (2.9452)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (58.9%, 88.3%)	
12/26 10:08:42午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][200/390]	Step 11148	lr 0.01075	Loss 1.5820 (1.4187)	Arch Loss 1.9346 (2.0455)	Arch Hard Loss 1.9346 (2.0455)	Arch Beta Loss 2.9451 (2.9450)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (58.8%, 87.8%)	
12/26 10:09:24午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][300/390]	Step 11248	lr 0.01075	Loss 1.4219 (1.4298)	Arch Loss 2.1960 (2.0595)	Arch Hard Loss 2.1960 (2.0595)	Arch Beta Loss 2.9446 (2.9449)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (58.7%, 87.6%)	
12/26 10:10:02午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [28][390/390]	Step 11338	lr 0.01075	Loss 1.8724 (1.4409)	Arch Loss 1.7339 (2.0427)	Arch Hard Loss 1.7339 (2.0427)	Arch Beta Loss 2.9440 (2.9448)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (58.4%, 87.4%)	
12/26 10:10:02午後 searchDistribution_trainer.py:166 [INFO] Train: [ 28/49] Final Prec@1 58.4320%
12/26 10:10:09午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][100/391]	Step 11339	Loss 2.1685	Prec@(1,5) (43.8%, 75.0%)
12/26 10:10:15午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][200/391]	Step 11339	Loss 2.1518	Prec@(1,5) (44.2%, 75.4%)
12/26 10:10:21午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][300/391]	Step 11339	Loss 2.1473	Prec@(1,5) (44.1%, 75.7%)
12/26 10:10:27午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [28][390/391]	Step 11339	Loss 2.1495	Prec@(1,5) (44.2%, 75.7%)
12/26 10:10:27午後 searchStage_trainer.py:323 [INFO] Valid: [ 28/49] Final Prec@1 44.1600%
12/26 10:10:27午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:10:27午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 44.1600%
12/26 10:11:10午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][100/390]	Step 11439	lr 0.01002	Loss 1.1362 (1.3315)	Arch Loss 1.8222 (2.0449)	Arch Hard Loss 1.8222 (2.0449)	Arch Beta Loss 2.9441 (2.9438)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (61.2%, 89.3%)	
12/26 10:11:52午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][200/390]	Step 11539	lr 0.01002	Loss 1.1386 (1.3568)	Arch Loss 1.7059 (2.0274)	Arch Hard Loss 1.7059 (2.0274)	Arch Beta Loss 2.9423 (2.9437)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (60.8%, 88.9%)	
12/26 10:12:34午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][300/390]	Step 11639	lr 0.01002	Loss 1.6022 (1.3827)	Arch Loss 2.6143 (2.0221)	Arch Hard Loss 2.6143 (2.0221)	Arch Beta Loss 2.9404 (2.9429)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (60.0%, 88.3%)	
12/26 10:13:12午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [29][390/390]	Step 11729	lr 0.01002	Loss 1.6634 (1.3941)	Arch Loss 2.1211 (2.0314)	Arch Hard Loss 2.1211 (2.0314)	Arch Beta Loss 2.9401 (2.9423)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (59.7%, 88.2%)	
12/26 10:13:13午後 searchDistribution_trainer.py:166 [INFO] Train: [ 29/49] Final Prec@1 59.6880%
12/26 10:13:19午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][100/391]	Step 11730	Loss 2.0595	Prec@(1,5) (46.4%, 77.0%)
12/26 10:13:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][200/391]	Step 11730	Loss 2.0968	Prec@(1,5) (45.5%, 76.5%)
12/26 10:13:31午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][300/391]	Step 11730	Loss 2.0965	Prec@(1,5) (45.5%, 76.4%)
12/26 10:13:37午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [29][390/391]	Step 11730	Loss 2.0860	Prec@(1,5) (45.7%, 76.6%)
12/26 10:13:37午後 searchStage_trainer.py:323 [INFO] Valid: [ 29/49] Final Prec@1 45.6520%
12/26 10:13:37午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:13:37午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 45.6520%
12/26 10:14:20午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][100/390]	Step 11830	lr 0.00929	Loss 1.6301 (1.2756)	Arch Loss 2.2643 (2.0368)	Arch Hard Loss 2.2643 (2.0368)	Arch Beta Loss 2.9402 (2.9400)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (63.1%, 90.2%)	
12/26 10:15:02午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][200/390]	Step 11930	lr 0.00929	Loss 1.1969 (1.2989)	Arch Loss 2.3808 (2.0251)	Arch Hard Loss 2.3808 (2.0251)	Arch Beta Loss 2.9395 (2.9402)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (62.2%, 89.8%)	
12/26 10:15:45午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][300/390]	Step 12030	lr 0.00929	Loss 1.1515 (1.3070)	Arch Loss 2.1618 (2.0270)	Arch Hard Loss 2.1618 (2.0270)	Arch Beta Loss 2.9389 (2.9398)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (61.8%, 89.6%)	
12/26 10:16:23午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [30][390/390]	Step 12120	lr 0.00929	Loss 1.2873 (1.3289)	Arch Loss 1.6979 (2.0121)	Arch Hard Loss 1.6979 (2.0121)	Arch Beta Loss 2.9392 (2.9397)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (61.2%, 89.1%)	
12/26 10:16:24午後 searchDistribution_trainer.py:166 [INFO] Train: [ 30/49] Final Prec@1 61.2560%
12/26 10:16:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][100/391]	Step 12121	Loss 2.0012	Prec@(1,5) (47.5%, 77.8%)
12/26 10:16:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][200/391]	Step 12121	Loss 2.0331	Prec@(1,5) (47.0%, 77.4%)
12/26 10:16:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][300/391]	Step 12121	Loss 2.0549	Prec@(1,5) (46.6%, 77.1%)
12/26 10:16:48午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [30][390/391]	Step 12121	Loss 2.0589	Prec@(1,5) (46.6%, 77.0%)
12/26 10:16:48午後 searchStage_trainer.py:323 [INFO] Valid: [ 30/49] Final Prec@1 46.6440%
12/26 10:16:48午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:16:48午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 46.6440%
12/26 10:17:32午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][100/390]	Step 12221	lr 0.00858	Loss 1.8851 (1.2297)	Arch Loss 1.9495 (1.9959)	Arch Hard Loss 1.9495 (1.9959)	Arch Beta Loss 2.9399 (2.9396)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (64.5%, 90.5%)	
12/26 10:18:14午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][200/390]	Step 12321	lr 0.00858	Loss 1.2211 (1.2327)	Arch Loss 1.7426 (2.0045)	Arch Hard Loss 1.7426 (2.0045)	Arch Beta Loss 2.9394 (2.9395)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (63.9%, 90.5%)	
12/26 10:18:57午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][300/390]	Step 12421	lr 0.00858	Loss 1.0960 (1.2610)	Arch Loss 1.9940 (2.0128)	Arch Hard Loss 1.9940 (2.0128)	Arch Beta Loss 2.9394 (2.9395)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (63.3%, 90.0%)	
12/26 10:19:35午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [31][390/390]	Step 12511	lr 0.00858	Loss 1.0198 (1.2804)	Arch Loss 2.2494 (2.0086)	Arch Hard Loss 2.2494 (2.0086)	Arch Beta Loss 2.9402 (2.9395)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (62.9%, 89.8%)	
12/26 10:19:36午後 searchDistribution_trainer.py:166 [INFO] Train: [ 31/49] Final Prec@1 62.9120%
12/26 10:19:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][100/391]	Step 12512	Loss 2.1549	Prec@(1,5) (45.9%, 76.1%)
12/26 10:19:48午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][200/391]	Step 12512	Loss 2.1463	Prec@(1,5) (45.9%, 76.1%)
12/26 10:19:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][300/391]	Step 12512	Loss 2.1384	Prec@(1,5) (45.9%, 76.2%)
12/26 10:20:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [31][390/391]	Step 12512	Loss 2.1357	Prec@(1,5) (46.0%, 76.2%)
12/26 10:20:00午後 searchStage_trainer.py:323 [INFO] Valid: [ 31/49] Final Prec@1 45.9560%
12/26 10:20:00午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:20:00午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 46.6440%
12/26 10:20:44午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][100/390]	Step 12612	lr 0.00789	Loss 1.1596 (1.1675)	Arch Loss 2.2630 (1.9599)	Arch Hard Loss 2.2630 (1.9599)	Arch Beta Loss 2.9402 (2.9400)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (65.9%, 91.0%)	
12/26 10:21:26午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][200/390]	Step 12712	lr 0.00789	Loss 1.4115 (1.1943)	Arch Loss 1.9442 (1.9938)	Arch Hard Loss 1.9442 (1.9938)	Arch Beta Loss 2.9406 (2.9403)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (65.2%, 90.9%)	
12/26 10:22:09午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][300/390]	Step 12812	lr 0.00789	Loss 1.0945 (1.2125)	Arch Loss 2.4882 (1.9864)	Arch Hard Loss 2.4882 (1.9864)	Arch Beta Loss 2.9419 (2.9406)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (64.6%, 90.7%)	
12/26 10:22:47午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [32][390/390]	Step 12902	lr 0.00789	Loss 1.1395 (1.2350)	Arch Loss 2.2031 (1.9911)	Arch Hard Loss 2.2031 (1.9911)	Arch Beta Loss 2.9405 (2.9408)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (63.9%, 90.4%)	
12/26 10:22:48午後 searchDistribution_trainer.py:166 [INFO] Train: [ 32/49] Final Prec@1 63.9240%
12/26 10:22:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][100/391]	Step 12903	Loss 2.1932	Prec@(1,5) (44.8%, 75.6%)
12/26 10:23:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][200/391]	Step 12903	Loss 2.1749	Prec@(1,5) (44.9%, 75.8%)
12/26 10:23:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][300/391]	Step 12903	Loss 2.1762	Prec@(1,5) (44.9%, 75.8%)
12/26 10:23:12午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [32][390/391]	Step 12903	Loss 2.1704	Prec@(1,5) (45.1%, 75.9%)
12/26 10:23:12午後 searchStage_trainer.py:323 [INFO] Valid: [ 32/49] Final Prec@1 45.1160%
12/26 10:23:12午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('max_pool_3x3', 9)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:23:12午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 46.6440%
12/26 10:23:56午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][100/390]	Step 13003	lr 0.00722	Loss 1.2050 (1.0921)	Arch Loss 2.2209 (1.9955)	Arch Hard Loss 2.2209 (1.9955)	Arch Beta Loss 2.9409 (2.9407)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (68.0%, 92.3%)	
12/26 10:24:38午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][200/390]	Step 13103	lr 0.00722	Loss 0.8820 (1.1337)	Arch Loss 1.6600 (1.9947)	Arch Hard Loss 1.6600 (1.9947)	Arch Beta Loss 2.9411 (2.9408)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (66.8%, 91.6%)	
12/26 10:25:20午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][300/390]	Step 13203	lr 0.00722	Loss 1.2330 (1.1528)	Arch Loss 1.4354 (1.9937)	Arch Hard Loss 1.4354 (1.9937)	Arch Beta Loss 2.9417 (2.9410)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (66.0%, 91.4%)	
12/26 10:25:58午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [33][390/390]	Step 13293	lr 0.00722	Loss 1.2142 (1.1644)	Arch Loss 2.1625 (1.9967)	Arch Hard Loss 2.1625 (1.9967)	Arch Beta Loss 2.9417 (2.9412)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (65.8%, 91.3%)	
12/26 10:25:58午後 searchDistribution_trainer.py:166 [INFO] Train: [ 33/49] Final Prec@1 65.7600%
12/26 10:26:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][100/391]	Step 13294	Loss 2.1092	Prec@(1,5) (47.3%, 77.5%)
12/26 10:26:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][200/391]	Step 13294	Loss 2.0889	Prec@(1,5) (47.7%, 77.8%)
12/26 10:26:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][300/391]	Step 13294	Loss 2.0811	Prec@(1,5) (47.7%, 77.9%)
12/26 10:26:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [33][390/391]	Step 13294	Loss 2.0824	Prec@(1,5) (47.8%, 77.9%)
12/26 10:26:23午後 searchStage_trainer.py:323 [INFO] Valid: [ 33/49] Final Prec@1 47.7680%
12/26 10:26:23午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:26:23午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 47.7680%
12/26 10:27:06午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][100/390]	Step 13394	lr 0.00657	Loss 1.1966 (1.0564)	Arch Loss 1.8167 (1.9690)	Arch Hard Loss 1.8167 (1.9690)	Arch Beta Loss 2.9417 (2.9420)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (68.6%, 93.0%)	
12/26 10:27:49午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][200/390]	Step 13494	lr 0.00657	Loss 1.4619 (1.0876)	Arch Loss 1.8926 (2.0038)	Arch Hard Loss 1.8926 (2.0038)	Arch Beta Loss 2.9425 (2.9419)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (68.0%, 92.4%)	
12/26 10:28:31午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][300/390]	Step 13594	lr 0.00657	Loss 1.2434 (1.1051)	Arch Loss 1.7963 (1.9870)	Arch Hard Loss 1.7963 (1.9870)	Arch Beta Loss 2.9428 (2.9421)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (67.3%, 92.3%)	
12/26 10:29:11午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [34][390/390]	Step 13684	lr 0.00657	Loss 1.1414 (1.1165)	Arch Loss 2.1063 (1.9875)	Arch Hard Loss 2.1063 (1.9875)	Arch Beta Loss 2.9428 (2.9422)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (67.0%, 92.1%)	
12/26 10:29:11午後 searchDistribution_trainer.py:166 [INFO] Train: [ 34/49] Final Prec@1 66.9720%
12/26 10:29:18午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][100/391]	Step 13685	Loss 2.7852	Prec@(1,5) (36.7%, 67.1%)
12/26 10:29:25午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][200/391]	Step 13685	Loss 2.7493	Prec@(1,5) (37.1%, 67.6%)
12/26 10:29:32午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][300/391]	Step 13685	Loss 2.7581	Prec@(1,5) (36.9%, 67.5%)
12/26 10:29:38午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [34][390/391]	Step 13685	Loss 2.7455	Prec@(1,5) (36.9%, 67.7%)
12/26 10:29:38午後 searchStage_trainer.py:323 [INFO] Valid: [ 34/49] Final Prec@1 36.9240%
12/26 10:29:38午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 7)], [('skip_connect', 8), ('avg_pool_3x3', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:29:38午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 47.7680%
12/26 10:30:23午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][100/390]	Step 13785	lr 0.00595	Loss 1.0511 (1.0212)	Arch Loss 1.9746 (1.9748)	Arch Hard Loss 1.9746 (1.9748)	Arch Beta Loss 2.9438 (2.9433)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (69.9%, 93.7%)	
12/26 10:31:08午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][200/390]	Step 13885	lr 0.00595	Loss 1.4620 (1.0470)	Arch Loss 1.6904 (1.9812)	Arch Hard Loss 1.6904 (1.9812)	Arch Beta Loss 2.9438 (2.9437)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (69.0%, 93.2%)	
12/26 10:31:52午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][300/390]	Step 13985	lr 0.00595	Loss 1.3349 (1.0666)	Arch Loss 2.3366 (1.9749)	Arch Hard Loss 2.3366 (1.9749)	Arch Beta Loss 2.9437 (2.9437)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (68.4%, 92.8%)	
12/26 10:32:31午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [35][390/390]	Step 14075	lr 0.00595	Loss 1.1431 (1.0728)	Arch Loss 1.7839 (1.9809)	Arch Hard Loss 1.7839 (1.9809)	Arch Beta Loss 2.9455 (2.9438)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (68.1%, 92.8%)	
12/26 10:32:32午後 searchDistribution_trainer.py:166 [INFO] Train: [ 35/49] Final Prec@1 68.1080%
12/26 10:32:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][100/391]	Step 14076	Loss 2.0457	Prec@(1,5) (48.3%, 78.9%)
12/26 10:32:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][200/391]	Step 14076	Loss 2.0570	Prec@(1,5) (47.9%, 78.3%)
12/26 10:32:51午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][300/391]	Step 14076	Loss 2.0538	Prec@(1,5) (48.2%, 78.4%)
12/26 10:32:57午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [35][390/391]	Step 14076	Loss 2.0719	Prec@(1,5) (47.8%, 78.1%)
12/26 10:32:57午後 searchStage_trainer.py:323 [INFO] Valid: [ 35/49] Final Prec@1 47.8520%
12/26 10:32:57午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:32:58午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 47.8520%
12/26 10:33:42午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][100/390]	Step 14176	lr 0.00535	Loss 0.7400 (0.9903)	Arch Loss 1.5736 (1.9850)	Arch Hard Loss 1.5736 (1.9850)	Arch Beta Loss 2.9455 (2.9457)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (70.6%, 93.7%)	
12/26 10:34:25午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][200/390]	Step 14276	lr 0.00535	Loss 1.2038 (0.9945)	Arch Loss 2.2054 (1.9779)	Arch Hard Loss 2.2054 (1.9779)	Arch Beta Loss 2.9456 (2.9454)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (70.5%, 93.4%)	
12/26 10:35:10午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][300/390]	Step 14376	lr 0.00535	Loss 0.8768 (1.0033)	Arch Loss 2.0527 (1.9622)	Arch Hard Loss 2.0527 (1.9622)	Arch Beta Loss 2.9460 (2.9456)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (70.2%, 93.4%)	
12/26 10:35:50午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [36][390/390]	Step 14466	lr 0.00535	Loss 1.0360 (1.0069)	Arch Loss 2.1684 (1.9747)	Arch Hard Loss 2.1684 (1.9747)	Arch Beta Loss 2.9454 (2.9456)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (70.0%, 93.5%)	
12/26 10:35:51午後 searchDistribution_trainer.py:166 [INFO] Train: [ 36/49] Final Prec@1 70.0200%
12/26 10:35:58午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][100/391]	Step 14467	Loss 2.7324	Prec@(1,5) (38.6%, 68.9%)
12/26 10:36:04午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][200/391]	Step 14467	Loss 2.7340	Prec@(1,5) (38.6%, 68.7%)
12/26 10:36:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][300/391]	Step 14467	Loss 2.7364	Prec@(1,5) (38.0%, 68.7%)
12/26 10:36:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [36][390/391]	Step 14467	Loss 2.7381	Prec@(1,5) (38.1%, 68.8%)
12/26 10:36:17午後 searchStage_trainer.py:323 [INFO] Valid: [ 36/49] Final Prec@1 38.0480%
12/26 10:36:17午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=range(9, 11))
12/26 10:36:17午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 47.8520%
12/26 10:37:03午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][100/390]	Step 14567	lr 0.00479	Loss 1.1053 (0.9310)	Arch Loss 1.7560 (1.9725)	Arch Hard Loss 1.7560 (1.9725)	Arch Beta Loss 2.9450 (2.9453)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (72.1%, 94.4%)	
12/26 10:37:47午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][200/390]	Step 14667	lr 0.00479	Loss 1.1236 (0.9482)	Arch Loss 2.2104 (1.9878)	Arch Hard Loss 2.2104 (1.9878)	Arch Beta Loss 2.9452 (2.9453)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (71.7%, 94.1%)	
12/26 10:38:32午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][300/390]	Step 14767	lr 0.00479	Loss 1.3115 (0.9486)	Arch Loss 2.1559 (1.9929)	Arch Hard Loss 2.1559 (1.9929)	Arch Beta Loss 2.9457 (2.9453)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (71.6%, 94.0%)	
12/26 10:39:13午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [37][390/390]	Step 14857	lr 0.00479	Loss 1.0696 (0.9557)	Arch Loss 2.0317 (1.9867)	Arch Hard Loss 2.0317 (1.9867)	Arch Beta Loss 2.9464 (2.9454)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (71.3%, 94.0%)	
12/26 10:39:14午後 searchDistribution_trainer.py:166 [INFO] Train: [ 37/49] Final Prec@1 71.3120%
12/26 10:39:21午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][100/391]	Step 14858	Loss 2.3767	Prec@(1,5) (42.9%, 74.3%)
12/26 10:39:29午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][200/391]	Step 14858	Loss 2.3237	Prec@(1,5) (44.0%, 75.3%)
12/26 10:39:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][300/391]	Step 14858	Loss 2.3359	Prec@(1,5) (44.0%, 75.2%)
12/26 10:39:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [37][390/391]	Step 14858	Loss 2.3283	Prec@(1,5) (44.1%, 75.3%)
12/26 10:39:42午後 searchStage_trainer.py:323 [INFO] Valid: [ 37/49] Final Prec@1 44.0880%
12/26 10:39:42午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('avg_pool_3x3', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=range(9, 11))
12/26 10:39:42午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 47.8520%
12/26 10:40:27午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][100/390]	Step 14958	lr 0.00425	Loss 0.8442 (0.8723)	Arch Loss 2.0149 (2.0262)	Arch Hard Loss 2.0149 (2.0262)	Arch Beta Loss 2.9470 (2.9464)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (74.0%, 95.1%)	
12/26 10:41:12午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][200/390]	Step 15058	lr 0.00425	Loss 1.1339 (0.8984)	Arch Loss 1.9729 (1.9975)	Arch Hard Loss 1.9729 (1.9975)	Arch Beta Loss 2.9472 (2.9467)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (73.2%, 94.8%)	
12/26 10:41:57午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][300/390]	Step 15158	lr 0.00425	Loss 0.7831 (0.9066)	Arch Loss 2.2465 (1.9952)	Arch Hard Loss 2.2465 (1.9952)	Arch Beta Loss 2.9477 (2.9470)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (73.1%, 94.7%)	
12/26 10:42:37午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [38][390/390]	Step 15248	lr 0.00425	Loss 0.9161 (0.9130)	Arch Loss 2.1595 (1.9873)	Arch Hard Loss 2.1595 (1.9873)	Arch Beta Loss 2.9474 (2.9472)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (72.8%, 94.6%)	
12/26 10:42:37午後 searchDistribution_trainer.py:166 [INFO] Train: [ 38/49] Final Prec@1 72.8320%
12/26 10:42:44午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][100/391]	Step 15249	Loss 1.9757	Prec@(1,5) (50.2%, 79.6%)
12/26 10:42:51午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][200/391]	Step 15249	Loss 1.9622	Prec@(1,5) (50.3%, 80.0%)
12/26 10:42:58午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][300/391]	Step 15249	Loss 1.9598	Prec@(1,5) (50.4%, 80.4%)
12/26 10:43:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [38][390/391]	Step 15249	Loss 1.9714	Prec@(1,5) (50.4%, 80.1%)
12/26 10:43:05午後 searchStage_trainer.py:323 [INFO] Valid: [ 38/49] Final Prec@1 50.3760%
12/26 10:43:05午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 8), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG3_concat=range(9, 11))
12/26 10:43:05午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 50.3760%
12/26 10:43:50午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][100/390]	Step 15349	lr 0.00375	Loss 0.8244 (0.8368)	Arch Loss 1.5876 (2.0358)	Arch Hard Loss 1.5876 (2.0358)	Arch Beta Loss 2.9478 (2.9476)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (74.9%, 95.2%)	
12/26 10:44:34午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][200/390]	Step 15449	lr 0.00375	Loss 0.8083 (0.8529)	Arch Loss 1.7816 (1.9883)	Arch Hard Loss 1.7816 (1.9883)	Arch Beta Loss 2.9473 (2.9477)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (74.2%, 95.2%)	
12/26 10:45:18午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][300/390]	Step 15549	lr 0.00375	Loss 0.9419 (0.8613)	Arch Loss 1.6505 (1.9749)	Arch Hard Loss 1.6505 (1.9749)	Arch Beta Loss 2.9478 (2.9476)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (73.9%, 95.1%)	
12/26 10:45:58午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [39][390/390]	Step 15639	lr 0.00375	Loss 0.6524 (0.8707)	Arch Loss 1.8772 (1.9868)	Arch Hard Loss 1.8772 (1.9868)	Arch Beta Loss 2.9489 (2.9478)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (73.6%, 95.1%)	
12/26 10:45:59午後 searchDistribution_trainer.py:166 [INFO] Train: [ 39/49] Final Prec@1 73.6200%
12/26 10:46:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][100/391]	Step 15640	Loss 2.2056	Prec@(1,5) (47.7%, 76.1%)
12/26 10:46:13午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][200/391]	Step 15640	Loss 2.2397	Prec@(1,5) (47.1%, 76.3%)
12/26 10:46:20午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][300/391]	Step 15640	Loss 2.2267	Prec@(1,5) (47.1%, 76.8%)
12/26 10:46:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [39][390/391]	Step 15640	Loss 2.2230	Prec@(1,5) (47.2%, 76.9%)
12/26 10:46:26午後 searchStage_trainer.py:323 [INFO] Valid: [ 39/49] Final Prec@1 47.1520%
12/26 10:46:26午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/26 10:46:26午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 50.3760%
12/26 10:47:11午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][100/390]	Step 15740	lr 0.00329	Loss 0.8433 (0.7898)	Arch Loss 2.3311 (1.9738)	Arch Hard Loss 2.3311 (1.9738)	Arch Beta Loss 2.9493 (2.9491)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (76.1%, 95.9%)	
12/26 10:47:56午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][200/390]	Step 15840	lr 0.00329	Loss 0.7177 (0.8037)	Arch Loss 2.0793 (1.9806)	Arch Hard Loss 2.0793 (1.9806)	Arch Beta Loss 2.9491 (2.9491)	Arch depth Loss 0.0029 (0.0029)	Prec@(1,5) (75.8%, 95.6%)	
12/26 10:48:40午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][300/390]	Step 15940	lr 0.00329	Loss 1.0816 (0.8171)	Arch Loss 2.0255 (1.9903)	Arch Hard Loss 2.0255 (1.9903)	Arch Beta Loss 2.9500 (2.9492)	Arch depth Loss 0.0030 (0.0029)	Prec@(1,5) (75.4%, 95.6%)	
12/26 10:49:20午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [40][390/390]	Step 16030	lr 0.00329	Loss 0.6747 (0.8212)	Arch Loss 1.7903 (1.9853)	Arch Hard Loss 1.7903 (1.9853)	Arch Beta Loss 2.9511 (2.9496)	Arch depth Loss 0.0030 (0.0029)	Prec@(1,5) (75.3%, 95.5%)	
12/26 10:49:20午後 searchDistribution_trainer.py:166 [INFO] Train: [ 40/49] Final Prec@1 75.3160%
12/26 10:49:28午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][100/391]	Step 16031	Loss 1.9927	Prec@(1,5) (49.7%, 79.8%)
12/26 10:49:35午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][200/391]	Step 16031	Loss 1.9629	Prec@(1,5) (50.4%, 80.1%)
12/26 10:49:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][300/391]	Step 16031	Loss 1.9714	Prec@(1,5) (50.2%, 80.0%)
12/26 10:49:49午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [40][390/391]	Step 16031	Loss 1.9880	Prec@(1,5) (50.2%, 79.8%)
12/26 10:49:49午後 searchStage_trainer.py:323 [INFO] Valid: [ 40/49] Final Prec@1 50.2080%
12/26 10:49:49午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('max_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/26 10:49:49午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 50.3760%
12/26 10:50:34午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][100/390]	Step 16131	lr 0.00287	Loss 0.5565 (0.7626)	Arch Loss 1.7164 (2.0048)	Arch Hard Loss 1.7164 (2.0048)	Arch Beta Loss 2.9509 (2.9510)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (77.1%, 96.1%)	
12/26 10:51:19午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][200/390]	Step 16231	lr 0.00287	Loss 0.6938 (0.7688)	Arch Loss 2.0644 (1.9984)	Arch Hard Loss 2.0644 (1.9984)	Arch Beta Loss 2.9504 (2.9509)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (77.0%, 96.0%)	
12/26 10:52:03午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][300/390]	Step 16331	lr 0.00287	Loss 0.7702 (0.7752)	Arch Loss 1.5995 (2.0048)	Arch Hard Loss 1.5995 (2.0048)	Arch Beta Loss 2.9523 (2.9510)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (76.9%, 96.1%)	
12/26 10:52:44午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [41][390/390]	Step 16421	lr 0.00287	Loss 0.8236 (0.7825)	Arch Loss 1.7040 (1.9904)	Arch Hard Loss 1.7040 (1.9904)	Arch Beta Loss 2.9527 (2.9513)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (76.5%, 96.0%)	
12/26 10:52:44午後 searchDistribution_trainer.py:166 [INFO] Train: [ 41/49] Final Prec@1 76.4480%
12/26 10:52:52午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][100/391]	Step 16422	Loss 2.0039	Prec@(1,5) (51.0%, 80.1%)
12/26 10:52:59午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][200/391]	Step 16422	Loss 1.9995	Prec@(1,5) (50.7%, 80.2%)
12/26 10:53:06午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][300/391]	Step 16422	Loss 2.0070	Prec@(1,5) (50.5%, 80.1%)
12/26 10:53:12午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [41][390/391]	Step 16422	Loss 2.0216	Prec@(1,5) (50.5%, 79.9%)
12/26 10:53:12午後 searchStage_trainer.py:323 [INFO] Valid: [ 41/49] Final Prec@1 50.5440%
12/26 10:53:12午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 8)]], DAG3_concat=range(9, 11))
12/26 10:53:12午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 50.5440%
12/26 10:53:58午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][100/390]	Step 16522	lr 0.00248	Loss 0.7193 (0.7082)	Arch Loss 1.8328 (1.9518)	Arch Hard Loss 1.8328 (1.9518)	Arch Beta Loss 2.9522 (2.9520)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (79.0%, 96.8%)	
12/26 10:54:42午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][200/390]	Step 16622	lr 0.00248	Loss 0.7524 (0.7147)	Arch Loss 1.7567 (1.9813)	Arch Hard Loss 1.7567 (1.9813)	Arch Beta Loss 2.9528 (2.9522)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (78.7%, 96.7%)	
12/26 10:55:27午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][300/390]	Step 16722	lr 0.00248	Loss 1.0410 (0.7297)	Arch Loss 1.6947 (1.9794)	Arch Hard Loss 1.6947 (1.9794)	Arch Beta Loss 2.9543 (2.9527)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (78.1%, 96.6%)	
12/26 10:56:07午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [42][390/390]	Step 16812	lr 0.00248	Loss 0.8833 (0.7375)	Arch Loss 2.1548 (1.9838)	Arch Hard Loss 2.1548 (1.9838)	Arch Beta Loss 2.9559 (2.9533)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (77.7%, 96.5%)	
12/26 10:56:08午後 searchDistribution_trainer.py:166 [INFO] Train: [ 42/49] Final Prec@1 77.7000%
12/26 10:56:15午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][100/391]	Step 16813	Loss 2.0164	Prec@(1,5) (50.7%, 80.2%)
12/26 10:56:22午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][200/391]	Step 16813	Loss 1.9781	Prec@(1,5) (51.2%, 80.4%)
12/26 10:56:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][300/391]	Step 16813	Loss 1.9513	Prec@(1,5) (51.6%, 81.0%)
12/26 10:56:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [42][390/391]	Step 16813	Loss 1.9444	Prec@(1,5) (51.7%, 80.9%)
12/26 10:56:36午後 searchStage_trainer.py:323 [INFO] Valid: [ 42/49] Final Prec@1 51.7440%
12/26 10:56:36午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('avg_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:56:37午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.7440%
12/26 10:57:22午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][100/390]	Step 16913	lr 0.00214	Loss 0.6194 (0.7000)	Arch Loss 1.8188 (1.9549)	Arch Hard Loss 1.8188 (1.9549)	Arch Beta Loss 2.9555 (2.9559)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (79.2%, 96.8%)	
12/26 10:58:05午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][200/390]	Step 17013	lr 0.00214	Loss 0.6621 (0.6997)	Arch Loss 2.5977 (1.9732)	Arch Hard Loss 2.5977 (1.9732)	Arch Beta Loss 2.9557 (2.9558)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (79.1%, 96.8%)	
12/26 10:58:51午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][300/390]	Step 17113	lr 0.00214	Loss 0.6876 (0.7023)	Arch Loss 1.8847 (1.9653)	Arch Hard Loss 1.8847 (1.9653)	Arch Beta Loss 2.9565 (2.9558)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (79.0%, 96.8%)	
12/26 10:59:32午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [43][390/390]	Step 17203	lr 0.00214	Loss 0.6448 (0.7115)	Arch Loss 1.8131 (1.9716)	Arch Hard Loss 1.8131 (1.9716)	Arch Beta Loss 2.9576 (2.9561)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (78.7%, 96.7%)	
12/26 10:59:32午後 searchDistribution_trainer.py:166 [INFO] Train: [ 43/49] Final Prec@1 78.6840%
12/26 10:59:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][100/391]	Step 17204	Loss 1.9584	Prec@(1,5) (51.6%, 81.3%)
12/26 10:59:45午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][200/391]	Step 17204	Loss 1.9645	Prec@(1,5) (51.8%, 81.1%)
12/26 10:59:52午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][300/391]	Step 17204	Loss 1.9711	Prec@(1,5) (51.6%, 81.1%)
12/26 10:59:59午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [43][390/391]	Step 17204	Loss 1.9702	Prec@(1,5) (51.7%, 81.0%)
12/26 10:59:59午後 searchStage_trainer.py:323 [INFO] Valid: [ 43/49] Final Prec@1 51.6760%
12/26 10:59:59午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 10:59:59午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.7440%
12/26 11:00:46午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][100/390]	Step 17304	lr 0.00184	Loss 0.8305 (0.6511)	Arch Loss 1.6754 (1.9999)	Arch Hard Loss 1.6754 (1.9999)	Arch Beta Loss 2.9586 (2.9584)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (80.7%, 97.3%)	
12/26 11:01:32午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][200/390]	Step 17404	lr 0.00184	Loss 0.6773 (0.6617)	Arch Loss 2.1160 (1.9820)	Arch Hard Loss 2.1160 (1.9820)	Arch Beta Loss 2.9591 (2.9586)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (80.3%, 97.2%)	
12/26 11:02:18午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][300/390]	Step 17504	lr 0.00184	Loss 0.8584 (0.6714)	Arch Loss 1.6941 (1.9825)	Arch Hard Loss 1.6941 (1.9825)	Arch Beta Loss 2.9608 (2.9590)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (79.9%, 97.1%)	
12/26 11:03:00午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [44][390/390]	Step 17594	lr 0.00184	Loss 0.7786 (0.6800)	Arch Loss 1.8707 (1.9802)	Arch Hard Loss 1.8707 (1.9802)	Arch Beta Loss 2.9614 (2.9596)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (79.6%, 97.0%)	
12/26 11:03:00午後 searchDistribution_trainer.py:166 [INFO] Train: [ 44/49] Final Prec@1 79.5920%
12/26 11:03:08午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][100/391]	Step 17595	Loss 2.0225	Prec@(1,5) (51.0%, 80.0%)
12/26 11:03:15午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][200/391]	Step 17595	Loss 2.0194	Prec@(1,5) (51.1%, 80.1%)
12/26 11:03:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][300/391]	Step 17595	Loss 2.0345	Prec@(1,5) (50.6%, 80.0%)
12/26 11:03:29午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [44][390/391]	Step 17595	Loss 2.0213	Prec@(1,5) (50.8%, 80.1%)
12/26 11:03:29午後 searchStage_trainer.py:323 [INFO] Valid: [ 44/49] Final Prec@1 50.8000%
12/26 11:03:29午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('avg_pool_3x3', 9)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 11:03:29午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.7440%
12/26 11:04:14午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][100/390]	Step 17695	lr 0.00159	Loss 0.7940 (0.6435)	Arch Loss 2.5332 (1.9946)	Arch Hard Loss 2.5332 (1.9946)	Arch Beta Loss 2.9611 (2.9611)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (81.0%, 97.2%)	
12/26 11:04:58午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][200/390]	Step 17795	lr 0.00159	Loss 0.5795 (0.6476)	Arch Loss 1.7232 (1.9839)	Arch Hard Loss 1.7232 (1.9839)	Arch Beta Loss 2.9625 (2.9614)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (80.8%, 97.4%)	
12/26 11:05:41午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][300/390]	Step 17895	lr 0.00159	Loss 0.5475 (0.6516)	Arch Loss 1.9098 (1.9848)	Arch Hard Loss 1.9098 (1.9848)	Arch Beta Loss 2.9637 (2.9619)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (80.7%, 97.4%)	
12/26 11:06:19午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [45][390/390]	Step 17985	lr 0.00159	Loss 0.7271 (0.6567)	Arch Loss 1.4521 (1.9762)	Arch Hard Loss 1.4521 (1.9762)	Arch Beta Loss 2.9657 (2.9626)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (80.5%, 97.2%)	
12/26 11:06:20午後 searchDistribution_trainer.py:166 [INFO] Train: [ 45/49] Final Prec@1 80.4520%
12/26 11:06:26午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][100/391]	Step 17986	Loss 1.9257	Prec@(1,5) (52.7%, 81.8%)
12/26 11:06:33午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][200/391]	Step 17986	Loss 1.9408	Prec@(1,5) (52.2%, 81.6%)
12/26 11:06:39午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][300/391]	Step 17986	Loss 1.9618	Prec@(1,5) (51.9%, 81.1%)
12/26 11:06:44午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [45][390/391]	Step 17986	Loss 1.9827	Prec@(1,5) (51.6%, 80.8%)
12/26 11:06:45午後 searchStage_trainer.py:323 [INFO] Valid: [ 45/49] Final Prec@1 51.5840%
12/26 11:06:45午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 11:06:45午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.7440%
12/26 11:07:28午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][100/390]	Step 18086	lr 0.00138	Loss 0.6277 (0.6219)	Arch Loss 1.8009 (1.9792)	Arch Hard Loss 1.8009 (1.9792)	Arch Beta Loss 2.9674 (2.9667)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.3%, 97.5%)	
12/26 11:08:11午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][200/390]	Step 18186	lr 0.00138	Loss 0.5751 (0.6284)	Arch Loss 1.9040 (1.9661)	Arch Hard Loss 1.9040 (1.9661)	Arch Beta Loss 2.9700 (2.9677)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (81.6%, 97.5%)	
12/26 11:08:55午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][300/390]	Step 18286	lr 0.00138	Loss 0.5253 (0.6245)	Arch Loss 2.3348 (1.9841)	Arch Hard Loss 2.3348 (1.9841)	Arch Beta Loss 2.9704 (2.9686)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (81.7%, 97.6%)	
12/26 11:09:34午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [46][390/390]	Step 18376	lr 0.00138	Loss 0.6060 (0.6310)	Arch Loss 1.7239 (1.9891)	Arch Hard Loss 1.7239 (1.9891)	Arch Beta Loss 2.9703 (2.9691)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (81.4%, 97.5%)	
12/26 11:09:35午後 searchDistribution_trainer.py:166 [INFO] Train: [ 46/49] Final Prec@1 81.4280%
12/26 11:09:41午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][100/391]	Step 18377	Loss 2.0959	Prec@(1,5) (49.9%, 79.9%)
12/26 11:09:48午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][200/391]	Step 18377	Loss 2.0669	Prec@(1,5) (50.6%, 80.2%)
12/26 11:09:55午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][300/391]	Step 18377	Loss 2.0613	Prec@(1,5) (51.0%, 80.1%)
12/26 11:10:00午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [46][390/391]	Step 18377	Loss 2.0567	Prec@(1,5) (50.7%, 80.2%)
12/26 11:10:01午後 searchStage_trainer.py:323 [INFO] Valid: [ 46/49] Final Prec@1 50.6880%
12/26 11:10:01午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 11:10:01午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.7440%
12/26 11:10:45午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][100/390]	Step 18477	lr 0.00121	Loss 0.9084 (0.5887)	Arch Loss 1.6292 (1.9848)	Arch Hard Loss 1.6292 (1.9848)	Arch Beta Loss 2.9720 (2.9713)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.0%, 98.2%)	
12/26 11:11:30午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][200/390]	Step 18577	lr 0.00121	Loss 0.9121 (0.6094)	Arch Loss 2.6827 (1.9769)	Arch Hard Loss 2.6827 (1.9769)	Arch Beta Loss 2.9749 (2.9724)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (81.9%, 97.8%)	
12/26 11:12:12午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][300/390]	Step 18677	lr 0.00121	Loss 0.6698 (0.6163)	Arch Loss 1.7841 (1.9878)	Arch Hard Loss 1.7841 (1.9878)	Arch Beta Loss 2.9751 (2.9733)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (81.8%, 97.5%)	
12/26 11:12:51午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [47][390/390]	Step 18767	lr 0.00121	Loss 0.7042 (0.6251)	Arch Loss 1.6821 (1.9831)	Arch Hard Loss 1.6821 (1.9831)	Arch Beta Loss 2.9750 (2.9737)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (81.5%, 97.5%)	
12/26 11:12:51午後 searchDistribution_trainer.py:166 [INFO] Train: [ 47/49] Final Prec@1 81.5280%
12/26 11:12:59午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][100/391]	Step 18768	Loss 2.0137	Prec@(1,5) (51.1%, 80.7%)
12/26 11:13:05午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][200/391]	Step 18768	Loss 2.0194	Prec@(1,5) (51.1%, 80.4%)
12/26 11:13:11午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][300/391]	Step 18768	Loss 2.0064	Prec@(1,5) (51.4%, 80.4%)
12/26 11:13:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [47][390/391]	Step 18768	Loss 2.0104	Prec@(1,5) (51.2%, 80.3%)
12/26 11:13:17午後 searchStage_trainer.py:323 [INFO] Valid: [ 47/49] Final Prec@1 51.1960%
12/26 11:13:17午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 8)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 11:13:17午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 51.7440%
12/26 11:14:01午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][100/390]	Step 18868	lr 0.00109	Loss 0.4906 (0.5745)	Arch Loss 2.2513 (1.9822)	Arch Hard Loss 2.2513 (1.9822)	Arch Beta Loss 2.9762 (2.9758)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (83.7%, 98.0%)	
12/26 11:14:46午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][200/390]	Step 18968	lr 0.00109	Loss 0.7264 (0.5967)	Arch Loss 1.9657 (1.9920)	Arch Hard Loss 1.9657 (1.9920)	Arch Beta Loss 2.9760 (2.9760)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.7%, 97.8%)	
12/26 11:15:31午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][300/390]	Step 19068	lr 0.00109	Loss 0.3862 (0.5994)	Arch Loss 1.8907 (1.9822)	Arch Hard Loss 1.8907 (1.9822)	Arch Beta Loss 2.9763 (2.9761)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.5%, 97.8%)	
12/26 11:16:10午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [48][390/390]	Step 19158	lr 0.00109	Loss 0.6875 (0.6103)	Arch Loss 1.9802 (1.9811)	Arch Hard Loss 1.9802 (1.9811)	Arch Beta Loss 2.9780 (2.9763)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.3%, 97.6%)	
12/26 11:16:10午後 searchDistribution_trainer.py:166 [INFO] Train: [ 48/49] Final Prec@1 82.2640%
12/26 11:16:17午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][100/391]	Step 19159	Loss 1.9991	Prec@(1,5) (50.7%, 79.7%)
12/26 11:16:23午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][200/391]	Step 19159	Loss 1.9850	Prec@(1,5) (51.4%, 80.1%)
12/26 11:16:30午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][300/391]	Step 19159	Loss 1.9674	Prec@(1,5) (52.0%, 80.6%)
12/26 11:16:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [48][390/391]	Step 19159	Loss 1.9650	Prec@(1,5) (52.1%, 80.7%)
12/26 11:16:36午後 searchStage_trainer.py:323 [INFO] Valid: [ 48/49] Final Prec@1 52.0960%
12/26 11:16:36午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 11:16:36午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 52.0960%
12/26 11:17:21午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][100/390]	Step 19259	lr 0.00102	Loss 0.3797 (0.5834)	Arch Loss 1.7699 (1.9766)	Arch Hard Loss 1.7699 (1.9766)	Arch Beta Loss 2.9791 (2.9785)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (83.1%, 97.9%)	
12/26 11:18:06午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][200/390]	Step 19359	lr 0.00102	Loss 0.5014 (0.5951)	Arch Loss 2.1152 (1.9981)	Arch Hard Loss 2.1152 (1.9981)	Arch Beta Loss 2.9798 (2.9790)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.5%, 97.9%)	
12/26 11:18:49午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][300/390]	Step 19459	lr 0.00102	Loss 0.6579 (0.6026)	Arch Loss 1.8201 (1.9796)	Arch Hard Loss 1.8201 (1.9796)	Arch Beta Loss 2.9814 (2.9795)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.4%, 97.7%)	
12/26 11:19:28午後 searchDistribution_trainer.py:152 [INFO] Train: Epoch: [49][390/390]	Step 19549	lr 0.00102	Loss 0.5196 (0.6071)	Arch Loss 1.8121 (1.9786)	Arch Hard Loss 1.8121 (1.9786)	Arch Beta Loss 2.9806 (2.9798)	Arch depth Loss 0.0030 (0.0030)	Prec@(1,5) (82.1%, 97.6%)	
12/26 11:19:29午後 searchDistribution_trainer.py:166 [INFO] Train: [ 49/49] Final Prec@1 82.1400%
12/26 11:19:36午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][100/391]	Step 19550	Loss 2.0379	Prec@(1,5) (51.3%, 81.0%)
12/26 11:19:42午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][200/391]	Step 19550	Loss 2.0152	Prec@(1,5) (51.4%, 80.8%)
12/26 11:19:49午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][300/391]	Step 19550	Loss 2.0017	Prec@(1,5) (51.3%, 80.9%)
12/26 11:19:54午後 searchStage_trainer.py:312 [INFO] Valid: Epoch: [49][390/391]	Step 19550	Loss 1.9887	Prec@(1,5) (51.6%, 81.2%)
12/26 11:19:54午後 searchStage_trainer.py:323 [INFO] Valid: [ 49/49] Final Prec@1 51.5640%
12/26 11:19:54午後 trainer_runner.py:77 [INFO] DAG = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('max_pool_3x3', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/26 11:19:55午後 trainer_runner.py:108 [INFO] Until now, best Prec@1 = 52.0960%
12/26 11:19:55午後 trainer_runner.py:113 [INFO] Final best Prec@1 = 52.0960%
12/26 11:19:55午後 trainer_runner.py:114 [INFO] Final Best Genotype = Genotype2(DAG1=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 0)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 3), ('skip_connect', 5)], [('skip_connect', 4), ('skip_connect', 6)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('max_pool_3x3', 9), ('skip_connect', 7)], [('skip_connect', 8), ('skip_connect', 9)]], DAG1_concat=range(9, 11), DAG2=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 2)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 8)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 8), ('avg_pool_3x3', 10)]], DAG2_concat=range(9, 11), DAG3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 1), ('skip_connect', 2)], [('skip_connect', 2), ('skip_connect', 3)], [('skip_connect', 3), ('skip_connect', 4)], [('skip_connect', 4), ('skip_connect', 5)], [('skip_connect', 5), ('skip_connect', 6)], [('skip_connect', 6), ('skip_connect', 7)], [('skip_connect', 7), ('skip_connect', 8)], [('skip_connect', 10), ('skip_connect', 9)]], DAG3_concat=range(9, 11))
12/27 12:25:09AM parser.py:28 [INFO] 
12/27 12:25:09AM parser.py:29 [INFO] Parameters:
12/27 12:25:09AM parser.py:31 [INFO] DAG_PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.001/DAG
12/27 12:25:09AM parser.py:31 [INFO] T=10.0
12/27 12:25:09AM parser.py:31 [INFO] ADVANCED=1
12/27 12:25:09AM parser.py:31 [INFO] ALPHA_LR=0.0003
12/27 12:25:09AM parser.py:31 [INFO] ALPHA_WEIGHT_DECAY=0.001
12/27 12:25:09AM parser.py:31 [INFO] ARCH_CRITERION=expected
12/27 12:25:09AM parser.py:31 [INFO] BATCH_SIZE=64
12/27 12:25:09AM parser.py:31 [INFO] CASCADE=0
12/27 12:25:09AM parser.py:31 [INFO] CHECKPOINT_RESET=False
12/27 12:25:09AM parser.py:31 [INFO] CURRICULUM_EPOCHS=[30, 30]
12/27 12:25:09AM parser.py:31 [INFO] CUTOUT_LENGTH=0
12/27 12:25:09AM parser.py:31 [INFO] DATA_PATH=../data/
12/27 12:25:09AM parser.py:31 [INFO] DATASET=cifar100
12/27 12:25:09AM parser.py:31 [INFO] DEPTH_COEF=-0.001
12/27 12:25:09AM parser.py:31 [INFO] DESCRIPTION=search_and_evaluation_curriculum_learning_with_-Beta-expected-Depth-ecpected-constraint_slidewindow-3
12/27 12:25:09AM parser.py:31 [INFO] DISCRETE=1
12/27 12:25:09AM parser.py:31 [INFO] EPOCHS=50
12/27 12:25:09AM parser.py:31 [INFO] EVAL_EPOCHS=100
12/27 12:25:09AM parser.py:31 [INFO] EXP_NAME=s0-depth-sw3-g-0.001
12/27 12:25:09AM parser.py:31 [INFO] FINAL_L=0.0
12/27 12:25:09AM parser.py:31 [INFO] G=0.0
12/27 12:25:09AM parser.py:31 [INFO] GENOTYPE=Genotype3(normal1=[[('sep_conv_5x5', 0), ('sep_conv_3x3', 1)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 0)], [('sep_conv_3x3', 1), ('sep_conv_3x3', 2)], [('sep_conv_3x3', 0), ('sep_conv_5x5', 4)]], normal1_concat=range(2, 6), reduce1=[[('sep_conv_3x3', 0), ('skip_connect', 1)], [('sep_conv_3x3', 1), ('max_pool_3x3', 0)], [('sep_conv_3x3', 2), ('sep_conv_3x3', 1)], [('max_pool_3x3', 0), ('dil_conv_3x3', 1)]], reduce1_concat=range(2, 6), normal2=[[('skip_connect', 0), ('sep_conv_5x5', 1)], [('skip_connect', 0), ('skip_connect', 2)], [('avg_pool_3x3', 0), ('avg_pool_3x3', 2)], [('skip_connect', 0), ('avg_pool_3x3', 2)]], normal2_concat=range(2, 6), reduce2=[[('avg_pool_3x3', 0), ('avg_pool_3x3', 1)], [('avg_pool_3x3', 0), ('skip_connect', 2)], [('skip_connect', 2), ('avg_pool_3x3', 0)], [('skip_connect', 2), ('avg_pool_3x3', 0)]], reduce2_concat=range(2, 6), normal3=[[('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('dil_conv_3x3', 1)], [('skip_connect', 0), ('skip_connect', 1)], [('skip_connect', 0), ('skip_connect', 2)]], normal3_concat=range(2, 6))
12/27 12:25:09AM parser.py:31 [INFO] GPUS=[0]
12/27 12:25:09AM parser.py:31 [INFO] HINT_EPOCHS=[16, 32]
12/27 12:25:09AM parser.py:31 [INFO] INIT_CHANNELS=16
12/27 12:25:09AM parser.py:31 [INFO] L=0.0
12/27 12:25:09AM parser.py:31 [INFO] LAYERS=32
12/27 12:25:09AM parser.py:31 [INFO] LOGGER=<Logger H-DAS (INFO)>
12/27 12:25:09AM parser.py:31 [INFO] NAME=Pruning
12/27 12:25:09AM parser.py:31 [INFO] NONKD=1
12/27 12:25:09AM parser.py:31 [INFO] PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.001
12/27 12:25:09AM parser.py:31 [INFO] PCDARTS=0
12/27 12:25:09AM parser.py:31 [INFO] PLOT_PATH=results/search_stage_KD/cifar100/Pruning/s0-depth-sw3-g-0.001/plots
12/27 12:25:09AM parser.py:31 [INFO] PRINT_FREQ=100
12/27 12:25:09AM parser.py:31 [INFO] RESET=0
12/27 12:25:09AM parser.py:31 [INFO] RESUME_PATH=None
12/27 12:25:09AM parser.py:31 [INFO] SAVE=s0-depth-sw3-g-0.001
12/27 12:25:09AM parser.py:31 [INFO] SEED=0
12/27 12:25:09AM parser.py:31 [INFO] SHARE_STAGE=0
12/27 12:25:09AM parser.py:31 [INFO] SLIDE_WINDOW=3
12/27 12:25:09AM parser.py:31 [INFO] SPEC_CELL=1
12/27 12:25:09AM parser.py:31 [INFO] STAGE_MACS=[8.18, 2.49, 1.88]
12/27 12:25:09AM parser.py:31 [INFO] TEACHER_NAME=none
12/27 12:25:09AM parser.py:31 [INFO] TEACHER_PATH=none
12/27 12:25:09AM parser.py:31 [INFO] TRAIN_PORTION=0.5
12/27 12:25:09AM parser.py:31 [INFO] TYPE=Distribution
12/27 12:25:09AM parser.py:31 [INFO] W_GRAD_CLIP=5.0
12/27 12:25:09AM parser.py:31 [INFO] W_LR=0.025
12/27 12:25:09AM parser.py:31 [INFO] W_LR_MIN=0.001
12/27 12:25:09AM parser.py:31 [INFO] W_MOMENTUM=0.9
12/27 12:25:09AM parser.py:31 [INFO] W_WEIGHT_DECAY=0.0003
12/27 12:25:09AM parser.py:31 [INFO] WORKERS=4
12/27 12:25:09AM parser.py:32 [INFO] 
12/27 12:25:12AM searchStage_trainer.py:134 [INFO] --> No loaded checkpoint!
12/27 12:26:40AM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][100/390]	Step 100	lr 0.025	Loss 4.4325 (4.5036)	Arch Loss 4.2701 (4.4891)	Arch Hard Loss 4.2701 (4.4891)	Arch Beta Loss 2.8232 (2.8233)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (2.5%, 10.3%)	
12/27 12:28:02AM searchDistribution_trainer.py:152 [INFO] Train: Epoch: [0][200/390]	Step 200	lr 0.025	Loss 4.1345 (4.4013)	Arch Loss 4.1662 (4.3895)	Arch Hard Loss 4.1662 (4.3895)	Arch Beta Loss 2.8239 (2.8233)	Arch depth Loss 0.0028 (0.0028)	Prec@(1,5) (3.4%, 13.3%)	
